var store = [{
        "title": "Azure Functions The Journey",
        "excerpt":"Our team was excited to recently release a preview of the new Azure Functions service at //build. We’ve done some blogging about the service already (e.g. Introducing Azure Functions), but in this post we’d like to delve a bit behind the scenes and discuss how the project started and the journey we’ve taken to arrive at where we are today. We’ll discuss the Functions Runtime, the Dynamic Compute layer (“Serverless”) as well as the Functions Portal, and see at a high level how all those pieces evolved and came together into a cohesive product. It’s been a fun ride for the team, and it’s only just begun :)   The evolution of this project is a great example of identifying synergies across a bunch of existing platform pieces, and connecting them together into a new product offering. In Azure App Service we already had many of the building blocks in place to enable us to rather quickly execute on the Azure Functions vision. By leveraging these existing assets and bringing in new innovations and functionality we were able to pull the project together pretty quickly.   WebJobs SDK   In Chris’s //build talk Introducing Azure Functions he explained how Azure Functions is built on the Azure WebJobs SDK. The WebJobs SDK has existed for a couple years now, and we have many customers happily using it to build backend processing jobs that trigger on a wide variety of event sources. The WebJobs SDK has a simple declarative programming model that makes it very easy to write sophisticated job functions with a minimal amount of code. Here’s an example:   public static void ProcessOrder(   [QueueTrigger(\"orders\")] Order order,   [Blob(\"processed/{Id}\")] out string receipt,   TraceWriter log)   {       log.Verbose(string.Format(\"Processing Order {0}\", order.Id));     // business logic     receipt = \"&lt;some value&gt;\";   }   When hosted by the WebJobs SDK JobHost in a vanilla .NET Console application, this function will be automatically triggered whenever a new queue message is added to Azure Queue “orders” and the queue payload will be deserialized into an instance of the Order POCO. The function also automatically binds to an output Blob using the “Id” property from the incoming message as part of the blob path. With this programming model, your job function just focuses on its business logic and doesn’t have to take care of any of the storage operations. Awesome!   The hosting model for such functions using the WebJobs SDK is to deploy them as Azure WebJobs. This works great and offers a lot of flexibility, and continues to be a very popular feature of Azure App Service.   Functions Runtime   Around the middle of last year, we started discussing what it would take to bring this simple programming model to other languages – we’d had customers ask us for this as well. Not everyone is a .NET C# programmer, yet many would like to use these WebJobs SDK patterns. So we started some prototyping efforts on this and came up with a model that allowed us to leverage the existing tried and true .NET WebJobs SDK runtime, layering on a new JSON description model for the metadata. The result is that you can write the same function as above in Node.js (or other languages):   module.exports = function (context, order) {       context.log('Processing order', order.id);     // business logic     context.bindings.receipt = \"&lt;some value\";       context.done();   }   You’ll notice that this function is structurally the same as the C# function above. That’s because it maps to the same runtime implementation. Declarative code attributes are just one way of specifying metadata. We realized that we could capture the same information in a simple JSON description file. Here’s the corresponding metadata file describing the bindings for this function (i.e. all the bits that are in the declarative attributes in the C# example):   {     \"bindings\": [{         \"type\": \"queueTrigger\",         \"name\": \"order\",         \"direction\": \"in\",         \"queueName\": \"orders\"     }, {         \"type\": \"blob\",         \"name\": \"receipt\",         \"direction\": \"out\",         \"path\": \"processed/{id}\"     }] }   The basic idea is that we can use this metadata to generate an in memory adaptor between various languages and the .NET WebJobs SDK runtime. We effectively generate the C# function you see above, and the method body of that function simply delegates to the actual user function (i.e. the Node.js function you wrote). An Azure Function can then just be a simple function.json metadata file describing the function bindings, along with a collection of one or more script files implementing the function. Here’s the same example as above, using the same metadata file, with the function written as a Windows BAT file:   SET /p order=&lt;%order%&gt; echo Processing order '%order%'   echo '&lt;some value&gt;' &gt; %receipt%   That same metadata file can be used to describe a function in any of our 7 supported languages. Of course each language has its own quirks and capabilities, and some are more suited than others for various tasks. The main point here is that we can have the same triggering/binding runtime for all of these languages, allowing each language to map to that model in its own way. BAT files are somewhat limited, but through environment variables and file streams, they can both receive inputs and write outputs, which the Functions runtime automatically maps to the underlying Azure Storage artifacts.   Having Azure Functions build on the core WebJobs SDK means we don’t have to write and maintain different versions of the WebJobs SDK per language, which is a huge engineering win. We have a single core runtime that handles all our binding/triggering logic, and investments we make in that core benefit functions as well as all our WebJobs SDK customers. It also means that all the trigger/binding Extensions that people write for the core SDK can also be used in Functions. We’ll continue investing heavily in the core WebJobs SDK and Extensions both for our traditional customers as well as for Azure Functions.   WebHook Support   Another important area we started focusing on was our WebHooks story. The ability for functions to be triggered on Azure Storage events is great, but we’ve had WebJobs customers asking us for the ability to trigger their job functions via WebHook requests as well. We had already experimented with this last year by writing a WebHooks Extension which worked well, but had a big drawback stemming from the fact that WebJobs run under the Kudu SCM site, which means that basic auth credentials are required to make requests. That’s a deal breaker for most WebHook integration scenarios, since you want the ability to hand out a URL with a simple auth code that is restricted to allowing only that endpoint to be reached.   To address this, we decided to package the Functions Runtime as a site extension that runs in root of a WebApp. This means that it is NOT behind the SCM endpoint, allowing us to achieve the auth patterns required. This enabled us to expose a simple set of authenticated endpoints for WebHook functions. We also integrated the ASP.NET WebHooks library into this, allowing us to leverage the large number of WebHook providers that library supports, giving us first class support for providers like GitHub, Slack, DropBox, Instagram, etc.   So at this point we had a flexible Functions Runtime that supported the full WebJobs SDK triggering/binding model for 7 languages (Node.js, C#, F#, Bash, BAT, Python, PHP), that also had an HTTP head supporting a wide array of WebHook integration scenarios.   Dynamic Compute   In parallel with the above runtime work, we were also having discussions about Serverless Computing and what we wanted to do in that space. We realized that this work we were doing for WebJobs was highly synergistic. We were developing a flexible, multi-language function runtime that could run user code in a sandboxed environment at high scale. However, the traditional WebJobs model requires users to create and manage the WebApp host that those WebJobs run on. What if we were able to abstract that portion of things away so users only had to write the functions themselves, and we’d handle all the deployment and scale concerns? Basically we’d have the WebJobs SDK as a Service. Eureka!   We spun up a team to go off and investigate that portion of the plan – “Dynamic Compute”. This was the point in the project where we grew quickly from a small handful of people into a much larger team – our scrum meetings were growing daily by 2-3 people it seemed :) Our Dynamic Compute layer is responsible for automatically scaling functions out as load increases, and scaling back when it decreases. The result for the end user is that they don’t have to worry about this at all, and they only get billed for the compute time they actually use. The Dynamic Compute area of the project is large and also includes other service aspects like monitoring and diagnostics, telemetry, etc. This area deserves its own blog post in the future.   Functions Portal   The next thing we started focusing on was a portal experience to make it really easy to author and manage these functions. In the traditional WebJobs SDK model, you compile and deploy a .NET Console application (JobHost) that contains all your precompiled job functions. For Azure Functions the deployment model is much simpler. The Functions Runtime was designed to have a very simple file system layout. That facilitates a straight forward Portal UI that operates on those files via the Kudu APIs. We could have a simple portal editor that allowed you to create/edit these files and push them into the function container (the WebApp running the functions). The simple file system model also makes it possible to deploy Azure Functions via ARM templates. That is actually possible today, but not documented well yet.   The team was able to get a Portal up and running pretty quickly and we were all very excited to be able to start using it to play with the nascent product. With the Portal in place things really started feeling like they were coming together! We were able to start having the wider team play with the product which drove lots of usability discussions/improvements and also helped us start working the bugs out. When the Portal work started, as with the Functions Runtime we had one or two people working on it, but as that early work gained traction and our scope/plans increased, we on-boarded more people. Scrum meetings got larger still :)      Templates   The simple file system model for functions also allowed us to develop the awesome template model you see today in the Functions Portal. We started churning out simple metadata/script templates for common scenarios across the various languages: “QueueTrigger – Node”, “GitHub WebHook C#”, etc. The idea is to have simple “recipes” or starting points for your functions that run immediately out of the box, that you can then customize and extend to your needs. In the future we hope to allow the community to also author such templates to drive an ecosystem.      Extensibility   Another area we focused a lot on leading up to our //build announcement of Azure Functions was a new set of WebJobs SDK Extensions that we made available in Functions. We released the WebJobs SDK Extensibility model last fall, which opened the programming model up to new trigger/binding sources. Our team had already seeded the community with some new useful extensions (e.g. TimerTrigger, FileTrigger, SendGrid binding, etc.) in the WebJobs SDK Exensions repo. We’ve also had community members start authoring their own extensions. Since Functions is built on the SDK, all these extensions can be made available to Azure Functions as well. There were many extensions we knew we wanted to write but didn’t have the time, and with our new larger team we had the resources to start cranking some of those out. In the last couple months we’ve added the following additional extensions and made them first class in Functions: EventHub, DocumentDb, NotificationHub, MobileApps, and ApiHub. This is only the beginning – there are many more extensions planned, and we expect the community to author more as well. We’re also working on an easy model for allowing 3rd parties to onboard their extensions into Functions. Stay tuned for that.   Another cool thing is that we decided early that we wanted to do all our work open source, just as we have with the core WebJobs SDK and WebJobs SDK Extensions repos. So we created the WebJobs SDK Script containing the Functions Runtime. Similarly, the Functions Portal is also open source: AzureFunctionsPortal.   In closing, all of the above has been a pretty high level overview of the various pieces of the project and how they came together: the Functions Runtime, Functions Portal, and Dynamic Compute. In future posts, we’ll delve more into the details of these various areas :)  ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/04/27/Azure-Functions-The-Journey.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service supports Node.js v6",
        "excerpt":"      Chris Anderson (Azure)     5/6/2016 11:00:15 AM  We're happy to announce that Azure App Service supports Node.js v6.0.0. Node.js v6.0.0 is a major step forward for the Node.js community thanks to the efforts of so many to increase the ES6 compatibility coverage, as well as many performance and security improvements. We'll follow the developments of v6 closely (including v6.1.0 which came out last night) as it moves towards a new v6 LTS version, at which point we'll plan on recommending developers creating new apps on App Service use that version, as we currently do for the v4 LTS version. Get started with Node.js on Azure App Service here. Using Node.js v6.0.0 on Azure App Service  To use Node.js v6.0.0, you can specify your version in your package.json file, as detailed on our Node.js documentation page. It's as simple as adding the following JSON to the file:   \"engines\": { \"node\": \"6.0.0\" },   Once you've done that and you redeploy your code via git/CI, our deployment process will select the v6.0.0 Node.js version. We default to using npm version v3.8.6 for Node.js v6.0.0. Getting started with Node.js on Azure App Service  If you haven't yet tried using Node.js on Azure App Service, it is one of the easiest ways of hosting a Node.js application in the cloud. Azure App Service makes it easy to create a Node.js website hosting whichever framework you like, using the developer tools you prefer, and all with little to no management overhead. This awesome doc written by Cephas Lin walks you through creating a Node MVC site via Yeoman, creating an Azure Web App via the x-plat cli (npm i -g azure-cli), modifying the port setting to use the environment variable provided by the App Service runtime, creating a git commit with all those changes, and then pushing it to Azure via git. If you have an existing Node.js website that you'd like to try moving to Azure, just try following the steps starting from #4. If you don't have an Azure subscription, you can get a free trial or get a temporary one for an hour via \"Try App Service\".   Next steps   Learn about Node.js on Azure App Service Try App Service Get an Azure Subscription      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/05/06/App-Service-supports-Node.js-v6.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Speed up your Joomla Web App on Azure Web Apps",
        "excerpt":"      mksunitha     5/9/2016 2:06:05 PM  Every website for a company or personal wants to engage their customers , but if your website takes too long to load then you lose your users. For different types of applications, there are different options to prevent this from happening . In the blog post below we are going to discuss how we can improve Joomla web app fast and respond to users quickly by just making some or all the tweaks mentioned below. Enable Joomla Caching  Caching is not enabled by default when you set up Joomla web app. Joomla does the following when displaying a page:  get the content from its database loads all the plugins, components and/or modules loads your template file finally brings this all together in a single page rendered in visitor's browser  This workflow of tasks can take time. Joomla has built-in caching mechanism that can help to load the page faster. Joomla supports two types of caching well explained here Conservative caching is the standard type of caching. The caching process work as described below:  When a page is requested by a user, Joomla checks if there is a version of that page requested that is in its cache directory. If the page exists and hasn't expired , Joomla will serve it to the visitor. Otherwise, a cached version of the page is created, and that cached version will be served to the visitor, and to every other consequent visitor, as long as the page is not expired. Progressive caching process is different from conservation caching .The caching process works as described below:  When a page is requested by a user , Joomla checks if a cached version of that page exists for that visitor . If its exists and hasn't  expired then it’ll be served to the visitor, otherwise, Joomla will create the cached page for that specific visitor and then will serve it to the user.  If another visitor  who had visited that same page previously and visits that page the second time, then Joomla will not serve the cached page of the previous visitor, instead, it will create a cached version of that page specifically for that user, and then serves it to him.  To enable the Joomla caching, go to System -&gt; Global Configuration.Next, you need to click on the System tab and find  the Cache Settings. Select ON - Conservative caching option with cache handle being Windows Cache ( Wincache) and Click on Save   Go to Extensions -&gt; Plugin Manager and Enable the System - Page Cache core plugin. Note if this plugin is not enabled, caching will not work even though Global configuration settings is set to use Conservative caching    You can use additional caching extensions to improve the caching capability of Joomla such as JotCache and Cache Cleaner. Use Joomla Memcache caching  You can opt for using Joomla Memcache caching mechanism instead of built-in caching feature.  Azure web app supports Memcache protocol with Azure Redis cache. To lean more , read this article. Enable Joomla Compression  Gzip Compression is enabled by default on web app at the server level. But for the application to use the GZip compression , you need to enable it within Joomla configuration.  Login to the Joomla web app admin dashboard and go to System -&gt; Global Configuration. Click on the Server tab and enable GZip page compression. Click on Save to save your changes.   Use IIS output caching  The IIS Output Caching feature targets semi-dynamic content. It allows you to cache static responses for dynamic requests and to gain tremendous scalability. Update your web.config and add the following section to cache your content. &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;configuration&gt;    &lt;system.webServer&gt;      &lt;caching&gt;        &lt;profiles&gt;          &lt;add extension=\".php\"  policy=\"CacheUntilChange\" /&gt;       &lt;/profiles&gt;      &lt;/caching&gt;    &lt;/system.webServer&gt; &lt;/configuration&gt; To learn more , check out this article. Remove  extensions not in use  Since Joomla would need to identify which extensions to use it has to scan through all the extensions. This can cause your page to take longer to load. If you have any extensions not in use , please remove them from your production app.Note You can have those extensions in your development or testing environment sites to identify the best extension that fits your needs. Minify CSS and JS  Use extensions like JCH Optimize which minifies , compresses Javascript to improve page response time. Use CDN  Enable Azure CDN with your Azure web app to improve performance. For details , check out this video. Stay up-to-date  Joomla  and its extensions may have updates that can impact the performance of your web application. Make sure you have the latest bits of Joomla CMS , Latest PHP version and the Joomla extensions you have installed within your Joomla app. Optimize your tables  Optimize your Joomla app database using phpMyAdmin .  If you have never used PHPMyadmin with Azure web apps , check out this article first. Select all  or some of the tables and Select Optimize Table operation to execute.   This post also appears on Sunitha Muthukrishna Blog.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/05/09/Speed-up-your-Joomla-Web-App-on-Azure-Web-Apps.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Disable Session affinity cookie (ARR cookie) for Azure web apps",
        "excerpt":"      mksunitha     5/16/2016 8:03:55 PM  Azure app service allows you to auto scale your web app by dynamically adding web server instances to handle the traffic to your web app. Azure app service uses Application Request Routing IIS Extension to distribute your connecting users between your active instances serving up the content. ARR cleverly identifies the user by assigning them a special cookie (known as an affinity cookie), which allows the service to choose the right instance the user was using to serve subsequent requests made by that user. This means, a client establishes a session with an instance and it will keep talking to the same instance until his session has expired.  If you already have a web app on Azure app service , just browse the app and use browser debugger ( click on F12)  to see the list of cookies. In the list of cookie you will see ARRAffinity Cookie    There are situations where in keeping the affinity is not desired. For example, if you are getting way too many requests from a single user and the requests going to the same web server instance can overload it.  If maintaining session affinity is not important and you want better load balancing , it is recommended to disable session affinity cookie. Follow the steps for either Azure portal or Azure resource Explorer to  disable the session affinity cookie: Azure Portal:   Login to the Azure portal Browse App Services and select your web application. Click on Settings-&gt;Application Settings.  Find ARR affinity setting under General Settings and click on Off   Azure Resource Explorer:   Go to Azure resource explorer. Click on subscriptions    Click on your azure subscription in which your web app is located. Click on resourcegroups    Click on the resource group where the web app is located. Click on Microsoft.Web. Click on sites and Select your web app . Click on Edit to make your changes .     Search for clientAffinityCookie and set it to false     Click on PUT to save your changes.      That’s it! You have now disabled the session affinity cookie. You can browse your web app and click on F12 key to access the debugger on your browser to view the cookies generated. For an app without Session affinity cookie you will  not see ARRAffinity in the list of cookies.    Without the cookie the requests for your web app, will be distributed evenly across all the instances serving your web app content. You can achieve  better load balancing for your web app.                 ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/05/16/Disable-Session-affinity-cookie-(ARR-cookie)-for-Azure-web-apps.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure App Service Web App troubleshooting blade and tools",
        "excerpt":"      Apurva Joshi (AJ)     5/18/2016 11:17:05 AM  I have been fortunate to have an opportunity to Build/Ship/Support on premise products as well as cloud services for Microsoft. One of my biggest take away from this experience is, “You ship an on-premises product and make it’s issues/bugs your CUSTOMER’S problem. You ship a service in the cloud and now the same issues/bugs are YOUR problem!” Azure App Service Web App team aggress to this philosophy and has been aggressively investing in troubleshooting and diagnostic tools.  I highly recommend watching this one hour “short” video (short from troubleshooting standards) from my  //Build 2015 session, When bad things happen to good apps.  It all started as an experiment outside of the Azure portal, we called it Support Portal. It was a success and was ready to be first-class citizen inside Azure portal. It found a place inside SUPPORT + TROUBLESHOOTING section of your Web App settings.    We soon realized that while these tools are great ingredients which are better served as a recipe. In another words, Please tell me what tools to use when and how? This is where Troubleshoot Blade comes handy. Troubleshoot blade  Troubleshoot blade is part of SUPPORT + TROUBLESHOOTING section of key Azure Services like Web Apps, Virtual Machine, SQL. etc. Every participating Azure Service populates this blade with their most common and usually top support issues.   This blade has three top level sections which we will cover in detail soon.   Resource health check Common support issues and solutions Ability to submit support request to Azure Customer Support  Resource health check for Web Apps  Resource Health Check for Web Apps is like a doctor that attempts to diagnose an issue (runtime issues) with your application to be either service level outage or application specific issue. It makes this determination mainly by reading two distinct signals. First signal is health of Canary Web App (static web page running under every VM instance) and second signal is active live site incident (service issue).  Scenario 1: IF Canary Web App signal IS healthy (HTTP 200 OK) and there IS NO active live site incident impacting your Web App THEN it will say Healthy, meaning we think life is good, but if you think otherwise then it is most likely an application issue. Scenario 2: IF Canary Web App signal IS NOT healthy (HTTP 200 NOT OK) and there IS an active live site incident impacting your Web App THEN it will say Unhealthy, meaning we think life is not good and someone in Redmond is actively working to resolve this issue. Scenario 3: IF Canary Web App signal IS NOT healthy (HTTP 200 NOT OK) and there IS NO active live site incident impacting your Web App THEN it will say Unhealthy meaning we think life could be better and doctor needs to perform more diagnostics.  NOTE: Resource Health Check for Web Apps is NOT available to FREE and Shared offerings (as there is no SLA for these offerings and hence no canary web app). Putting an analogy here would be recipe for disaster, so I would stop right here. Common solutions  This is the place where we put together a recipe (step-by-step troubleshooting guide) to resolve a specific issue using some of the ingredients (troubleshooting tools). Here we list out our common supportability issues based on symptoms or scenarios. In this blog post I will pick one scenario and explain the steps in detail. My App is returning HTTP 5xx errors  You are here because resource health check told you it is Scenario 1 or Scenario 3.  Step 1: Assess the HTTP errors impact using Live HTTP traffic chart  When my Web App starts giving HTTP 5xx errors my 1st instinct is to try and asses the impact. Are all requests failing? What percent of requests are failing? etc. “Live HTTP traffic” chart is a great way to assess the impact. This tools shows you aggregated live traffic for the selected Web App across different hostnames. There is hardly 10 seconds delay in charting. It basically aggregates your HTTP server logs from all the instances, including multi region deployments behind traffic manager. It then splits our success vs. failures and charts them.    Image above shows about 30% of my requests are failing and it is not entire Web app down situation. (Blue represent success, Red represents failures). I can choose to filter the graph by hostnames etc.  (While the situation is not that pretty, got to admit the graph is very pretty!)  Step 2: Identify instance(s) exhibiting poor application performance  Now we know that about 30% of my requests are failing, would not it be nice to know if these failures are tied to single instance (if my web app is running multi-instances) or distributed across all? Or I just want to check the load distribution across various instances, or may be check CPU/Memory usage for last one hour across various instances. All of above mysteries can be solved by clicking on this view. This view provides you critical statistics about your Web App (site) per instances over span of Last 1 hour, Last 24 hours and Last 5 days    Image above shows I have two instances (RD0003FF451561 and RD0003FF454F62) in last one hours. If I had more or less instances in last 24 hours or five days, it would show them all regardless of current configuration. I think that’s kind of cool, especially when investigating past issues. The mage above also confirms my load was equally distributed across both the machines and both of them were giving HTTP 5xx, so this issue is not tied to a single instance. I can also check the CPU/Memory/Network IO etc. by scrolling down the charts.  Step 3: Attempt to resolve the issue by using Advanced Application restart  Restart is an answer to all technical issues – isn’t it? It surely is first thing one tries to recover. If Step 2 helped you identify an instance that is “bad” then this blade is a pure blessing. Just select the “bad” instance and click on Restart. If it is all of them then you can select them all with Restart Sleep Timer of 90 seconds and click away the Restart button. Yep, it’s that easy!    Let’s see what the “Restart button” does in background.  For start, this is NOT same as Restarting your Web App. Web App Restart is ruthless beast that goes out and fires restart across all instances at the same time. (If you have single instance then the impact is the same). This is NOT same as Rebooting your VM. Well in Azure App Service, you can’t reboot your VM (yet), at least by choice. (If you really want to reboot the VM instance, then simply trick the system by changing the scale Up or Down. That is switch to medium from small or large etc.) This is simply graceful restart of your Web App process (w3wp.exe) in an overlapped recycling manner. Similar to Costco registers where they open new lane for check out before closing the old one. If you happen to be in the old one (existing requests to your web app) you get 90 seconds to finish your business (well not quite like Costco, but you get the point), while all new checkouts (new incoming requests) goes to the new open lane. Thus minimizing the impact down to few handful requests. “Restart Sleep timer” of 90 seconds adds additional layer of protection by waiting for 90 seconds before going to other instances. If you have multiple Web Apps running on same instance then it does not impact other Web Apps. It only restarts Web App you initiated this operation from.  Step 4: Identify highest CPU/Memory consuming Web app(s) within your App Service Plan  Let’s refresh our memory little bit and bring back Resource Health Check Scenario 3.  This blade helps you find out the offending Web App in the App Service Plan. We named this blade “App Service plan Metric per Instance”. It does exactly what it says. This view will help you quickly identify highest CPU/Memory consuming Web App (Site) in your Plan.    Above image indicates that I have 2 Web Apps (Sites) in the App Service Plan. DemoDaas seems to be the one using all CPU and Memory in this case. At the same note, you can also observe that PHPDemo could be taking all CPU and Memory, hence impacting performance for DemoDaas. You can use this view to separate out the culprits from victims and go to Step 3 to click on “Restart Button” for culprit Web App.  Finally, Restart is really not an answer to all the problems and that’s where the Restart button is not that glorious. If HTTP 5xx is because a bug in your application and not the hostile surrounding it found itself in, then restarts are not really going to help. This is where we move to next Step.  Step 5: “Check out the application event logs  to understand the potential root cause”  This is really old school event viewer logs. The beauty of this feature here is that, these logs are aggregated across multiple instances (if you have multiple instances) into single view. You can filter them per instance or other attributes of your choice. It only contains logs are that specific to this Web App and it’s life cycle, so they are pre filtered for your need.   Step 6: “Enable FREB Logging” OR “Trace source of failure using Failed Request Tracing  feature”  I call step as Peeling the Onion step. This step will help you identify source of HTTP 5xx errors or Slow Performance. It won’t really tell you exact root cause (unless you are the developer who check-in had the bug then knowing the source is usually enough). Please watch this short video by Felipe Barreiros that explains the feature. Recommended documents, Profilers like App Insight, New Relic etc.  It finally provides links to some recommended documentations to will help peel the onion even further. Application bug that are easily reproducible  are best root caused using some sort of profiler or remote debugging inside stage/QA environment. Need help?  If none of above helped and you want to engage Microsoft Azure Support team then journey begins by clicking on open a Support request.    Do try out other common scenarios and let us know the feedback by simply clicking on Feedback smiley at the top of the blade.       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/05/18/Azure-App-Service-Web-App-troubleshooting-blade-and-tools.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Deploying Azure Web App Certificate through Key Vault",
        "excerpt":"      akurmi     5/24/2016 10:48:12 AM     Introduction  As part of App Service Certificate (ASC) offering, we now support certificate deployment through Azure Key Vault (AKV). ASC stores the private certificate into a user provided Key Vault Secret (KVS). When an ASC is deployed into a Web App, Web App Resource Provider (RP) actually deploys it from the KVS associated with ASC. Essentially, ASC and Web App are loosely connected through Azure Key Vault. If you manually upload a private certificate into a KVS then you can use the same feature for deploying your own certificate into Web App through AKV. Prerequisites  In order to use this feature, first you need an Azure Key Vault. This Key Vault needs to be in the same subscription as your web app but it need not be in the same region as your Web App. Web App doesn’t have a runtime dependency on Key Vault. When you deploy a certificate, Web App RP reads it from the KV and caches it in its management database. It need not even be in the same resource group. If you don’t have a KV then you can use the following PowerShell command to create a new one: New-AzureRmKeyVault -VaultName akurmitestvault -ResourceGroupName keyvaulttestrg -Location \"eastus2\" -Sku standard By default, the Web App RP doesn’t have access to customer KV. In order to use a KV for certificate deployment, you need to authorize the RP by executing the following PowerShell command: Set-AzureRmKeyVaultAccessPolicy -VaultName akurmitestvault -ServicePrincipalName abfa0a7c-a6b6-4736-8310-5855508787cd -PermissionsToSecrets get The RP requires read access to KV. ‘abfa0a7c-a6b6-4736-8310-5855508787cd’ is the RP service principal name and it remains same for all Azure subscriptions. Note for Azure Gov cloud environment you will need to use '6a02c803-dafd-4136-b4c3-5a6f318b4714' as the RP service principal name in the above command instead of ‘abfa0a7c-a6b6-4736-8310-5855508787cd’ .  Last thing you need is a KVS that contains the PFX certificate you would like to deploy. Before deploying a certificate, the RP performs the following checks on KVS:  It actually contains a PFX certificate that’s not password protected Content type of the secret should be ‘application/x-pkcs12’  You can use the following PowerShell snippet to upload a PFX certificate from your machine into a Key Vault secret: $pfxFilePath = \"F:\\KeyVault\\PrivateCertificate.pfx\" $pwd = \"[2+)t^BgfYZ2C0WAu__gw[\" $flag = [System.Security.Cryptography.X509Certificates.X509KeyStorageFlags]::Exportable  $collection = New-Object System.Security.Cryptography.X509Certificates.X509Certificate2Collection   $collection.Import($pfxFilePath, $pwd, $flag)  $pkcs12ContentType = [System.Security.Cryptography.X509Certificates.X509ContentType]::Pkcs12  $clearBytes = $collection.Export($pkcs12ContentType)  $fileContentEncoded = [System.Convert]::ToBase64String($clearBytes)  $secret = ConvertTo-SecureString -String $fileContentEncoded -AsPlainText –Force  $secretContentType = 'application/x-pkcs12'  Set-AzureKeyVaultSecret -VaultName akurmitestvault -Name keyVaultCert -SecretValue $Secret -ContentType $secretContentType # Change the Key Vault name and secret name Deploying Key Vault Certificate into Web App  After completing all prerequisites, now we are ready to deploy the certificate into a Web App. Currently, Azure portal doesn’t support deploying external certificate from Key Vault, you need to call Web App ARM APIs directly using ArmClient/Resource Explorer/Template Deployment Engine. I will be using ARMClient for the rest of this blogpost. You can also use Resource Explorer to do everything described below.  We need to find the resource group for certificate resource before calling the ARM APIs as it ideally we should use App Service Plan’s resource group, you can find this from ‘serverFarmId’ property of the site resource: ARMClient GET /subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/Default-Web-EastAsia/providers/Microsoft.Web/sites/appservicecertificatedemo?api-version=2016-03-01 …. {   \"id\": \"/subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/Default-Web-EastAsia/providers/Microsoft.Web/sites/appservicecertificatedemo\",   \"name\": \"appservicecertificatedemo\",   \"type\": \"Microsoft.Web/sites\",   \"location\": \"East Asia\",   …     \"serverFarmId\": \"/subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/Default-Web-EastAsia/providers/Microsoft.Web/serverfarms/appservicecertificatedemoplan\",     ….   } } Also note the following properties from this response:  Location since certificate resource needs be created in the same location as server farm. ServerFarmId as it would be required to create certificate resource. We would also use the resource group name specified in this resource id.  We also need Key Vault resource URI to deploy the certificate. You can get this value by executing the following PowerShell command: Get-AzureRmKeyVault -VaultName akurmitestvault Vault Name                       : akurmitestvault Resource Group Name              : keyvaulttestrg Location                         : eastus2 Resource ID                      : /subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/keyvaulttestrg/providers/Microsoft.KeyVault/vaults/akurmitestvault Vault URI                        : https://akurmitestvault.vault.azure.net/ ... Once you have these values, you can use the following ARMClient command to upload the certificate into your Web App. Note that in order to call this API, the caller needs to have write access to the Key Vault account specified in the request body. ARMClient.exe PUT /subscriptions/&lt;Subscription Id&gt;/resourceGroups/&lt;Server Farm Resource Group&gt;/providers/Microsoft.Web/certificates/&lt;User Friendly Resource Name&gt;?api-version=2016-03-01 \"{'Location':'&lt;Web App Location&gt;','Properties':{'KeyVaultId':'&lt;Key Vault Resource Id&gt;', 'KeyVaultSecretName':'&lt;Secret Name&gt;', 'serverFarmId':'&lt;Server Farm (App Service Plan) resource Id&gt;'}}\" ARMClient.exe PUT /subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/Default-Web-EastAsia/providers/Microsoft.Web/certificates/keyvaultcertificate?api-version=2016-03-01 \"{'Location':'East Asia','Properties':{'KeyVaultId':'/subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/keyvaulttestrg/providers/Microsoft.KeyVault/vaults/akurmitestvault', 'KeyVaultSecretName':'keyVaultCert', 'serverFarmId': '/subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/Default-Web-EastAsia/providers/Microsoft.Web/serverfarms/appservicecertificatedemoplan'}}\" ---------- Request -----------------------  PUT /subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/Default-Web-EastAsia/providers/Microsoft.Web/certificates/keyvaultcertificate?api-version=2016-03-01 HTTP/1.1 Host: management.azure.com …. ---------- Response (2997 ms) ------------ … {   \"id\": \"/subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/Default-Web-EastAsia/providers/Microsoft.Web/certificates/keyvaultcertificate\",   \"name\": \"keyvaultcertificate\",   \"type\": \"Microsoft.Web/certificates\",   \"location\": \"East Asia\",   \"tags\": null,   \"properties\": {     \"friendlyName\": \"\",     \"subjectName\": \"appservicecertificatedemo.com\",     \"hostNames\": [       \"appservicecertificatedemo.com\"     ],     \"pfxBlob\": null,     \"siteName\": null,     \"selfLink\": null,     \"issuer\": \"appservicecertificatedemo.com\",     \"issueDate\": \"2016-05-02T21:09:24-07:00\",     \"expirationDate\": \"2017-05-02T00:00:00-07:00\",     \"password\": null,     \"thumbprint\": \"F454D4277D449D8CD2384B63D7AA2F2F7F3766E4\",     \"valid\": null,     \"toDelete\": null,     \"cerBlob\": null,     \"publicKeyHash\": null,     \"hostingEnvironment\": null,     \"hostingEnvironmentProfile\": null,     \"keyVaultId\": \"/subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourcegroups/keyvaulttestrg/providers/microsoft.keyvault/vaults/akurmitestvault\",     \"keyVaultSecretName\": \"keyvaultcert\",     \"webSpace\": \"eastasiawebspace\",     \"tags\": null   } } After executing this command, the certificate would be listed under ‘Custom Domains and SSL’ blade in Azure portal. Now you can use this certificate to create SSL bindings just like a regular certificate as described in this article. You can also use the following ARMClient command to create SSL binding for custom hostname ‘appservicecertificatedemo.com’. If the custom hostname you want to use in this call is not already added to the website, then you should also create the DNS records required for verification as described  here . ARMClient.exe PUT /subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/Default-Web-EastAsia/providers/Microsoft.Web/sites/appservicecertificatedemo/hostnameBindings/appservicecertificatedemo.com?api-version=2016-03-01 \"{'Location':'East Asia','properties':{'sslState':'SniEnabled','thumbprint':'F454D4277D449D8CD2384B63D7AA2F2F7F3766E4'}}\" …  {   \"id\": \"/subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/Default-Web-EastAsia/providers/Microsoft.Web/sites/appservicecertificatedemo/hostNameBindings/appservicecertificatedemo.com\",   \"name\": \"appservicecertificatedemo/appservicecertificatedemo.com\",   \"type\": \"Microsoft.Web/sites/hostNameBindings\",   \"location\": \"East Asia\",   \"tags\": null,   \"properties\": {     \"siteName\": \"appservicecertificatedemo\",     \"domainId\": null,     \"azureResourceName\": \"appservicecertificatedemo\",     \"azureResourceType\": \"Website\",     \"customHostNameDnsRecordType\": \"A\",     \"hostNameType\": \"Managed\",     \"sslState\": \"SniEnabled\",     \"thumbprint\": \"F454D4277D449D8CD2384B63D7AA2F2F7F3766E4\"   } }  … If you want to create an IP-based SSL binding instead of SNI then replace ‘SniEnabled' with ‘IpBasedEnabled’ in the ARMClient command. You can also access this certificate from your Web App once it’s uploaded instead of creating SSL binding as described in this blog. Rotating Certificate  Once a certificate has been deployed through KVS, follow these steps to rotate it:  Update the KVS with a new certificate Call the Create Certificate API again with the same body. This would update the certificate resource and migrate all Web Apps that are using it to the new certificate The Web App RP has a batch job that periodically syncs all Web App certificate resources with the associated Key Vault secret so if you don’t call the Create Certificate API after updating the KVS, then this periodic job would eventually migrate the Web Apps to the new certificate.  Deploying other secrets from Key Vault  You may ask, deploying a certificate from KVS is fine. But what about deploying other secrets from KV such as connection strings? Currently, our platform only supports certificate deployment through Key Vault. You can however, use this feature and write some custom code to deploy generic Key Vault secrets into your Web App. Say your application requires a symmetric encryption key and a SQL connection string. You can follow these steps to deploy your app secrets through Key Vault:  Store the connection string and symmetric key in a Key Vault as individual secrets Create a self-signed certificate and authorize it to read Key Vault Secrets as described here Store this certificate in the Key Vault Deploy the certificate through KVS and create the required App Setting so that it would be available locally for your Web App to use In the Application_Start event, use this certificate to read secrets from Key Vault and update web.config if required  ARM Template to deploy and Assign KV Certificate  You can use the following ARM template to deploy a certificate through KVS and create SSL bindings for a custom hostname: https://azure.microsoft.com/en-us/documentation/templates/201-web-app-certificate-from-key-vault/        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/05/24/Deploying-Azure-Web-App-Certificate-through-Key-Vault.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Introducing Failure History (appLens) for Azure App Service Web App",
        "excerpt":"      Apurva Joshi (AJ)     6/2/2016 2:36:18 PM  Why was my Web App down?” is the million-dollar question that usually follows with more questions than answer, for example: “Was it cloud provider issue?” “Was it a deployment I rolled out?” “Was it just abnormal increase in traffic?” etc. Getting to the bottom of the issue requires tedious activities like pulling off few logs, aligning them with correct times or even calling Support for help, and this is just first layer of investigation a.k.a “Isolation” or “Peeling the onion”.  This process should not take hours and we agree! Introducing Failure History (appLens) for Azure App Service Web App: A tool to visualize various data points in few seconds!  What is Failure History (appLens)?  Let me start with little background on the project. Project’s code name is MDH (Make David Happy). David is our rock star engineer (@Lamboin) who spends his day working on customer reported issues. He is the one who tries to answer the million-dollar question for our customers (“Why was my Web App down?”). We watched him pull variety of logs, overlay them and then align the time frames to get the 1st level of isolation. This process was MDS (Making David Sad), and that was one of the inspirations to kick start this project.  Failure History (appLens) is an attempt to solve problem described above. It is self-service RCA tool that helps you visualize variety of data points in your web app life cycle in matter of seconds. This visualization helps answer the questions that usually follow our million-dollar question. Let’s see how it works  Failure History (appLens) can be accessed from “Settings” blade for your Web App.    With current release Failure History (appLens) focus on 3 core data points, which are,  Availability Requests/Failures Deployments  Let’s drill down on each of them with a real life examples,  Availability  This an overlay chart of 2 distinct data points, Organic availability and Container Health (Canary Web App).  Organic availability is an aggregated data points of successful HTTP requests vs. Failed HTTP requests to your web app. On the other hand Container Health (Canary Web App) is an aggregated data points of successful HTTP requests vs. Failed HTTP requests to a static page that resides inside same VM (container) as your web app. Both of them are weighted number in percentage. To learn more about the Canary Web App, please read “Resource Health Check” section of my previous blog.  I call this chart “Is it me? vs. Is it you?” chart. This literally is best way to isolate application issues vs. platform issues. This chart tries to answer “Was it cloud provider issue?” question.  If you see Organic availability chart taking a dip while Container Health chart is at 100% then it surely is an application issue. If you see Organic availability chart taking a dip as well as Container Health chart taking a dip then it is most likely platform issue (App Service issue). The reason I say “most likely” is because, a bad web app in app service plan can potentially freeze the container and cause Container health chart to take a dive.  NOTE: To see individual charts at appropriate scale I recommend you filter out an individual graphs by selecting them using radio buttons.  Canary Web App concept is NOT applicable to FREE and SHARED web apps and hence that data will be missing for them. Example Scenario 1: Organic availability and Canary Health taking dip due to platform issue   Example Scenario 2: Organic availability and Canary Health taking dip due to high load freezing VM   Requests/Failures  This is an aggregated data points of total incoming HTTP requests vs. Failed HTTP requests to your web app. This chart can be used to answer “Was it just abnormal increase in traffic?” question. If you see drop in Organic availability chart (right above this chart) following large increase in Total incoming HTTP requests (HTTP Requests counter) then you can conclude that downtime could be related to increase in traffic and maybe I should consider turning on Auto Scale. You can also use this chart to answer “What % of my traffic was failing?” question.  NOTE: To see individual charts at appropriate scale I recommend you filter out an individual graphs by selecting them using radio buttons Example Scenario 3: Organic availability taking dip due to increased traffic (need to scale out)    Deployments  This is simple data point indicating time frames when you or someone in your organization did deployment to your web app. This chart tries to answer “Was it a deployment I rolled out?” question.  NOTE: This only shows deployments done via web deploy or Kudu endpoint. It does not cover deployments done using FTP.  This is a great data point to co-relate with availability charts and see if Organic availability tanked right after the deployment? This way you can be sure if availability drop is related to your deployment or not. Example Scenario 4: Organic availability taking dip due to bad deployment    Finally, few disclaimers for this version of Failure History (appLens)  Failure History (appLens) data is at least 15 minutes behind. For issues that are currently happening and you need help then please use our troubleshoot blade. Failure History (appLens) data can go back 7 days to RCA (root cause analysis) issues that happened in past Failure History (appLens) defaults to UTC time      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/06/02/Introducing-Failure-History-(appLens)-for-Azure-App-Service-Web-App.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Updates to WebJobs Portal experience",
        "excerpt":"      Chris Anderson (Azure)     6/6/2016 11:00:26 AM  We've recently made updates to the WebJobs Portal experience in the Azure Portal designed to make it easier to set up a scheduled triggered WebJob, access the trigger URL for triggered WebJobs, and other operations like viewing your logs. Creating a scheduled WebJob    As you can see in the screenshot, to create a scheduled WebJob requires 3 steps, in addition to the usual steps of naming and uploading your code.  Select \"triggered\" as the WebJob type option Select \"Scheduled\" as the WebJob triggers option Add a cron tab expression  To create a scheduled WebJob in the new experience, you just provide a cron tab expression as part of the creation of your triggered WebJob. This will add a schedule property to your setting.job file which Kudu will then use to call your WebJob. Importantly, this requires \"always on\" to be enabled. If you wish to have a triggered WebJob called on a schedule without \"always on\" being required or if the schedule you require is too complicated to be expressed as a cron tab expression, you can continue to use Azure Scheduler by choosing the \"WebHook\" option for \"Triggers\", and then providing the trigger URL to an Azure Scheduler job. This is a departure from how we previously did scheduled jobs, where we'd automatically create a Azure Scheduler job for you. We had a lot of feedback that this wasn't optimal for all scenarios, so we've moved to this new model. Updates to browse WebJobs experience  In addition to the triggered WebJobs updates, we've redone the browse experience to both bring it in line with the other browse experiences in the portal, as well as expose the trigger URL for triggered WebJobs in an easier to access way. One major experience change is that the logs, delete, and run buttons at the top of the blade correspond with the selected row. You can see this experience in the picture below.    We're always looking for more feedback on the WebJobs experience. You can leave feedback on the WebJobs UX experience at our feedback site or in the comments section down below.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/06/06/Updates-to-WebJobs-Portal-experience.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Adjusting the HTTP call with Azure Mobile Apps",
        "excerpt":"      Adrian Hall (MSFT)     6/16/2016 9:00:05 AM  Azure Mobile Apps provides an awesome client SDK for dealing with common mobile client problems - data access, offline sync, Notification Hubs registration and authentication.  Sometimes, you want to be able to do something extra in the client.  Perhaps you need to adjust the headers that are sent, or perhaps you want to understand the requests by doing diagnostic logging.  Whatever the reason, Azure Mobile Apps is extensible and can easily handle these requirements.  Android (Native)   You can implement a ServiceFilter to manipulate requests and responses in the HTTP pipeline.  The general recipe is as follows:   ServiceFilter filter = new ServiceFilter() {     @Override     public ListenableFuture handleRequest(ServiceFilterRequest request, NextServiceFilterCallback next) {          // Do pre-HTTP request requirements here         request.addHeader(\"X-Custom-Header\", \"Header Value\");  // Example: Adding a Custom Header         Log.d(\"Request to \", request.getUrl());                // Example: Logging the request          ListenableFuture responseFuture = next.onNext(request);          Futures.addCallback(responseFuture, new FutureCallback() {             @Override             public void onFailure(Throwable exception) {                 // Do post-HTTP response requirements for failures here                 Log.d(\"Exception: \", exception.getMessage());  // Example: Logging an error             }              @Override             public void onSuccess(ServiceFilterResponse response) {                 // Do post-HTTP response requirements for success here                 if (response != null &amp;&amp; response.getContent() != null) {                     Log.d(\"Response: \", response.getContent());                 }             }         });                  return responseFuture;     } };  MobileServiceClient client = new MobileServiceClient(\"https://xxx.azurewebsites.net\", this).withFilter(filter);   You can think of the ServiceFilter as a piece of middleware that wraps the existing request/response from the server.   iOS (Native)   Similar to the Android case, you can wrap the request in a filter.  For iOS, the same code (once translated) works in both Swift and Objective-C.  Here is the Swift version:   class CustomFilter: NSObject, MSFilter {      func handleRequest(request: NSURLRequest, next: MSFilterNextBlock, response: MSFilterResponseBlock) {         var mutableRequest: NSMutableURLRequest = request.mutableCopy()          // Do pre-request requirements here         if !mutableRequest.allHTTPHeaderFields[\"X-Custom-Header\"] {             mutableRequest.setValue(\"X-Custom-Header\", forHTTPHeaderField: \"Header Value\")         }          // Invoke next filter         next(customRequest, response)     } }  let client = MSClient(applicationURLString: \"https://xxx.azurewebsites.net\").clientWithFilter(CustomFilter())   The .clientWithFilter() method clones the provided client with the filters.    JavaScript &amp; Apache Cordova   As you might exepct given the Android and iOS implementations, the JavaScript client (and hence the Apache Cordova implementation) also uses a filter - this is just a function that the request gets passed through:   function filter(request, next, callback) {     // Do any pre-request requirements here     console.log('request = ', request);                     // Example: Logging     request.headers['X-Custom-Header'] = \"Header Value\";    // Example: Adding a custom here          next(request, callback); }  var client = new WindowsAzure.MobileServiceClient(\"https://xxx.azurewebsites.net\").withFilter(filter);  Xamarin / .NET   The equivalent functionality in the .NET world is a Delegating Handler.  The implementation and functionality are basically the same as the others:   public class MyHandler: DelegatingHandler {     protected override async Task SendAsync(HttpRequestMessage message, CancellationToken token)     {         // Do any pre-request requirements here         request.Headers.Add(\"X-Custom-Header\", \"Header Value\");          // Request happens here         var response = await base.SendAsync(request, cancellationToken);          // Do any post-request requirements here          return response;     } }  // In your mobile client code: var client = new MobileServiceClient(\"https://xxx.azurewebsites.net\", new MyHandler());  General Notes   There are some HTTP requests that never go through the filters you have defined.  A good example for this is the login process.  However, all requests to custom APIs and/or tables get passed through the filters.  You can also wrap the client multiple times.  For example, you can use two separate filters - one for logging and one for the request.  In this case, the filters are executed in an onion-like fashion -  The last one added is the outer-most.  The request goes through each filter in turn until it gets to the actual client, then the response is passed through each filter on its way out to the requestor.  Finally, note that this is truly a powerful method allowing you to change the REST calls that Azure Mobile Apps makes - including destroying the protocol that the server and client rely on.  Certain headers are required for Azure Mobile Apps to work, including tokens for authentication and API versioning.  Use wisely.   (Cross-posted to My Personal Blog)     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/06/16/Adjusting-the-HTTP-call-with-Azure-Mobile-Apps.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Cross-Post App Service Auth and Azure AD B2C",
        "excerpt":"      Chris Gillum (MSFT)     6/22/2016 4:15:21 PM  Note: This post was cross-posted from CGillum Dev Blog.  An exciting new preview feature which was recently added to Azure Active Directory is Azure Active Directory B2C. “B2C” stands for “Business to Consumer” and allows a developer to add user and login management to their application with very little (if any) coding. This also includes login integration with social identity providers like Facebook, Amazon, LinkedIn, etc. Check out their documentation and blog posts for more details. My colleague Swaroop from the Azure AD team also has a nice //build video where you can see it in action.  From my perspective, App Service Authentication / Authorization (Easy Auth) shares a similar goal of B2C, which is to make it really easy to build identity into your application. We saw a great opportunity to make these features work well together, giving you both an identity management system as well as login and OAuth token management without requiring a single line of code.  In this post, I’ll describe how you can use Easy Auth to add Azure AD B2C capabilities to your App Service Web App. Creating an App Service Web App  Hopefully you know how to do this by now. Go ahead and create a web app (or an API/mobile/function app – they all work the same way) and make a note of the URL. For example, when drafting this blog post and walking through the steps, I created https://cgillum-b2c-preview.azurewebsites.net. Use your own web app URL in place of mine wherever you see it in these instructions. However, don’t configure Authentication / Authorization yet. We’ll do that in a later step. Creating the Azure AD B2C Tenant and Application  We don’t currently support an “Express” setup of B2C like we do for classic Azure AD, so these steps will need to be done manually. You can find detailed instructions for this below:  Create an Azure AD B2C tenant Register your application  Note that in step 2, you’ll need to use the https address of the web app you previously created as the Reply URL and you must suffix it with “/.auth/login/aad/callback” (again, in my case this is https://cgillum-b2c-preview.azurewebsites.net/.auth/login/aad/callback). Once this is done, you should have an application in the B2C portal which looks something like the following:    Make a note of the Application Client ID that you see in the Application blade. You’ll need this in a later step. Adding a Sign-Up/Sign-In Policy  For simplicity, we’ll create a single B2C “policy” which allows the user to sign in or sign up if they don’t already have an account. In the portal, this is the Sign-up or sign-in policies selection. Add a new policy (assuming you don’t have one already). The details of the policy don’t matter too much, so I won’t provide any specific guidance here. There are a lot of options, including whether to configure social identity providers. In my case, I set up email login as well as Google and Facebook. To get started quickly, I suggest you use the email sign-up policy. When you’re done, make a note of the Metadata Endpoint for this policy URL which gets generated, like in the screenshot below:    Azure AD B2C supports other policy types as well, but the combination sign-up/sign-in is currently the one best suited for Easy Auth login integration. Configure Easy Auth  Now let’s go back to the web app we previously created. We’ll configure Easy Auth with Azure AD using the Advanced configuration option. The steps are:  In the portal in the context of your web app, click the Settings icon. Set App Service Authentication to On Configure Azure Active Directory Select the Advanced management mode Set the Client ID to be the Application Client ID from before. Set the Issuer URL to be the Metadata Endpoint for this policy URL value that was generated from your sign-in/sign-on B2C policy. Click OK and then the Save icon to save your changes.  Your Authentication / Authorization settings blade should look something like the following:    Now if you navigate to your site, you should see the B2C login page that you configured previously. Depending on how it was configured, you can sign up using social identity credentials or you can sign up using username (or email) and password. You will also be prompted for additional registration information, such as your name, etc (again, all dictated by the policies you configured).  Here is an example of what your initial sign-in page might look like. Notice the link on the bottom of the image which allows users to register:    Below is an example of what your “sign-up” registration page will look like. If you selected the email option, Azure AD B2C will even implement the email verification workflow for you.    That’s it! You’ve now created a skeleton B2C web application that allows users to sign-up and sign-in without writing any code or deploying any databases! I’ve used all the defaults in terms of styling, but Azure AD B2C does allow you to customize the look and feel of these pages to match your own application branding, if you choose. See the B2C UI customization documentation for more information.  Once signed in, you can write code which inspects the inbound HTTP headers and/or the /.auth/me endpoint (both described in my earlier Token Store post) to get more information about the user. If you’re running an ASP.NET application, you can also enumerate the claims on the current ClaimsPrincipal. Specifically, you should be able to see all the claims that you configured in your B2C policy. This is great because you don’t need to provision your own database which contains this information – it’s built into the B2C directory and can be accessed using the features of Easy Auth. Azure AD B2C Social Providers vs. Easy Auth Social Providers  One thing you may have noticed is that there are now two ways to incorporate social logins into your web app: using B2C policies or configuring them directly in the Authentication / Authorization settings. Ideally, there would be just one which is common between the two technologies. Unfortunately we’re not there yet. Until then, here are some important differences between social providers in Azure AD B2C and Easy Auth:  Different identity providers: B2C and Easy Auth support different providers. At the time of writing, B2C supports MSA, Facebook, Google, LinkedIn, and Amazon identities. Easy Auth, however, supports MSA, Facebook, Google, and Twitter. Client-Directed Login: Both B2C and Easy Auth support server-directed social logins where the login flow is controlled by the browser. However, only Easy Auth supports client-directed logins where the login flow is controlled by the client operating system (typically a mobile OS or a JavaScript client). User Claims: B2C provides a somewhat normalized set of user claims for each login. These claims are similar to what you’d see in an ordinary AAD login. The claims are also configurable. With Easy Auth, however, the claims are static and in many cases are different for each identity provider. OAuth Tokens: With Easy Auth, the application code has direct access to the provider-specific OAuth tokens. This is useful if you want to make graph API calls on behalf of the logged-in user (for example, calling the Facebook Graph to post a photo to the user’s timeline). B2C, however, does not expose the provider OAuth tokens to your application code.  If social identity integration is important to your app, then consider these differences very carefully when deciding between the two options. Note that these limitations will certainly change as both Easy Auth and Azure AD B2C evolve over time, hopefully in a way that better aligns them together (this is certainly our goal, internally).  Taking it to the Next Level  This post demonstrated using a single, global B2C policy within a web app in a way that doesn't require any code or database setup. If you are a mobile, API, or SPA app developer, I have written a followup post which goes into more details about how to use code to dynamically select B2C policies, how to set up token refresh, and even included a sample SPA app which demonstrates these capabilities. Check it out in Part 2 of the App Service + Azure AD B2C series.  Note: This post was cross-posted from CGillum Dev Blog.       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/06/22/Cross-Post-App-Service-Auth-and-Azure-AD-B2C.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure App Service and ASP.NET Core",
        "excerpt":"      Daria Grigoriu     6/27/2016 12:00:28 AM  The release of ASP.NET Core 1.0 was announced today! ASP.NET Core 1.0 supports modern web development with its lightweight and modular design. ASP.NET Core is also cross-platform ready and open source. You can read all the details for the release in this announcement. Visual Studio 2015 Update 3 was also announced today with support to build .NET Core apps in Visual Studio. Azure App Service is ready to welcome your ASP.NET Core 1.0 apps. Please see the ASP.NET Core 1.0 announcement for pointers on getting started. Great resources are also available on the ASP.NET Core documentation page. To get started bring your own ASP.NET Core repo or select a sample from Visual Studio. To get started in Visual Studio 2015 navigate to New -&gt; Project -&gt; Web and select an ASP.NET Core sample. Request a Git repo on sample creation.  Create a web app in Azure App Service and configure Local Git as the deployment source as described in documentation here. Copy the Git URL from the Settings -&gt; Properties blade of your app in the Azure Portal. From your ASP.NET Core app Git repo push the content to Azure App Service using the Git URL copied.  The Kudu deployment engine running in Azure App Service is able to detect ASP.NET Core apps and generate a custom deployment script for these apps. If you would like to explore and customize the deployment script generated for Azure App Service deployment you can easily access this script. Navigate to the Kudu SCM management app running alongside the web app from the Tools -&gt; Kudu blade of your app in the Azure Portal. Using the Kudu debug console access D:\\home\\site\\deployments\\tools\\deploy.cmd.   The first step in the deployment script is a NuGet restore with the home drive of the app as the restore location. Restore will be revisited for subsequent deployment only if new dependencies are detected. The next step in the deployment script detects the type of project. If the project originated from Visual Studio and a .sln file is available the deployment engine will run msbuild and then use the new dotnet.exe utility to publish with a no build flag. Otherwise use the new dotnet.exe utility to build and publish. All build actions are completed on the target Azure App Service hosting environment. An alternate Visual Studio deployment option bypassing source control is using the Publish action which will leverage WebDeploy to deploy to Azure App Service instead of leveraging the Kudu deployment engine. With this option build actions would be completed in the source development environment as opposed to build actions being completed in the target Azure App Service hosting environment.  If you don't have an Azure account you can still try ASP.NET Core 1.0 on Azure App Service free of charge and commitment with our Azure App Service free trial.  Looking forward to feedback and questions on the Azure App Service forum.              ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/06/27/Azure-App-Service-and-ASP.NET-Core.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Offline Sync with Azure Mobile Apps and Apache Cordova",
        "excerpt":"      Adrian Hall (MSFT)     6/29/2016 12:21:44 PM  In the past, I've introduced you to a TodoList application built in Apache Cordova so that it is available for iOS, Android or any other platform that Apache Cordova supports.  You can find the QuickStart for Apache Cordova from within the Azure Portal, and read about it within our documentation. Recently, we released a new beta for the Azure Mobile Apps Cordova SDK that supports offline sync, which is a feature we didn't have.  Underneath, the Cordova offline sync functionality uses SQLite - this means it isn't an option at this point for HTML/JS applications.  We'll have to work out how to do this with IndexDB or something similar, but for now that isn't an option without a lot of custom work.  Let's take a look at the differences.  Step 1: New variables   Just like other clients, I need a local store reference and a sync context that is used to keep track of the operational aspects for synchronization:  [javascript]     var client,        // Connection to the Azure Mobile App backend         store,         // Sqlite store to use for offline data sync         syncContext,   // Offline data sync context         todoItemTable; // Reference to a table endpoint on backend [/javascript]  Step 2: Initialization   All the initialization is done in the onDeviceReady() method.  I have to set up a model so that the SQLite database is set up to match what is on the server:  [javascript] function onDeviceReady() {      // Create the connection to the backend     client = new WindowsAzure.MobileServiceClient('https://yoursite.azurewebsites.net');      // Set up the SQLite database     store = new WindowsAzure.MobileServiceSqliteStore();      // Define the table schema     store.defineTable({         name: 'todoitem',         columnDefinitions: {             // sync interface             id: 'string',             deleted: 'boolean',             version: 'string',             // Now for the model             text: 'string',             complete: 'boolean'         }     }).then(function () {         // Initialize the sync context         syncContext = client.getSyncContext();         syncContext.pushHandler = {             onConflict: function (serverRecord, clientRecord, pushError) {                 window.alert('TODO: onConflict');             },             onError: function(pushError) {                 window.alert('TODO: onError');             }         };         return syncContext.initialize(store);     }).then(function () {         // I can now get a reference to the table         todoItemTable = client.getSyncTable('todoitem');          refreshData();          $('#add-item').submit(addItemHandler);         $('#refresh').on('click', refreshData);     }); } [/javascript]  There are three distinct areas here, separated by promises.  The first promise defines the tables.  If you are using multiple tables, you must ensure that all promises are complete before progressing to the next section.  You can do this with `Promise.all()` as an example.  The second section initializes the sync context.  You need to define two sections for the push handler - the conflict handler and the error handler.  I'll go into the details of a conflict handler at a later date, but this is definitely something you will want to spend some time thinking about.  Do you want the last one in to be the winner, or the current client edition to be the winner, or do you want to prompt the user on conflicts?  It's all possible.  Once I have created a sync context, I can get a reference to the local SQLite database table, which is used instead of the `getTable()` call that it replaces.  The rest of the code is identical - I refresh the data and add the event handlers.  Step 3: Adjusting the Refresh   In the past, refresh was just a query to the backend.  Now I need to do something a bit different.  When refresh is clicked, I want to do the push/pull cycle for synchronizing the data.  [javascript] function refreshData() {     updateSummaryMessage('Loading data from Azure');     syncContext.push().then(function () {         return syncContext.pull(new WindowsAzure.Query('todoitem'));     }).then(function () {         todoItemtable             .where({ complete: false })             .read()             .then(createTodoItemList, handleError);     }); } [/javascript]  Just like the initialization, the SDK uses promises to proceed asynchronously.  First push (which resolves as a promise), then pull (which also resolves as a promise) and finally you do EXACTLY THE SAME THING AS BEFORE - you query the table, read the results and then build the todo list.  Seriously - this bit really didn't change.  That means you can add offline to your app without changing your existing code - just add the initialization and something to trigger the push/pull.  Wrap Up   This is still a beta, which means a work-in-progress.   Feel free to try it out and give us feedback.  You can file issues and ideas at our GitHub repository.  Cross-posted to my personal blog      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/06/29/Offline-Sync-with-Azure-Mobile-Apps-and-Apache-Cordova.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Cross-Post Creating a Corporate Wiki in Azure",
        "excerpt":"      Chris Gillum (MSFT)     7/5/2016 9:42:35 AM   Note: This post was cross-posted from CGillum Dev Blog.    Using Azure App Service and Azure Active Directory (AAD), it's possible to create a MediaWiki-based web app for use within your organization with minimal setup and for little or no cost. If you're not familiar with MediaWiki, it's the same open source platform which powers Wikipedia. A few folks within Microsoft surprised me when they created internal wikis using my Easy Auth feature (Authentication / Authorization) so I thought I'd try it out for myself and do a quick write-up on it.  Note that I'm assuming you're already familiar with Azure Active Directory and that you have an Azure Subscription that is associated with your organization. If not, you can find more information here: https://azure.microsoft.com/en-us/documentation/articles/sign-up-organization/. Creating a Web App  The first step is to create a new web app. If you already know how to do this, you can skip this section. The easiest way is to simply navigate to https://portal.azure.com, log in with your Azure Subscription (the one for your organization), and go to New --&gt; Web and Mobile --&gt; Web App. This can also be done using the Azure PowerShell or Cross-Platform CLI Tools, though I won't cover those details here. In this example, let's suppose you named the web app easyauth-wiki (all my examples and screenshots will use this name, but you can replace it with your own app name).  IMPORTANT: If you want to create custom hostnames for your web app, you should set that up now. Enabling AAD Authentication  As I hinted to before, this can be done in the portal via Easy Auth, Azure App Service's integrated authentication feature. For simplicity, we'll use the Express configuration, which automatically creates an AAD application and configures it for your site.  In https://portal.azure.com, select the web app you previously created. Select Settings and navigate down to Authentication / Authorization. Set App Service Authentication to On. Under Authentication Providers, select Azure Active Directory For Management mode, select Express and then click OK. Back in the Authentication / Authorization blade, click Save.    At this point, your new web app is now protected using Azure Active Directory authentication and only users in your organization will be able to access the site. Installing MediaWiki  It's possible to create a MediaWiki app using the Marketplace gallery in the Azure management portal, but for this write-up I'm going to configure it from scratch. This also allows me to use a local SQLite database (instead of paying for a ClearDB MySQL database), which is convenient for testing and is free. If you're expecting your wiki to be used by a large number of users, then you should definitely consider using MySQL instead of SQLite, though I won't cover the MySQL setup here. Download MediaWiki  There are multiple ways to get MediaWiki installed on your web app. I'm going to show you the quick-and-dirty way which doesn't involve any 3rd party tools or source control. Start by navigating to the debug console on the SCM endpoint for the site you just created: https://{appname}.scm.azurewebsites.net/DebugConsole. You can log in using your Azure Subscription credentials if you're not already logged in. Then do the following:  cd D:\\home\\site\\wwwroot del hostingstart.html curl https://releases.wikimedia.org/mediawiki/1.26/mediawiki-1.26.3.tar.gz &gt; mediawiki.tar.gz tar -xzvf mediawiki.tar.gz  The last step might take a while due to the large number of files to extract. This will get all the MediaWiki bits onto your web app. I chose MediaWiki 1.26.3 since that was the latest when I started writing this post, but a newer version is probably available by the time you read this (in fact, 1.27.0 was released shortly after I finished putting together my sample). You can find available versions of MediaWiki on the MediaWiki download page. Be sure to adjust my instructions accordingly depending on which version you decide to use. Configure MediaWiki  Now that MediaWiki is installed, let's configure it with a simple SQLite database backend.  Navigate to https://{appname}.azurewebsites.net/mediawiki-1.26.3/mw-config/index.php Click through the first two pages. In the Connect to database page, select Database type: SQLite and click Continue. Configure your wiki with a name and an administrator account and click Continue. For User rights profile, select Private wiki. Feel free to mess with additional settings on this page as necessary. Under Advanced configuration, you may want to enable PHP object caching for improved performance (internally we use WinCache). When all done, click Continue and then Continue two more times to complete the installation.  At this point, you should see a Complete! screen and a LocalSettings.php file should have been downloaded by your browser. You'll need to upload this file to your MediaWiki installation directory (D:\\home\\site\\wwwroot\\mediawiki-1.26.3) to complete the installation. The easiest way is to simply drag/drop it from your file system to the browser window which shows the Debug Console in the D:\\home\\site\\wwwroot\\mediawiki-1.26.3 directory. Configuring Integrated Authentication  The final required step is to connect the user accounts in your Azure Active Directory to the user accounts in your wiki. This can be done using the Auth_remoteuser extension, as I'll describe here. The great thing about this extension is that it can also be used for on-premises Active Directory, making it very easy to do on-premises to Azure migrations.  Once again, let's take the simple route of installing it directly onto the web app using the Kudu Debug console (otherwise you can follow the instructions on the extension page).  Use cURL to download the extension, e.g. curl https://extdist.wmflabs.org/dist/extensions/Auth_remoteuser-REL1_26-6103d19.tar.gz &gt; Auth_remoteuser-REL1_26-6103d19.tar.gz (the actual URL will be different for you depending on which version is the latest by the time you read this). Extract the downloaded extension into the MediaWiki extensions directory - e.g. tar -xzvf Auth_remoteuser-REL1_26-6103d19.tar.gz -C D:\\home\\site\\wwwroot\\mediawiki-1.26.3\\extensions (again, your exact path may differ). Open your LocalSettings.php for editing (e.g. D:\\home\\site\\wwwroot\\mediawiki-1.26.3\\LocalSettings.php) and make the following changes:  [php] require_once \"$IP/extensions/Auth_remoteuser/Auth_remoteuser.php\"; $wgAuth = new Auth_remoteuser(); [/php] At this point your identity setup is now complete! MediaWiki automatically recognizes your login. No registration required. You can test it by browsing to the root of your MediaWiki installation - e.g. https://{appname}.azurewebsites.net/mediawiki-1.26.3.  The last step is to add a URL rewrite rule to fix your URLs so that you don't need to include the MediaWiki installation directory in your URL. Configuring URL Rewrite Rules (Optional)  The final step involves configuring IIS rewrite rules on your app to remove the installation directory as well as to \"prettify\" your URLs. Without doing this, your URLs are quite ugly and hard to discover.    There are many ways to configure this so consider the below just one of many examples.  In the Kudu console, navigate to D:\\home\\site\\wwwroot. Create a web.config file by entering the following command: touch web.config Open the file for editing and add the following content (replacing the MediaWiki version numbers as necessary):  [xml] &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt; &lt;configuration&gt;  &lt;system.webServer&gt;   &lt;rewrite&gt;    &lt;rules&gt;     &lt;rule name=\"wikiRule1\" stopProcessing=\"true\"&gt;      &lt;match url=\"^wiki/(.*)$\" /&gt;      &lt;action type=\"Rewrite\" url=\"/mediawiki-1.26.3/index.php?title={UrlEncode:{R:1}}\" /&gt;     &lt;/rule&gt;     &lt;rule name=\"wikiRule2\" stopProcessing=\"true\"&gt;      &lt;match url=\"^wiki/$\" /&gt;      &lt;action type=\"Rewrite\" url=\"/mediawiki-1.26.3/index.php\" /&gt;     &lt;/rule&gt;     &lt;rule name=\"wikiRule4\" stopProcessing=\"true\"&gt;      &lt;match url=\"^/*$\" /&gt;      &lt;action type=\"Rewrite\" url=\"/mediawiki-1.26.3/index.php\" /&gt;     &lt;/rule&gt;    &lt;/rules&gt;         &lt;/rewrite&gt;  &lt;/system.webServer&gt; &lt;/configuration&gt; [/xml]  Open the LocalSettings.php file and ensure the following variables are set as shown here (again, you may need to fix up the MediaWiki version number):  [php] $wgScriptPath = \"/mediawiki-1.26.3\"; $wgArticlePath = \"/wiki/$1\"; $wgUsePathInfo = true; [/php]  Now, if you navigate to your site root, you'll get redirected to https://{appname}.azurewebsites.net/wiki and you will see your wiki content. If you click on a page, you'll get a friendly /wiki/PageTitle URL.    This is a big improvement from before! Linking to Anchors (Optional)  It's common for people to create links to certain sections of their wiki pages which contain URL fragments. For example, you might have a URL which looks like /wiki/Main_Page#SectionZ. This ensures that when you share the link with someone and they click it, the browser will automatically scroll to wherever \"SectionZ\" is located on the page. More information on anchors in MediaWiki can be found here.  There is one problem that occurs when you introduce login to your web app, however. If you're familiar with URL fragments (the #SectionZ part of the URL) then you'll know that they are never sent to the server. By default, the Easy Auth module handles the login entirely on the server, so if one of your colleagues clicks on a link to the wiki with a URL fragment in it and they are not yet logged in, the URL fragment will be lost by the time they finish logging in and get redirected back to the page they tried to visit. This is a pain because then they have to manually scroll to find the location that they were supposed to be directly linked to. Note that this problem is not unique to MediaWiki or Easy Auth. There are many other server-side authentication solutions which suffer from the same issue.  One potential workaround is to have people complete the login and then click the link again in order to be navigated to the correct location in the target page. Obviously, this is not a very good solution. Several teams internally at Microsoft have run into this problem and reported it to me, so I thought it would be a good idea to find a way to solve it in a way that didn't require users to know about the problem. To that end, we recently added a new feature in Easy Auth which solves this by using some JavaScript to ensure URL fragments are correctly preserved. Currently it's an opt-in feature which you can enable by setting the WEBSITE_AUTH_PRESERVE_URL_FRAGMENT app setting to true in the Azure management portal.    With this setting in place, when users click on your links which contain URL fragments, the login process will ensure that the URL fragment part of your URL does not get lost in the login redirect process. Let us know in the comments if you found this feature helpful for you, we'd love to know about it. If it helps out enough folks, we'll likely turn on this capability by default.   Note: This post was cross-posted from CGillum Dev Blog.       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/07/05/Cross-Post-Creating-a-Corporate-Wiki-in-Azure.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Create digital experiences with Episerver CMS in Azure",
        "excerpt":"      mksunitha     7/7/2016 8:53:12 PM  Episerver CMS, a platform to build web content management solutions, is now available in the Azure Marketplace.This gives you the ability to get a 30-day free evaluation of Episerver CMS running on Azure App Service. Please note that you will be charged for the Azure resources consumed by the application in your Azure subscription. This solution uses a BOYL (bring your own license) model, to continue its use after the evaluation period you can purchase a license from Episerver website. You can learn more at the Episerver CMS web site.  In this tutorial you'll learn how to create an Episerver CMS application in Azure App Service.  1. Click on this link to open Create workflow to Episerver in the Azure portal. Check out the details on Episerver app in the Azure Marketplace.  2. Enter your Application name and Select your subscription. You can choose to create the application in a new or existing resource group.    3. Click on App Service plan/Location to choose an existing App Service plan or create a new App Service plan as shown in the image below    4. Click on SQL Database to choose and existing or new SQL Azure database. You can create a new database in an existing SQL Azure server if the web app and SQL Azure server are in the same location.    5. Click on Create to start deployment of the Episerver application. You can check the “Pin to dashboard” checkbox to pin the resource group in Azure portal dashboard for easy access.    6. Check for the deployment status, by clicking on notification button as shown below        7. Once the deployment has been completed, you can access the resource group you created. Select your web app and click on Browse to view your web app.    8. The Episerver application installer wizard will walk you through the installation.    9. Once the wizard completes, you can access the CMS in edit mode, by appending /episerver/cms/edit to the site URL. For example, the URL would look like http://episerverapp1.azurewebsites.net/episerver/cms/edit/   10. Note that Episerver CMS is available for a 30-day trial. You will see a message on the web application that it is currently in trial period. Buy Episerver license to continue using the application past the 30-day evaluation period you can   References  Getting started with Episerver Learn how to build complex integration Episerver resources on Github     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/07/07/Create-digital-experiences-with-Episerver-CMS-in-Azure.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Cross-Post App Service Auth and Azure AD Domain Hints",
        "excerpt":"      Chris Gillum (MSFT)     7/13/2016 6:33:50 AM   Note: This post was cross-posted from CGillum Dev Blog.    When creating web, mobile, API, or Function apps for use by members of your organization, it's often the case that you're using Azure Active Directory and you want to remove the option to log in with non-organizational credentials. For example, you want to prevent users from accidentally logging in with MSA credentials (hotmail.com, live.com, outlook.com, etc.). This can be done by leveraging what's known as a domain hint when navigating users to the Azure AD login page.  Domain hints will do two things for you: 1) remove the home realm discovery page from the login flow and 2) ensure that users can't accidentally auto-log into your app using wrong credential types (for example, MSA credentials). More background information on Azure AD's support for domain hints can be found on the Microsoft Enterprise Mobility blog:  https://blogs.technet.microsoft.com/enterprisemobility/2015/02/11/using-azure-ad-to-land-users-on-their-custom-login-page-from-within-your-app/  Vittorio Bertocci also talks about domain hints in his post on Skipping the Home Realm Discovery Page in Azure AD., demonstrating how to use them when using ADAL and the OpenID Connect Middleware to build your web app. In this post, however, I'll describe how enable domain hints when using App Service's integrated Easy Auth feature. Default Login Parameters  Most web apps will want to configure domain hints to be used for all logins. Unfortunately you cannot configure default domain hints in this way using the Azure portal today. Instead, you must use the App Service Management API. Until we get around to building a portal experience, I recommend that most people configure default domain hints in Azure Resource Explorer. This can be done using the following steps:  Search for your web, mobile or API app using the search bar. Alternatively, you can navigate directly to your app if you click on the Resource Explorer link in the tools section of the portal. Under your site node, navigate to /config/authsettings. Click Edit to enable making changes. Set additionalLoginParams to the following (This is a JSON array value): [\"domain_hint=microsoft.com\"] Click the Read/Write button at the top of the page to enable making changes. Click the PUT button to save your changes.  The JSON configuration for your auth settings should look something like the screenshot below. In my case, I specified domain_hint=microsoft.com since the app shown here is intended to be used by Microsoft employees.    Once this is done, users will no longer see the home realm discovery page when logging into the app. Instead, users will be immediately directed to the organizational login page, ensuring they cannot intentionally or accidentally log in with the wrong credentials. Using the Login API  If you're building an app that invokes the built-in /.auth/login/aad REST API, you can alternatively specify domain_hint={domain} as a query string parameter to get the same effect.  For example, if I'm writing a mobile client and using the App Service .NET SDK, I could write the following code to initiate a login using a domain hint for contoso.com.  [csharp]   var user = App.MobileClient.LoginAsync(   MobileServiceAuthenticationProvider.WindowsAzureActiveDirectory,   new Dictionary&lt;string, string&gt;   {     { \"domain_hint\": \"contoso.com\" }   } [/csharp]  Similarly, I could create a login link in a web page using HTML that includes a domain_hint parameter.  [html]&lt;a href=\"/.auth/login/aad?domain_hint=contoso.com\"&gt;Login&lt;/a&gt;[/html]  This allows me to specify login hints without changing the auth settings of the app as I showed in the first part of this post. In theory, this would also allow me to create multiple login links, one for each domain that my Azure AD application supports. Note that if an app is already configured with a default domain hint, the query string parameter will override that default. Conclusion  In conclusion, most single-tenant applications will want to use domain hints to optimize the login experience. These hints allows you to skip the home realm discovery page in the Azure AD login sequence and mitigates the common problem where the browser will try to log into the app using MSA credentials via SSO. Depending on the type of application you are building, you can use either the default login parameter method or you can explicitly specify login hints via the built-in /.auth/login/aad endpoint.   Note: This post was cross-posted from CGillum Dev Blog.       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/07/13/Cross-Post-App-Service-Auth-and-Azure-AD-Domain-Hints.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Implementing Client-side Encryption with Azure Mobile Apps",
        "excerpt":"      Adrian Hall (MSFT)     7/15/2016 11:09:26 AM  Azure Mobile Apps provides an offline sync feature that makes it easy to build mobile apps that work without a network connection. When apps use this feature, end users can still create and modify data, even when the app is in an offline mode. The changes are saved to a local store and can be synced to your Mobile App backend when the app is back online. See Offline Data Sync in Azure Mobile Apps for more details.  Offline sync uses a local store to persist data on the client device, where the specific storage implementation can be customized. The Mobile Apps client SDK provides local stores based on SQLite (Windows, Xamarin, and Android) and Core Data (iOS native).  SQLite does not have any built-in encryption support, but there are a number of extensions that provide encryption. One such extension is the SQLite Encryption Extension (SEE). SEE is an add-on to the public domain version of SQLite and does not require a custom local store implementation.  Note that SEE is not the only encryption option for Mobile Apps; For instance, you can define a local store that uses SQLCipher for encryption.  This sample requires you to purchase a license for SEE.  This is not included as part of the Azure Mobile Apps Client SDK.  In this article I will walk through a sample to show how to create an encrypted local store using SEE in a Xamarin.Android app - this can be done in three parts:  Build the Quickstart for Xamarin.Android and enable offline sync Build sqlite3.dll with SEE for Android Update the Quickstart to use custom version of sqlite3  The Quickstart for Azure Mobile Apps builds a simple task list.  You can follow the Getting Started tutorial for Xamarin.Android and then Enable Offline Sync in your quickstart app. Build SQLite with SEE Support for Android  The SQLite Encryption Extension is a commercial encryption product and you must buy a license for SEE before continuing.  After purchase, you may download the code for building SQLite for Android and build the native SQLite3 library with SEE.  By default, the native library is build for the armeabi platform - common for actual Android devices.  You will need to build the native app for an x86 platform if you wish to run your modified app on the Visual Studio Emulator for Android.  To do this, open a Visual Studio command prompt and do the following: cd SQLite_Android_Bindings\\sqlite3\\src\\main ndk-build.cmd APP_ABI=x86 Adjust the paths above as appropriate for your environment. Once built, you can open your Quickstart project in Visual Studio and copy the generated native library for x86 from SQLite_Android_Bindings\\sqlite3\\src\\main\\libs\\x86 to YourQuickstartProject\\lib\\x86. Finally, update the build action for the copied libsqliteX.so file to be AndroidNativeLibrary:   Build and Run the Quickstart  Before we can build the Quickstart, we need to configure the build environment to include the modified sqliteX DLL instead of the normal sqlite3.dll system library that is a part of the Android platform. Add an app.config file to your project with the following:  &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt; &lt;configuration&gt;     &lt;dllmap dll=\"sqlite3\" target=\"libsqliteX.so\" /&gt; &lt;/configuration&gt;  Any P/Invoke operations that would normally load the sqlite3.dll will now be mapped to load the libsqliteX.so file that we provide. The SQLitePCL library that is used by the Azure Mobile Apps Offline Client SDK uses P/Invoke to call the native methods within sqlite3.dll, so this will now automatically reference the sqliteX library.  This configuration file needs to be included in the APK package. This only happens when the EmbedAssembliesIntoApk is set to true in your csproj file. This property is set to false by default when using a debug build. When debugging the app, ensure you set the EmbedAssembliesIntoApk to true. Edit the csproj file and add the following to it: &lt;EmbedAssembliesIntoApk&gt;True&lt;/EmbedAssembliesIntoApk&gt; It's a good idea to do this edit from a normal text editor and then load it into Visual Studio. For an example, see the sample on GitHub.  We can now create a local encrypted SQLite database protected by a password for use with offline sync. Create a MobileServiceSQLiteStore as normal, but specify a file Uri with a query parameter that includes the password. Here is the modified code that initialized the local store: /// &lt;summary&gt; /// Converts a string to a hex key // &lt;/summary&gt; private string StringToHex(string hexstring)  {      var sb = new StringBuilder();      foreach (char t in hexstring)      {          sb.Append(Convert.ToInt32(t).ToString(\"x\") + \" \");      }      return sb.ToString();  }   private async Task InitLocalStoreAsync()  {      // WARNING: Do not hard code passwords in your application!      var password = \"Hello\";       if (!Utils.MobileService.SyncContext.IsInitialized)      {          // Generate the URI to the offline cache file          var hexkey = StringToHex(password);          var offlineCacheUri = new System.Uri(Path.Combine(ApplicationData.Current.LocalFolder.Path,\"testSee.db\"));          string offlineCache = $\"{offlineCacheUri.AbsoluteUri}?hexkey={hexkey}\";           // Set up the encrypted SQLite Store as normal          var store = new MobileServiceSQLiteStore(offlineCache);          store.DefineTable&lt;TodoItem&gt;();          await Utils.MobileService.SyncContext.InitializeAsync(store);      }       // Synchronize the offline cache with the server      await SyncAsync();  }   Once the local database is created with a password, it is encrypted. If you try to use that database without providing a valid password, it would fail (throwing an Exception) with the error message ‘Error: file is encrypted or is not a database’.  We've created a sample on GitHub that includes a solution for Xamarion.iOS and Universal Windows (UWP). The same technique will also work with Xamarin.Forms applications. Useful links   How to compile and use SEE. Build and use the CLI for SEE for additional options. For example, You can update/remove password for encrypted database using the rekey option. How to Interop with Native Libraries in Xamarin.  Tips  The Android Debug Log shows detailed logs on location of the assemblies being loaded into the application. You can use this to verify the sqliteX that you built is loaded into the app.  For Xamarin.Android, set the build configuration to match the native library architecture. A mismatch in the architecture will cause dll not found errors. Getting in touch  As always, you can ask questions of the team via Stack Overflow or the Azure Forums.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/07/15/Implementing-Client-side-Encryption-with-Azure-Mobile-Apps.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Mobile Supporting IPv6 and the Apple Submission Process",
        "excerpt":"      Adrian Hall (MSFT)     7/18/2016 9:00:26 AM  Apple announced in September 2015 that from the 1st of June, all apps submitted to the iOS App Store for review must support IPv6 only networks.  TL;DR – your app submissions will likely work just fine as long as you are not embedding IPv4 addresses or using IPv4 specific communication methods in your apps.  For more information, keep reading.       Why IPv6  IPv4 address are exhausted, and carriers are deploying IPv6 only which make it critical that our apps continue to work on IPv6 only networks. Fortunately for us, most apps will continue to work on an IPv6 only network without modification.    To ensure your apps continue to work on an IPv6 only work, you'll want to make sure you're using a network library (for example NSUrlSession or CFNetwork). You'll also want to avoid the use of IPv4 APIs and hard-coded IP addresses. Essentially if your app is using a higher level API and framework for the network rather than the IP layer, your app should continue to work on top of either IPv4 or IPv6.  For more information, check out the Apple Documentation.    As part of the carriers upgrade to IPv6, they have deployed both DNS64 and NAT64 on their network which allows IPv6 clients (your app) to communicate with existing IPv4 infrastructure. If we take an App Service running in Azure as an example, it currently supports IPv4, but we still wish to communicate with it on the IPv6 carrier network. When our iOS app attempts to contact the REST endpoint we have set up, it will use a host name rather than a hard-coded IPv4 address. The DNS64 server will synthesize an IPv6 address and pass this back to the client. Any packets get routed to the NAT64 engine, which will then translate IPv6 traffic to IPv4 and vice versa. Through using DNS64 and NAT64, our IPv4 only App Service now appears (to our connecting client) to be an IPv6 service.   Testing   If you wish to test if your app supports IPv6 only networks without submitting your app for review, you can use a handy addition to MacOS network settings. Apple have provided a DNS64 and NAT64 implementation in MacOS 10.11. This can be enabled by option clicking on the Share pane in System Preferences and then option-clicking the Internet Sharing service. After that, you'll see the Create NAT64 Network option appears.    Find out More   iOS developers should take the time to watch Apple's video from WWDC in order to learn more about the new app store requirement to support IPv6. Most developers will not experience any issues with the new requirement as long as they've followed best practices; even if their existing infrastructure has no support for IPv6.      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/07/18/Azure-Mobile-Supporting-IPv6-and-the-Apple-Submission-Process.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Transition from Mobile Services to Mobile Apps Node.js Edition",
        "excerpt":"      Adrian Hall (MSFT)     7/18/2016 1:20:30 PM  We recently announced that Azure Mobile Services will be deprecated and all services will be migrated to Azure App Service. At this point, you will become responsible for the code running your app. You may want to upgrade your site to take advantage of the additional facilities that Azure App Service provides you, such as staging slots and picking the Node version that is run when you run your site.  The Azure Mobile Apps compatibility package allows you to convert older Azure Mobile Services applications written for the Node platform so that they can utilize the latest Azure Mobile Apps Node SDK.  How Does it Work?   The package takes the raw source code from a Node-based Azure Mobile Service and generates the equivalent set of table and custom API definitions that will work with the Azure Mobile Apps Server SDK for Node. You will have a new project at the end that you can deploy as a  new site to Azure App Service. Both platforms offer a similar set of functionality, but with different APIs. The compatibility package maps the Mobile Services API to the newer Mobile Apps API.  The generated app is ready to deploy to an Azure App Service and should work for most applications. It's important to review the code afterwards as some common scenarios (such as authentication) will require specific configuration or code changes in addition to the conversion.  Performing a Conversion   Because the conversion produces a new site, there is a natural process to the conversion. If you run into problems, please get live help - we listen in on Stack Overflow, the Azure Forums and have a Gitter channel for live assistance during normal (West US) working hours.  Note that this process cannot be attempted until AFTER you have migrated the site from Azure Mobile Services to Azure App Service.   Obtain your Azure Mobile Services Scripts   Open the Debug Console in your browser (it's at http://yourMobileService.scm.azure-mobile.net/DebugConsole).  Navigate by clicking on the directory names to site/wwwroot/App_Data/config.  Download the scripts directory in ZIP format by clicking on the download icon next to the folder name.  Create the Azure Mobile App   First, install the compatibility package by executing the following with elevated privileges:  npm i -g azure-mobile-apps-compatibility  This installs a command line utility with the following usage:  scaffold-mobile-app &lt;inputPath&gt; &lt;outputPath&gt;  For example,  scaffold-mobile-app scripts out  This reads the Azure Mobile Service definition from the scripts directory located in the current working directory and creates a directory called out with a scaffolded Mobile App.  Once the app has been created, check the target folder to make sure it contains files for the tables and custom APIs you defined in your mobile service.  Your app is almost ready to deploy!  Deploying and Testing   During deployment, you will need to update your database and create a new App Service, linking the updated SQL database to the new App Service.  Create Database Compatibility Views   Mobile Services created a specific schema to hold the Mobile Services data and had system column names preceded by a double-underscore.  Mobile Apps has changed these requirements.  We can map one to the other using SQL Views.  The scaffolded app includes a SQL script called createViews.sql. This script must be executed against the target database. The connection string for the target database can be obtained from your Mobile Service or migrated Mobile App from the Settings blade under the Connection Strings section. The connection string name is MS_TableConnectionString.   This script creates read / write views in the dbo database schema that map older reserved column names to new column names.  This script can also be obtained from our GitHub repository.  Create the Target Mobile App   Create a new App Service Mobile App using the Azure portal and perform the following tasks:   Take note of the URL for your Mobile App. You will need it later. Configure a data connection that points to the Mobile Service database. Configure push settings to use the same configuration as the Mobile Service.   If you previously used one of the built in authentication providers, there are additional steps that you must take. Read about these changes in the .NET documentation - they are valid to all migrations.  Deploy your new Mobile App   The simplest way to get your app onto Azure is using FTP. The URL, username and password can be obtained from the portal. Before copying the files, you must run npm install in a console window from the output folder created above. Copy the entire contents of the output folder to the site/wwwroot folder of the FTP host.  Alternatively, if you are familiar with git, we recommend you follow publish from source control.  You can also use WebDeploy or hook up continuous deployment.  After you have deployed your app, open your browser and navigate to the URL of your Mobile App. You should see the home page for your app.  Additionally, the Easy Tables and Easy API sections for your app in the portal should now be functional.  Update Your Client   The client application must be updated to use the latest version of the Azure Mobile Apps SDK. In many cases, this may simply be a matter of updating the Azure Mobile Apps libraries to the latest version.  Note that some libraries changed names:   The C#/.NET/Xamarin library is now Microsoft.Azure.Mobile.Client The JavaScript library is now azure-mobile-apps-client The Apache Cordova library is now cordova-plugin-ms-azure-mobile-apps   However, in some cases, additional code changes may be required.  You also need to update the URL that is passed to the constructor of the Mobile App client object to the URL of the mobile app you created above and remove the API Key, which is no longer required.  Each client SDK has a new HOWTO document to aid in development:   C#/.NET/Xamarin JavaScript Apache Cordova iOS: Swift or Objective-C Android: Java   Consult these documents for your client platform if you run into problems with the client SDK.  Troubleshooting   If you run into a problem, you should debug the issue just like you would any other development issue.  Generally, this means you should enable diagnostic logs for your app.  Explicitly, you should turn on Application Logs (Filesystem) to see most of the issues with the code.  Here are some of the more common errors you may encounter with their solutions.  Cannot find module 'xxx'   Dependencies on external modules such as async have not been included by default to reduce the size of the application. If you are using any external modules, you will need to install them by opening a browser to https://_yourMobileService_.scm.azurewebsites.net/DebugConsole , navigating to the site/wwwroot folder and executing:  npm i &lt;module name&gt;  You can also add an options @&lt;version&gt; - this is recommended to install the same package versions that were used in your original Mobile Service.  The table 'xxx' does not exist   The getTable function is now case-sensitive.  Check to ensure the appropriate case is being used.  Invalid column name '__createdAt'   The double underscore notation for createdAt, updatedAt, version and deleted columns have been removed. You will need to update any explicit column references manually within your code.  The SQL script createViews.sql will take care of these columns in your database.  Can't set headers after they are sent   Calling request.respond or response.send more than once per request will result in this error. Older versions of the web framework used by Mobile Services, express, allowed this behavior, but the current version does not.  Use the generated stack trace to identify the offending module and change the code to ensure these functions are only called once.  Error in sideband demultiplexer   This usually indicates a corrupt git repository. You can fix this by running:  git remote set-head origin master  This assumes your remote repository uses the default name origin and the branch you are pushing to is called master.  Caveats   There are a couple of areas that require additional changes. For example, if you are using Mobile Services authentication, you need to update redirect URLs on your identity provider as they have changed. Read this article for more information. Custom authentication (i.e. not using an identity provider such as facebook) should not be affected.  Other issues   Our github repository will be updated with new troubleshooting steps as common cases are uncovered.  It's important to note that this package is experimental. We need your help to make the experience as seamless as possible. Join the conversation on gitter and let us know about your experiences.  Post any issues within our GitHub repository, and ask questions on Azure Forums or Stack Overflow.       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/07/18/Transition-from-Mobile-Services-to-Mobile-Apps-Node.js-Edition.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Upgrading Python on Azure App Service",
        "excerpt":"App Service is Microsoft Azure’s platform-as-a-service offering for web apps, whether they are sites accessed through a browser, REST APIs used by your own clients, or event-triggered processing. Many of you are already using Python to implement your apps on App Service (and rightly so!).   When we first enabled Python on App Service we wanted to make it as easy as possible. So we went and installed the latest available versions on every host, so that you could just assume it was going to be present. Unfortunately, this did not turn out to be a great long-term solution.   Happily though, we found a better approach! While it isn’t quite polished yet, we know that people want the solution now. Rather than waiting until we’ve finished all the scripts, documentation, videos etc. that will come in the future, we decided to give out early details in this blog post.   This post will start by outlining some of the problems, why we couldn’t do the “obvious” fix, and how to use the new approach. Feedback is welcome as we continue to improve the user experience around it, but hopefully the information here will be sufficient to get everyone moving again.   What went wrong?   Having Python installed on every App Service machine sounds like a great idea, right? And so we went ahead and installed the most up-to-date Python 2.7.8 and Python 3.4.1… oh yeah, they’re not the latest versions of Python any more.   The obvious solution here is to simply upgrade Python so that everyone has the latest improvements, bug and security fixes. But unfortunately, there were changes made between 2.7.8 and 2.7.9 and between 3.4 and 3.5 that meant upgrading would break existing users. Stability of the platform had to outweigh these improvements, so we were stuck. (The SSL improvements in 2.7.9 had workarounds that customers could implement themselves, so weren’t sufficient to justify breaking other customers.)   We had also chosen to install the 32-bit versions of Python. This adds an extra restriction on users who may have been deploying pre-built binaries targeting 64-bit versions, or other micro versions of Python.   Since users want to be able to choose their version of Python, the fix is to let everyone choose. We also wanted to improve package installation and make it easier to avoid IIS details.   Choosing your version of Python   Azure App Service has support for site extensions, which allow you to add features to your site. These can be deployed as part of an ARM template, using a REST API, or manually through the portal. The main part of our improved Python support is a set of site extensions containing the Python runtime, broken down by the exact version so that you can choose which one to install. (Obviously we recommend using the latest Python 3 version, but when you need an older version, you really need it so you can choose it.)   If your site is already deployed and running, it is easiest to install through the portal. Navigate to your App Service blade, select Tools, Extensions and then Add.      From the list of extensions, scroll down until you spot the Python logos, then choose the version you need. (Improvements to this UI are coming in the future; right now you just need to search manually.)   However, if you are deploying your site with an Azure Resource Manager (ARM) template, it is much simpler to add the site extension as a resource. It will appear as a nested resource of your site, with a type siteextensions and the name can be found from siteextensions.net.   For example, after adding a reference to python352x64, your template may look like this:   \"resources\": [     {       \"apiVersion\": \"2015-08-01\",       \"name\": \"[parameters('siteName')]\",       \"type\": \"Microsoft.Web/sites\",       ...       \"resources\": [         {           \"apiVersion\": \"2015-08-01\",           \"name\": \"python352x64\",           \"type\": \"siteextensions\",           \"properties\": { },           \"dependsOn\": [             \"[resourceId('Microsoft.Web/sites', parameters('siteName'))]\"           ]         },       ...   Regardless of how you choose to install the site extension, after installing you will have a version of Python installed at a path like C:\\home\\Python35\\python.exe (see the description of the extension for the exact path).   Configuring your site   Once Python is installed on your site, you will need to reference it. Previously our tooling has been able to do this automatically, since we knew where Python was, but now the control is in your hands. Luckily, configuring your site is mostly a matter of knowing where to find python.exe.   Since App Service apps all run behind IIS, the configuration file is known as web.config (if you’re used to httpd servers, web.config is the equivalent of .htaccess), and there are two request handlers available: FastCGI, and Http Platform.   Using the FastCGI handler   FastCGI is an interface that works at the request level. IIS will receive incoming connections and forward the request details to a WSGI app running in one or more persistent Python processes. The wfastcgi package is pre-installed and configured, so you can easily enable it.   Your web.config configuration should include the following:   &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt; &lt;configuration&gt;   &lt;appSettings&gt;     &lt;add key=\"PYTHONPATH\" value=\"D:\\home\\site\\wwwroot\"/&gt;     &lt;add key=\"WSGI_HANDLER\" value=\"app.wsgi_app\"/&gt;     &lt;add key=\"WSGI_LOG\" value=\"D:\\home\\LogFiles\\wfastcgi.log\"/&gt;   &lt;/appSettings&gt;   &lt;system.webServer&gt;     &lt;handlers&gt;       &lt;add name=\"PythonHandler\" path=\"*\" verb=\"*\" modules=\"FastCgiModule\" scriptProcessor=\"D:\\home\\Python35\\python.exe|D:\\home\\Python35\\wfastcgi.py\" resourceType=\"Unspecified\" requireAccess=\"Script\"/&gt;     &lt;/handlers&gt;   &lt;/system.webServer&gt; &lt;/configuration&gt;   The value for PYTHONPATH may be freely extended, but must include the root of your website. WSGI_HANDLER should be updated to point to a WSGI app importable from your website. WSGI_LOG is optional but recommended while debugging your site. All app settings are made available to the app as environment variables.   The path to python.exe and wfastcgi.py will need to be customized if you are using a different version of Python. See the description of the site extension to find out where it will be installed and update these paths accordingly.   Using the Http Platform handler   &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt; &lt;configuration&gt;   &lt;system.webServer&gt;     &lt;handlers&gt;       &lt;add name=\"PythonHandler\" path=\"*\" verb=\"*\" modules=\"httpPlatformHandler\" resourceType=\"Unspecified\"/&gt;     &lt;/handlers&gt;     &lt;httpPlatform processPath=\"D:\\home\\Python35\\python.exe\"                   arguments=\"D:\\home\\site\\wwwroot\\runserver.py --port %HTTP_PLATFORM_PORT%\"                   stdoutLogEnabled=\"true\"                   stdoutLogFile=\"D:\\home\\LogFiles\\python.log\"                   startupTimeLimit=\"60\"                   processesPerApplication=\"16\"&gt;       &lt;environmentVariables&gt;         &lt;environmentVariable name=\"SERVER_PORT\" value=\"%HTTP_PLATFORM_PORT%\" /&gt;       &lt;/environmentVariables&gt;     &lt;/httpPlatform&gt;   &lt;/system.webServer&gt; &lt;/configuration&gt;   As for the previous configuration, the path to python.exe may need to be customized depending on the version of Python you are using. See the description of the site extension to find out where it will be installed and update these paths accordingly.   Arguments may be freely customized for your app. The HTTP_PLATFORM_PORT environment variable contains the port your local server should listen on for connections from localhost. In this example, I created another environment variable SERVER_PORT that isn’t really required. You can add or remove environment variables as necessary for your app.   Installing packages   Once you’ve installed Python onto your server, the next thing you’ll need is any packages your app depends on. This is the area we’re currently focusing on, so expect new announcements in the coming weeks as we simplify this process, but here are a few ways you can do it right now.   Kudu Console   Even after you have installed your packages, you will likely find this is an invaluable debugging tool. Once your website is created, for example at http://trywebsites.azurewebsites.net/, you can get into the Kudu console by adding .scm after your site name: https://trywebsites.scm.azurewebsites.net/. You will need to log in with your Azure account (so that example URL probably isn’t going to work) but can then directly access files and run commands on your site. The Kudu documentation contains the most up-to-date information about the console.      Once you are in the console and have added the site extension, you can freely install any packages you like (well, almost - more on this later). The one trick is that you’ll have to specify the full path to Python. We also suggest including a requirements file as part of your site so that it is easy to reproduce the set of packages both locally and on the server. For example:   D:\\home&gt;D:\\home\\Python35\\python.exe -m pip install --upgrade -r D:\\home\\site\\wwwroot\\requirements.txt   There’s no C compiler on your web server, so if any packages have native extension modules you’ll need to install the wheel. Many popular packages provide their own wheels, so installing them will work just fine, but for those that don’t you will need to use pip wheel [package] on a development machine and then upload the wheel with your site. (The end of our page on managing requirements shows an example.)   Kudu REST API   If you don’t want to manually log into the Kudu portal to install packages, you can also trigger these commands remotely via the REST API. The command command behaves identically to typing into the console, except you can POST the command to https://yoursite.scm.azurewebsites.net/api/command.   See the documentation for other commands and information about authentication. There is a helper class in this sample project that obtains the credentials using the Azure SDK for Python and will let you submit the same command as above via the exec() method. (Remember how I mentioned that we’re working on better ways to do all of these? Yep, there’s a lot of manual work required right now, but soon we’ll have install-on-deploy automation available.)   Vendor everything   A final option for deploying your packages is to “vendor” them. This essentially means copying the entire library into your own source code and copying it as part of your site. Depending on how many dependencies you have and how frequently you update them, this may be the easiest way to get a working deployment going. The one catch is that you need to ensure that you copy libraries from a version of Python that precisely matches the version you are installing on the server. If you take extensions from Python 3.5 32-bit and try and use them with 64-bit Python, you will see obscure import errors after deployment. However, as the versions of Python we make available on Azure are exactly the same as those released on python.org, you can easily obtain a compatible version for local development.   Aside: what about virtual environments?   While we recommend working in a virtual environment locally, to ensure you fully understand the dependencies needed by your site, once you have published there should not be multiple projects using the same Python install at all. (If there are, you really want to avoid having conflicting dependencies!) As a result, it’s easier and more efficient to just install into the main Python directory.   Summary   We hope you appreciate this information at this time. While there is still a lot of ongoing work to improve Python on Azure App Service, we have reached a point where there is enough for people to benefit from being able to use parts of it. In particular, we know that many of you will be unblocked by the new ability to install newer versions of Python onto your app service servers. &lt;If you have any feedback, suggestions, or want to deploy or manage your web site in a way you think we may not have considered, feel free to leave a comment on this post or email python@microsoft.com directly. While we can’t respond to every piece of feedback or need for assistance (we suggest creating support requests for those), we’re happy to hear what you need.  ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/08/04/Upgrading-Python-on-Azure-App-Service.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Introducing a Quicker Mobile App Quickstart",
        "excerpt":"      Adrian Hall (MSFT)     8/11/2016 2:00:06 PM  The traditional Azure Mobile Apps process has been somewhat long winded.  Aside from creating a Mobile App, you have to create a SQL Azure server and database, link the two up, deploy some code, and then you are ready to actually develop a mobile client.  This can take 15 minutes even in the best case scenario.  Today, we are introducing a new method of creating a Mobile backend via the Mobile Apps Quickstart.  The Mobile Apps Quickstart is a pre-configured mobile backend suitable for development purposes and learning about mobile backends.  It provides a base mobile backend using a SQLite database for data storage.  This means that you can immediately start using it without hooking up an external database.  You can still access features like Easy Tables and Easy APIs, hook up authentication and push notifications - in fact, anything that does not rely on a SQL Azure instance.  Setting up a Mobile Apps Quickstart is a breeze.  Log into the Azure Portal.  Click on the big + NEW in the top left corner, and enter \"Mobile Apps Quickstart\" in the search box:    Click on the **Create** button at the bottom of the blade.    The App name, Subscription, Resource group and App Service plan/Location fields are identical to those required by the standard Mobile App flow.  Just fill in the information.  However, ensure you always check the **Pin to dashboard** box.  Finally, click on **Create**.    The deployment takes approximately 3-4 minutes and is ready for going through one of the client walk-throughs immediately after the deployment is completed.  Along with the quicker deployment, you also get access to a new simplified management experience.  Clicking on the dashboard app tile (the one that you pinned) brings you to a new blade:    You can always get to the underlying Mobile App (click on the middle card).    Limitations   Because this template provides a SQLite database, it does not scale.  Do not run more than one instance of the Mobile App.  If you wish to run this Mobile App in a scalable manner, then connect a SQL Azure database instance through the **Data Connections** blade.  The  Mobile Apps Quickstart is available on the Azure Marketplace right now.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/08/11/Introducing-a-Quicker-Mobile-App-Quickstart.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Patching Swagger-UI Vulnerabilities in Azure Mobile Apps",
        "excerpt":"      Adrian Hall (MSFT)     8/11/2016 3:00:58 PM  ALERT: Some Mobile Apps (a feature of Azure App Service) deployments may be vulnerable to phishing attacks because of how current and older versions of swagger-ui are installed. Please take steps to determine if your deployments are at risk, and then mitigate, if necessary.   Our Microsoft Azure Security team is following reports of multiple high risk vulnerabilities present in current and older versions of swagger-ui. These are third-party vulnerabilities and not related to the Azure platform. However, some Mobile Apps deployments may have swagger-ui installed in a manner that makes those deployments vulnerable to phishing attacks.   How the vulnerability is exploited   The swagger-ui component allows loading of arbitrary swagger definition files by passing the URL of the swagger definition as a querystring parameter. Malicious swagger definitions can be constructed that execute arbitrary code within the browser. An attacker can then send a URL containing a reference to the malicious swagger definition that is then executed by simply opening the URL in a browser (for example, clicking on the link in an email).   How the vulnerability is mitigated   The Mobile Apps server SDKs now validate the URL of the swagger definition that is passed as a querystring parameter. Additionally, a Content Security Policy (CSP) header is sent which prevents the browser from communicating with servers that may host malicious swagger definitions.   How to determine if your deployment is at risk   First determine whether your Mobile Apps deployment is based on Node.js (this includes all Easy Tables users) or .NET.    For Node.js, you can determine if your deployment is vulnerable by looking at the code in your app.js file (if you are using Easy Tables, you can do this by using the Edit Script option in the Azure portal; this will open App Service Editor and allow you to browse the files). If you see the line \"swagger: true\" then swagger-ui is enabled and your deployment is potentially vulnerable. For .NET, your deployment is potentially vulnerable if the application you publish includes the Azure Mobile .NET Server Swagger package (the vulnerabilities aren‘t in this package itself but one of its dependencies).  Steps to perform mitigation actions  For Node.js, updated packages are available. We recommend that Node.js users complete one of the following actions:    Edit your application code (for example, app.js) to disable the configuration setting that enables our swagger UI functionality (use swagger: false). Or update to swagger-ui 2.1.5, and then update to the latest version of the Azure Mobile Apps Node.js SDK. Here are a couple of ways to do this:  Sign in to the kudu debug console by opening https://.scm.azurewebsites.net/DebugConsole (update  to your mobile app name), change directory to D:\\home\\site\\wwwroot, and then run npm update -save azure-mobile-apps swagger-ui. When this completes, go to the Azure portal, open your mobile app, and then select the Restart option.  Update package version numbers in package.json (azure-mobile-apps should be version 2.2.3; swagger-ui should be 2.1.5) and deploy using git.      We strongly recommend the following steps for .NET customers:  Uninstall the Azure Mobile .NET Server Swagger package as a mitigation.  Confirm that your application code no longer includes a reference to the Swashbuckle.Core package.  Republish your application.    For more information on the open source component swagger-ui vulnerabilities, please visit the following webpages on the Node Security Platform website:    XSS in Consumes/Produces Parameter  XSS in key names  XSS via Content-type header    As always, if you run into problems, please contact us.  We listen on the Azure Forums and Stack Overflow.       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/08/11/Patching-Swagger-UI-Vulnerabilities-in-Azure-Mobile-Apps.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Cross-Post App Service Auth and Azure AD B2C (Part 2)",
        "excerpt":"      Chris Gillum (MSFT)     8/15/2016 8:44:05 AM  Note: This post was cross-posted from CGillum Dev Blog. EDIT 1/23/2017: Updated token refresh section with simplified instructions and added code snippets. This post is a continuation of my previous post on App Service Auth and Azure AD B2C, where I demonstrated how you can create a web app that uses Azure AD B2C without writing any code. If you haven't done so already, be sure to read that post to get proper context for this one.  In a recent service update, we've improved our overall support for B2C in Azure App Service. This includes enhancing our existing web app support, but more importantly includes adding full support for leveraging B2C in mobile, API and function apps. More specifically, support has been added for the Easy Auth Token Refresh API. Additionally, the Login API has been updated to support specifying specific B2C policies as arguments. If you're a Mobile app developer, these improvements will make using Azure AD B2C in your mobile app significantly easier.  This post will go into more details about these improvements, show a few code snippets, and conclude by demonstrating these B2C capabilities in a simple demo web app. Pick Your Policy  Specific B2C policies can be invoked using the built-in Easy Auth login API for AAD. If you're not familiar with the Easy Auth login API, it works by allowing you to initiate a server-directed login by sending a GET request to your web, mobile, API, or function app's built-in {root}/.auth/login/aad endpoint. This endpoint supports the standard sign-in query string parameters for AAD, including the newly added p={policy} query string parameter which allows you to specify a B2C policy by name.  For example, one could use the following HTML in a web app to create hyperlinks that invoke specific B2C policy workflows, such as editing the user profile or resetting the password:  [html] &lt;a href=\"/.auth/login/aad?p=B2C_1_EditProfile&amp;post_login_redirect_uri=/\"&gt;Edit Profile&lt;/a&gt; &lt;a href=\"/.auth/login/aad?p=B2C_1_ResetPassword&amp;post_login_redirect_uri=/\"&gt;Reset Password&lt;/a&gt; [/html]  Clicking one of these links will automatically redirect the user to the corresponding B2C policy page and allow the user to edit their user profile or reset their password accordingly.  If you're writing a native client which uses one of the App Service Mobile Client SDK flavors, you could write something similar in platform-specific code. The example below shows how a mobile client app written in C# can invoke a B2C sign-in policy that requires MFA:  [csharp] App.MobileClient.LoginAsync(   MobileServiceAuthenticationProvider.WindowsAzureActiveDirectory,   new Dictionary&amp;lt;string, string&amp;gt;   {     { \"p\", \"B2C_1_SignInWithMFA\" }   } [/csharp]  In this case, the user will presented with a native web view dialog which allows the end user to sign in using MFA (phone authentication, etc.). The primary thing to keep in mind about this experience is that these B2C policies can be easily invoked with just a few simple lines of client-side code. No platform-specific middleware or server-side code is required.  One important note of caution: the claims associated with the signed-in user will be updated every time you invoke a B2C policy. If your app depends on the presence of specific claims, make sure they are explicitly configured in each of your B2C policies. Refreshing Tokens (Optional)  Easy Auth also has a built-in API for refreshing both provider-specific OAuth tokens and the app-specific authentication tokens. It works similar to the login API, in that it requires a GET request to the app's built-in {root}/.auth/refresh endpoint.  More information on token refresh (and our token management story all-up) can be found in my earlier App Service Token Store blog post.  This token refresh support also extends to Azure AD B2C apps and is completely optional. However, leveraging token refresh is very important if you're building a native app to ensure a smooth user experience. In order to set this up, you will need to do the following: Create an app key for your B2C application  Creating app keys can be done in the Azure management portal for B2C.  [caption id=\"attachment_198\" align=\"aligncenter\" width=\"951\"] Generating an App Key in the B2C Management Portal[/caption]  Make a note of the app key that gets auto-generated by the portal. We'll need it to configure Easy Auth in the next step. Update the Easy Auth Settings  Easy Auth doesn't require an app key by default and instead relies on the OpenID Connect Implicit Flow to implement secure logins. In order to get refresh tokens, however, we need to switch to the Hybrid Flow (Don't worry if you don't understand what these mean, Easy Auth will take care of the protocol details for you).  To make this protocol switch, you need to update the App Service Auth settings for your app with the key from the previous step. This can be done in the Advanced tab in the Azure Active Directory portal.  [caption id=\"attachment_2865\" align=\"alignnone\" width=\"1190\"] Setting the B2C app key as the Easy Auth client secret.[/caption]  Now that you’ve enabled the hybrid flow, your app needs to start requesting refresh tokens from B2C. This can be done by updating the login parameters in your app code to include the offline_access scope.  Updated HTML Example  [html] &lt;a href=\"/.auth/login/aad?p=B2C_1_EditProfile&amp;post_login_redirect_uri=/&amp;scope=openid+offline_access\"&gt;Edit Profile&lt;/a&gt;  &lt;a href=\"/.auth/login/aad?p=B2C_1_ResetPassword&amp;post_login_redirect_uri=/&amp;scope=openid+offline_access\"&gt;Reset Password&lt;/a&gt; [/html]  Updated Mobile App SDK C# Example  [csharp] App.MobileClient.LoginAsync(   MobileServiceAuthenticationProvider.WindowsAzureActiveDirectory,   new Dictionary&amp;lt;string, string&amp;gt;   {     { \"p\", \"B2C_1_SignInWithMFA\" },     { \"scope\", \"openid+offline_access\" }   } [/csharp]  Once this is done, all future logins should result in refresh tokens in the app's built-in token store. You can then write client code which invokes the {root}/.auth/refresh API (or use the corresponding Mobile Client SDK method) to periodically refresh these tokens, which allows your app to function for longer periods of time without requiring a re-auth. Demo App  To demonstrate all of this, I've created a single-page application (aka a SPA app) written using HTML, jQuery, and Bootstrap. It's a trivial app written by someone who is clearly not a UI designer (me) and demonstrates the various patterns described in this blog post.  You can browse to it here and play around with it (I promise not to give out your information if you decide to provide it), or simply copy the source code and host it yourself in your own App Service web app. Note that I theoretically could have also built this using the iOS, Android, UWP/Xamarin, or one of the other mobile SDKs that are provided, but it was simpler for me to build a plain-old HTML web app. :)  The important thing to keep in mind is that there is absolutely no auth code in this sample (in fact, no backend code at all). All of this is implemented on the client and in the App Service platform with the help of Azure AD B2C. No SDKs required.  When you first visit the demo page, you will be given two login options. One is a standard email-based login and the other is an MFA login which requires you to register a phone number for phone authentication.  [caption id=\"attachment_183\" align=\"aligncenter\" width=\"510\"] Demo app starting page when unauthenticated[/caption]  The phone authentication provided by B2C allows you to do phone calls or SMS in my case. You can enter the provided code to complete the authentication.  [caption id=\"attachment_182\" align=\"aligncenter\" width=\"419\"] Phone authentication when using Azure AD B2C[/caption]  Once signed-in, you will see a few B2C policy actions that you can invoke as well as a set of user claims displayed on the page. There's also a sign-out button which uses Easy Auth's built-in Logout API to clear the session.  [caption id=\"attachment_185\" align=\"aligncenter\" width=\"992\"] This B2C demo app supports updating the user profile and resetting the password used for logging in.[/caption]  [caption id=\"attachment_189\" align=\"aligncenter\" width=\"1003\"] This B2C policy is configured to return the object ID, postal code, name and email address.[/caption]  Note that one of the claims, https://schemas.microsoft.com/claims/authnclassreference, contains the name of the B2C policy that the user logged-in with. Your application code can take advantage of this if, for example, you want to grant special permissions to users who log in using a higher-privilege B2C policy.  Again, it's a very simple app to quickly demonstrate some of the powerful capabilities of the App Service \"Easy Auth\" platform when combined with Azure AD B2C.  My hope is that this is enough to give you some ideas about how you can leverage the Azure AD B2C platform in your own App Service apps. Following Up  Have a technical questions about Azure App Service and/or Azure AD B2C? Head over to StackOverflow.com and tag your questions with azure-app-service and/or azure-ad-b2c accordingly. We monitor posts with these tags and are happy to help.  Note: This post was cross-posted from CGillum Dev Blog.      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/08/15/Cross-Post-App-Service-Auth-and-Azure-AD-B2C-(Part-2).html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing  MySQL in-app for Web Apps (Windows)",
        "excerpt":"      mksunitha     8/18/2016 4:26:55 PM  MySQL in-app feature enables running MySql natively on Azure App Service platform.You don’t need to provision a database explicitly as during the creation of the web app when using this feature,  we take care of enabling it if you select “MySQL in-app ” during creation or if the feature is turned ON for existing web app. To understand what MySQL in-app means , I have highlighted core functionality supported with the preview release of the feature:  Support PHP , MYSQL applications like WordPress, Joomla , Drupal etc . MySQL server running on the same instance side by side with your web server hosting the site. This will boost performance of your application Storage is shared between both MySQL and your web app files. Note with Free and Shared plans you may hit our quota limits when using the site based on the actions you perform . Check out quota limitations for Free and Shared plans. You can turn on Slow query logging and general logging for MySQL . Note that this can impact the site performance and should NOT always be turned ON . The logging feature will help investigation any application issues .     Note : This MySQL in-app is specific to Windows version of Azure app service. If you are looking for local mysql on Linux MySQL app service , click here. Create new Web App with MySQL in-app  Login to Azure portal  and launch Web App + MySQL template by clicking here .Enter the Site name and select MySQL in-app  as the database provider. Click on Create to deploy a web app using MySQL in-app.    You may also create a WordPress application with MySQL in-app from Azure marketplace. Test drive our demo site here using MySQL in-app.You can login with username : demo and password: demopassword .  Limitations  For preview release the feature has some limitations that to keep in mind.  Auto scale feature is not supported since MySQL currently runs on on a single instance . Enabling Local cache is not supported. MySQL database cannot be accessed remotely. You can only access your database content using PHPMyadmin or using MySQL utilities in KUDU debug console. This is described in detail below. WordPress and Web App + MySQL templates currently support MySQL in-app in the create experience.We are working on bringing this feature in for other MySQL based applications in Web category for Azure marketplace.    Manage MySQL in-app  Go to your web app and select MySQL in-app  in the Menu blade on the right. You can use the setting here to manage your MySQL in-app feature , turn on logging , access PHPmyadmin etc.      Access database content  The database is protected by our sandbox environment and hence cannot be accessed remotely through MySQL workbench or MySQL command line tools (running on remote machine) . There are two ways you can manage your database content :    Using PHPMyAdmin:  With MySQL in-app , the MySQL process ( mysqld.exe) must be ready for connections before using PHPmyadmin tool to access the database. This means your web app has to open the mysql connection. You can use the sample code mentioned in section Get database connection string to open mysql connection. Go to your web app and select MySQL in-app  in the Menu blade on the right . Click on the Browse button to open PHPmyadmin.       The database enabled with your web app is \"localdb\". You are now ready to import your database schema or create a new one for your web app.     Using Kudu Debug console: Access your Kudu debug console  from the portal , go to your web app and Select Advanced Tools or use use a URL in this format https://sitename.scm.azurewebsites.net/debugconsole (replace sitename with your web app name).  Run the following command to run your query (remember to update the port number to your web app’s MySQL port since this feature does not use 3306 port)    D:\\Program Files (x86)\\mysql\\5.7.9.0\\bin\\mysql.exe -e \"ENTER SQL STATEMENTS\" --user=azure --password=password --port=49175 --bind-address=127.0.0.1    Example: D:\\Program Files (x86)\\mysql\\5.7.9.0\\bin\\mysql.exe -e \"USE localdb;Select * from tasks;\" --user=azure --password=password --port=49175 --bind-address=127.0.0.1   mysql: [Warning] Using a password on the command line interface can be insecure. mysql: Unknown OS character set 'cp0'. mysql: Switching to the default character set 'latin1'. task_id    subject    start_date    end_date    description 1    task1    2016-02-18    2016-02-19     sample task  The mysql warning statements can be ignored in the output. You can use mysqladmin.exe and mysqld.exe as well , in the similar format as above .Please review the password and database information from D:\\home\\data\\mysql\\MYSQLCONNSTR_localdb.ini  before entering the connection information in the commands below. Here is an example to flush logs mysqladmin.exe flush-logs --user=azure --password=password --port=49175 --bind-address=127.0.0.1 Logging  Turn on slow query logs or general logs for MySQL . Once turned on , you can find these logs in D:\\home\\logfiles\\mysql folder. Note if these settings are always on , then this can impact your web app performance   How to deploy your web app to using MySQL in-app  Get the database connection string  Before you deploy your web app code , the key thing to note when using this feature is to use ENVIRONMENT VARIABLES since the database connection information is not accessible directly. You can get the database connection information using MYSQLCONNSTR_localdb environment variable . You can also get the connection string from D:\\home\\data\\mysql\\MYSQLCONNSTR_localdb.ini .Here is a sample code snippet that you can use in your application to get the database host, port, database name , database user, database password.  $connectstr_dbhost = ''; $connectstr_dbname = ''; $connectstr_dbusername = ''; $connectstr_dbpassword = '';  foreach ($_SERVER as $key =&gt; $value) {     if (strpos($key, \"MYSQLCONNSTR_localdb\") !== 0) {         continue;     }          $connectstr_dbhost = preg_replace(\"/^.*Data Source=(.+?);.*$/\", \"\\\\1\", $value);     $connectstr_dbname = preg_replace(\"/^.*Database=(.+?);.*$/\", \"\\\\1\", $value);     $connectstr_dbusername = preg_replace(\"/^.*User Id=(.+?);.*$/\", \"\\\\1\", $value);     $connectstr_dbpassword = preg_replace(\"/^.*Password=(.+?)$/\", \"\\\\1\", $value); }  $link = mysqli_connect($connectstr_dbhost, $connectstr_dbusername, $connectstr_dbpassword,$connectstr_dbname);  if (!$link) {     echo \"Error: Unable to connect to MySQL.\" . PHP_EOL;     echo \"Debugging errno: \" . mysqli_connect_errno() . PHP_EOL;     echo \"Debugging error: \" . mysqli_connect_error() . PHP_EOL;     exit; }  echo \"Success: A proper connection to MySQL was made! The my_db database is great.\" . PHP_EOL; echo \"Host information: \" . mysqli_get_host_info($link) . PHP_EOL;  mysqli_close($link);  As an example , if you are running a WordPress site you need to update wp-config.php such that it reads the connection string from the environment variable . /*Add at the begining of the file*/  $connectstr_dbhost = ''; $connectstr_dbname = ''; $connectstr_dbusername = ''; $connectstr_dbpassword = '';  foreach ($_SERVER as $key =&gt; $value) {     if (strpos($key, \"MYSQLCONNSTR_localdb\") !== 0) {         continue;     }          $connectstr_dbhost = preg_replace(\"/^.*Data Source=(.+?);.*$/\", \"\\\\1\", $value);     $connectstr_dbname = preg_replace(\"/^.*Database=(.+?);.*$/\", \"\\\\1\", $value);     $connectstr_dbusername = preg_replace(\"/^.*User Id=(.+?);.*$/\", \"\\\\1\", $value);     $connectstr_dbpassword = preg_replace(\"/^.*Password=(.+?)$/\", \"\\\\1\", $value); }  // ** MySQL settings - You can get this info from your web host ** // /** The name of the database for WordPress */ define('DB_NAME', $connectstr_dbname);  /** MySQL database username */ define('DB_USER', $connectstr_dbusername);  /** MySQL database password */ define('DB_PASSWORD', $connectstr_dbpassword);  /** MySQL hostname : this contains the port number in this format host:port . Port is not 3306 when using this feature*/ define('DB_HOST', $connectstr_dbhost);  As a BEST PRACTICE when using MySQL in-app, we recommend to ALWAYS use Environment variables for the database information to prevent database connection issues with your web app. If your application requires a separate variable for port , you can use WEBSITE_MYSQL_PORT environment variable. The port number selected can vary if the instance is recycled and hence ALWAYS use environment variables. Deploy you code  Deploy your web app code using GIT or FTP or any one of the supported deployment processes with Azure Web Apps . Refer Deploy to Azure app service web apps for details . Deploy your database  You cannot directly deploy you database . Hence , export your local database into a SQL script . Access your web app MySQL in-app database using PHPmyAdmin ( https://sitename.scm.azurewebsites.net/phpmyadmin) and click on the IMPORT tab to import your script into the localdbdatabase . For example: USE localdb;  CREATE TABLE IF NOT EXISTS tasks (   task_id INT(11) NOT NULL AUTO_INCREMENT,   subject VARCHAR(45) DEFAULT NULL,   start_date DATE DEFAULT NULL,   end_date DATE DEFAULT NULL,   description VARCHAR(200) DEFAULT NULL,   PRIMARY KEY (task_id) ) ENGINE=InnoDB Remember to include USE localdb;  statement in your script so that the your schema and data are imported into the correct database. How to turn on MySQL for existing Web Apps  Go to your web app and select MySQL in-app  in the Menu blade on the right . Turn ON MySQL in-app feature.    Browse your web app and Check the process explorer to verify if mysqld.exe is running. If the process is running, then MySQL server is ready to use. Remember to open the MySQL connection to your MySQL in-app database , localdb in your web app.   Migration to production database  You can easily migrate this database when ready for production to  Azure database for MySQL(Preview) ClearDB database MySQL on virtual machine on Linux or Windows OS  Best practices   When using Web app with MySQL in-app provider with Basic, Standard or Premium app service plans, turn on ALWAYS ON setting as described here. By default, web apps are unloaded if they are idle for some period of time which means both the web app and MySQL in-app server will be take a longer time to load from an idle state. PHPMyadmin may not be accessible during the idle state. With ALWAYS ON feature, you can keep your web app from getting into an idle state. When using this feature with Free and Shared Web App pricing plans, add the app setting WEBSITE_FASTCGI_MAXINSTANCES and set its value to 3 if your web app is likely to get traffic from a few users say between 10-20. This setting will prevent creating too many PHP FastCGI instances which will consume all the memory causing your web app to hit the quota too early. Checkout benchmarking blog post for more information.  References  Exporting your MySQL database to MySQL in-app database Benchmarking MySQL in-app performance     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/08/18/Announcing-MySQL-in-app-for-Web-Apps-(Windows).html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Benchmarking MySQL in-app performance",
        "excerpt":"      mksunitha     8/18/2016 4:26:30 PM  Azure app service just launched a new feature, MySQL in-app to support MySQL natively. MySQL in-app is recommended for development and testing (DEV/TEST)  scenarios to quickly spin up PHP+ MYSQL applications on Azure to start developing and understanding the Azure app service platform. You can easily migrate this database when ready for production to  ClearDB database ClearDB Clusters MySQL on virtual machine on Linux or Windows OS  We conducted a benchmarking experiment with MySQL in-app  to understand its performance compared to other MySQL solutions offered on Azure. We conducted two tests as described below:  We conducted a benchmarking experiment with MySQL in-app to understand its performance compared to other MySQL solutions offered on Azure. We conducted two tests as described below : Test Configuration  We used simple testing methodology for both scenarios to understand the performance of the feature. The baseline configuration for both tests mentioned below are:   Two test clients (one is the same region as web app and one in a different region) added application insights to web app  to gather telemetry data using MySQL in-app database constant user load on the web app   Test Scenario with Vanilla WordPress :  We deployed a vanilla word press web app on various pricing plans for Azure App service. No caching layer was used with the web app configuration. Note: Keep in mind that Free and Shared hosting have quota limitations that impacted the result of the tests.   During this test , we set a limit on how many PHP FastCGI processes created on Free and Shared pricing plan. To learn more about limiting PHP FastCGI process , check out this article.In Azure app service , this can be done by using enabling the app setting WEBSITE_FASTCGI_MAXINSTANCES . For this test the value was set to 3.  Try out the demo site    Web App SKu User Load Server Response Time CPU Time Requests HTTP Server Errors Average Memory Working Set   Free 10 248.14 ms 127.69 440 0 524.12 MB   Free 25 245.56 ms 278.01 903 0 597.17 MB   Shared 10 269.19 ms 166.53 445 0 515.6 MB   Shared 20 217.23 ms 255.81 960 0 537.05 MB   Basic Small 15 369.8 ms 675.81 2.24 k 0 421.83 MB   Basic Small 30 531.97 ms 773.88 2.51 k 0 285.67 MB   Basic Medium 25 270.54 ms 1.01 k 3.74 k 0 607.58 MB   Basic Medium 50 453.78 ms 1.59 k 5.47 k 0 444.87 MB    Test scenario with customized WordPress application with popularly used plugins  After modifying the above vanilla WordPress with a few plugins to WordPress app as  listed below:  MotoPress  Editor  lite Jetpack Yoast SEO  This configuration is similar to a production web application and we did not include include any caching layer to understand the performance of MySQL server running locally on the azure app service instance.  Demo site:    Web App Sku User Load Server Response Time CPU Time Requests HTTP Server Errors Average Memory Working Set Memory Working Set   Standard Small 30 1.87 s 751.76 1.29 k 0 490.03 MB 7.47 GB   Standard Small 50 2.23 s 762.9 1.23 k 0 489.14 MB 7.28 GB    You can make the application load even more faster , by using one or more of the options below :  Using Wincache object cache  or using Azure Redis cache Caching static content using browser caching Minify JS and CSS files as per your application framework documentation Reducing HTTP requests per page Compress images  as per your application framework documentation Optimize your database and perform regular clean up of your content  Conclusion  MySQL in-app feature is recommended for development and testing purposes. Based on the data above you can see that this feature improves the performance of your PHP application since both the Web server and MySQL server are co-located on the same instance.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/08/18/Benchmarking-MySQL-in-app-performance.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Exporting your database to MySQL in-app database",
        "excerpt":"      mksunitha     8/18/2016 4:27:45 PM  This blog post will guide you through the process of exporting your current website's database to local MySQL. Follow the process below to export your database: Locate and access your current database:  Your database must be remotely accessible. Check your existing hosting provider on how to access your MySQL database. Most common tool used is PHPmyadmin for accessing your database. Check out this article on How to setup PHPmyadmin for your Azure Web App if your app is already running on Azure. PHPmyadmin is browser based tool that can be used to manipulate and manage your database.       You may also use MySQL workbench to access your database . Check out this article on how to access your database using MySQL workbench. Export your database and Save it locally  PHPmyadmin  Access your database using PHPmyadmin and click on Export tab.    Select Custom export method to have the ability to modify how the script should be generated. Click on GO to generate the script and save the file locally .   MySQLDump.exe  If you have MySQL installed on your local machine you can using mysqldump.exe utility usually found in the bin folder within MySQL folder. To export a remote database run the command in this format D:\\Program Files (x86)\\mysql\\5.7.9.0\\bin&gt;mysqldump -P port_number -h host_name -u mysql_user -p database_name &gt; result_file.sql Example: D:\\Program Files (x86)\\mysql\\5.7.9.0\\bin&gt;mysqldump -P 48926 -h mysqlserver.cloudapp.net -u root -p mywordpressdb &gt; mydatabaseexport.sql MySQL workbench  This tool offers an export wizard as shown below to export your database content. Check out the documentation for using the Export wizard to export the database   Once you have successfully exported the database, then inspect your MySQL database script to check if your application stores the site URL in the database. If yes, then update the URL to use Azure app service web app URL or custom domain if the custom domain is already pre-configured on your Azure web app. Your script is ready to be imported. Import your database  Go to your web app Settings-&gt;Feature -&gt; MySQL in-app to access the management settings for this feature.  Import Feature in Azure portal : Select MySQL in App setting , under Data Import and Export select \"Import\" to import a remote database into MySQL In App database . Enter the remote database connection information to import the database. Note that MySQL In App uses MySQL 5.7.9 version and make sure your remote database is compatible with this version of MySQL .  Using PHPmyadmin :  To open PHPmyadmin for your MySQL in-app database . Check your SQL script and make sure the USE statement is using the database name “azuredb” . This is the database used with the connection string we provide with MySQL in-app. If the USE statement has a different database name, update it to use azuredb database. Then Click Import in the top menu in PHPmyadmin .Under File to Import, click Browse and select the script your exported from your source database. Then click Go to complete the import.    When the import is completed and successful, you can update your web app to connect to azuredb database with the imported database schema. That's it and your database migration is completed.        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/08/18/Exporting-your-database-to-MySQL-in-app-database.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP runtime and extension updates including potentially breaking changes",
        "excerpt":"      Cory Fowler (MSFT)     8/22/2016 10:04:49 AM  In an upcoming release, we are making some changes to the available runtimes and PHP extensions on the Azure App Service workers. We suggest that you review your sites to ensure that these changes do not cause any downtime of your applications or tooling. PHP Runtime Updates  Due to some recent high priority security updates, we are adjusting the runtimes that are available on Azure App Service workers. For more details on the changes, please review the links to the specific version changelogs available in the After Update column of the table below. Note: PHP 5.4 will soon be retired on Azure App Service as it is no longer receiving security updates. See more details about the retirement on the Azure Blog.    Runtime Version Currently Supported After Update     5.4 5.4.45 5.4.45   5.5 5.5.36 5.5.38   5.6 5.6.22 5.6.24   7.0 7.0.7 7.0.9    PHP Extension Updates  SQL Server Driver for PHP 7  Recently the SQL Server team released the Microsoft drivers 4.0 for PHP,which includes support for PHP 7. Now that this driver is no longer in preview, we are including the driver on the workers by default. If you have been loading your own version of this driver, you will need to remove the statements which are loading the driver as having a duplicate reference will cause errors. XDebug  We are updating the version of XDebug which is available on the workers by default. Currently, we have version 2.2.4 available in d:\\devtools\\xdebug which is being replaced by version 2.4.0. If you are referencing XDebug for profiling or remote debugging purposes, the extension will no longer be available on the workers and the references will need to be updated to point to 2.4.0.  The good news is that XDebug version 2.4.0 supports PHP 5.5, 5.6 &amp; 7.0, which means all supported runtimes now have the ability to take advantage of XDebug for debugging and profiling purposes.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/08/22/PHP-runtime-and-extension-updates-including-potentially-breaking-changes.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "New App Service quota UX",
        "excerpt":"      Byron Tardif     8/26/2016 12:37:00 PM  Apps hosted in Free and Shared App Service plans get access to certain amounts of resources based on their quotas. You can learn more about app service quotas and how the apply to your apps here: How to: Monitor Apps in Azure App Service  The new quota UX let’s get an at a glance view of the quotas applicable to your app.    Each quota contains basic information about (1) the current utilization, (2) the limit for this specific quota, (3) when will the quota re-set and (4) the quota name.    You can manually refresh the view by clicking on the refresh button in the action bar or provide us feedback directly about this new UX.  This new UX makes it easier to understand the resource usage for your apps and what resources are being exhausted.  If you have any questions about this UX or App Service in general be sure to check our forums in MSDN and Stack Overflow and for any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/08/26/New-App-Service-quota-UX.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Onboarding to Azure Web Marketplace and Certification",
        "excerpt":"      mksunitha     8/26/2016 2:28:03 PM  Azure Marketplace is a hub of solutions for users to create different types of resources.  Each category of resource such as Data services, Virtual machines, Web have different on-boarding processes for ISVs to publish their solutions in Azure marketplace. In this article we will discuss the process to on-board Web Apps to Web Marketplace in Azure.  To showcase your application in Web Azure marketplace , you need to get your application certified. The certification process is a 5 Step process.          APPLICATION   Step 1: Apply by providing basic information about your business and solution Step 2: Share solution-specific information and wait for approval     ONBOARDING Build your Azure package and provide the marketing content for your application . See details below.   CERTIFICATION We’ll run tests to verify compatibility with our platform or service   PUBLISHING   Step 1: Showcase the Azure certified logo for your application Step 2: Publish your application on Azure Marketplace/Azure pages     MARKETING Promote and market your application taking advantage of Microsoft go-to-marketing resources     On-boarding New applications to the Web Azure Marketplace  For new applications:  The on-boarding process is a gated approach and the application will be reviewed by our team. Click here to request for certification. Leverage the benefits of this program from being showcased in the Azure Marketplace but also advantages of being part of Microsoft partner network.  Follow the guidelines mentioned below to build your template and test your application on App service.  If accepted we will enable it in the Azure portal. Existing Applications:  We will continue to maintain existing applications in the Azure Web Marketplace. Please reach out appgal@microsoft.com if you haven't already to get details on updated process for managing updates to your application. Azure Web Marketplace Principles  Users can browse and view applications for different types of Web sites, ranging from photo galleries to blogs to e-commerce sites. To be part of the Azure Web Marketplace, developers should follow these principles, which establish a consistent, quality user experience:  Be Current: The application you provide a link to must be the latest, stable final release version available, hosted on a publicly available Web URL. Application License: The application Azure Web Marketplace may provide an entry point free of charge or use Bring your own license model (BOYL)  where users can purchase a license from the application publisher's website. Be Compatible: The generated and configured application deployed from Azure Web Marketplace must also run on any Windows OS.The application should support running on cloud infrastructure by providing an option to make the application stateless. Be Hostable: The application to which you provide a link must run well in a shared hosted environment as well as when the user has administrative rights for the computer. Be Deployable: Your application code must be available on a public repository on Github.com . Azure users should be able to fork the repository and deploy to Azure web app. Be Supported: You must provide a publicly available Web site where end users can download your application, find documentation and/or get free on a best effort basis support through a forum. Be Platform Independent: The application to which you provide a link must be able to run on all Windows  platforms x86, and x64. Be Inclusive: If your application is included in the Gallery, you should include a statement of availability in the Azure App Gallery on the application community’s Web site. Be Safe: The application to which you provide a link must not harm customers or be malicious, dishonest, destructive, invasive, or act in any manner restricted by the Web Gallery Application Submission agreement. Be a Web App: The application to which you provide a link must be a Web application that can be used to generate a working, usable Web site after deployment without requiring code or customization. Support Database Dependencies: Currently our create experience supports Web App with Database ( MySQL and/or SQL DB). If your application has other dependencies , Web Marketplace may not be an option.You may want to look into Azure solution templates.  Package your application code  Using Git Deploy: Create a public Github repository with your application code as it would be deployed under wwwroot in the Azure web app. You may include custom post deployment scripts with a deploy.cmd file in the root of your repository, see details on how to add custom scripts.  This packaging method makes managing updates to your application easier without having to go through the entire certification process. For future updates to your application , you need to update the code in the repository with appropriate commit message for users to pull in to latest bits of your application. When code changes are committed to your repo  , the code is not automatically pulled in for users using your application to prevent breaking their application. Users using your application must perform a manual sync to pull in the latest committed changes from your repository. Note: We are no longer supporting Web deploy method of application packaging for NEW applications in the Web marketplace. Building an Azure Package for Marketplace  Azure Package has a special folder structure to be consumed by Azure Marketplace service. Each folder at the root level approximately represents a publisher. A folder contains one or more .json files, called package manifests, each of which contains the metadata for an Azure Gallery package. Every folder also includes a set of deployment templates, strings , icons and screenshots which can be referenced by the package manifests. See the folder structure shown below : /MyPackage/ /MyPackage/Manifest.json /MyPackage/UIDefinition.json /MyPackage/Icons/ /MyPackage/Screenshots/ /MyPackage/Strings/ /MyPackage/DeploymentTemplates/  You can find sample packages on GitHub .  Manifest.json:  The manifest file contains all of the metadata for your gallery item. For a visual representation of where each metadata value is used , view the schema for Manifest.json. Add the paths to the Icons , Screenshots and links to articles that can help customers get more information about your application.   UIDefinition.json :Use the UIDefintion.json schema to build appropriate UIDefinition.json for your application. You can use \"parameters\" properties which is optional , if your application needs to ask the user for information for the deployment of your app. These parameters become AppSettings for your web app and can be consumed within your app as environment variables.To hide a parameter from the portal UI , set \"hidden\":true as show here  . To mark a parameter as required for the create experience , set \"required\":true as shown here. Icons : The relative path specified by iconPath in a package manifest must point to a folder that includes the following four images with these dimensions mentioned below:  Small.png (40x40 px) Medium.png (90x90 px) Large.png (115x115 px) Wide.png (255x115 px)  You can group icons under sub-folders if you have different ones per product. Just be sure to include the sub-folder in the iconPath for the package manifest that uses them. Screenshots : Images must be exactly 533px by 324px and in PNG format. Specifying a screenshot for a gallery package is completely optional, so do not feel compelled to include one unless it makes sense for your offering. Deployment Templates : Include an ARM template that allows Azure users to deploy  the application via PowerShell. To learn how to build an ARM template , read the guidelines stated here . Strings: Include resources.resjson and description.md files to include the description about your application. Here is a sample description.md and sample resources.resjson.  Update your application version  When there is a new version of your existing application, update the following :  Change the packageURL property in UIdefinition.json file to point to HTTP URL for your application. Change the packageURL in Deployments/Website_NewHostingPlan_SQL_NewDB-Default.json file with the HTTP url for your application. [Optional] Update icons or screenshots , strings if needed  Build a new azure package in ZIP format and submit a  request to certify.  Test your application  Follow the criteria below  Build an ARM (Azure resource manager) template as per guidelines stated here . You can find a sample here Use the Azure resource manager templates and deploy using PowerShell. Run these tests in at least 3 different Azure regions. Save the results of these deployment in an Excel or Word document.  The excel document should have the following columns:  Resource group Web app name Region Subscription ID Time of deployment Web app Pricing Tier or Sku Tested with Auto-scale feature[ Values : Pass/Fail]   Test your application with auto-scaling feature turned on and under a heavy load . For example you can choose to run a 5 min load test of 50 users  on Web App Standard Small (S1) Pricing tier    Tested with Continuous Integration[ Values : Pass/Fail]  In this test , publish changes to your application and see if you changes are being picked up by your application linked to the Github repository .     Tested with Deployment slots [ Values : Pass/Fail]  In this test , create a deployment slot. Connect to the application Github repository to the deployment slot.  Push changes to the github repository and then complete to Swap your application slot with production slot.    Tested with Backup and restore [ Values : Pass/Fail]  In this test configure and setup Backup for your application code and database (optional) to be backed up.  restore  from the backup ZIP file to an existing site       There are some limitations with the Azure create in the portal and power shell . If your application requires these configurations mentioned below , we will not be able to on board the application.        You web app need Virtual application setting to be configured for web app Your web app need a dependency that is not supported by App Service create scenario. We currently support ONLY SQL DB , MySQL and Azure Storage dependencies.        Submit your application  Submit a certification request here .  Please do provide information about your application during submission .  Here is the kind of information we are looking for to learn about your application  What is current Usage statistics of your application Do you have customers using your application on the Cloud ( Azure or other hosting providers). If yes share at least 2 customer stories. How active is the community engaged , primarily for Free applications this information is required  You will receive a response in 3-5 business days with a request for more information or with next steps to move forward. Post publishing  We recommend to maintain documentation and support for your application on your website. This is key to help get new users started with using your application and follow best practices based on your guidance. Marketing  Once approved your application will be visible in the Azure portal under \"Web + Mobile\" category. Users can view your application on Azure website in the Marketplace page. FAQ  Check out the frequently asked questions here . If you don't see the answer to your question , contact us at appgal@microsoft.com     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/08/26/Onboarding-to-Azure-Web-Marketplace-and-Certification.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions 0.5 release &amp; August portal update",
        "excerpt":"      Chris Anderson (Azure)     9/1/2016 11:20:33 AM  We're happy to announce we've officially released Azure Functions host version 0.5 into our Public Preview, as well as some updates to our Portal experience. The host version does include several breaking changes, so please read the release notes before upgrading. We will also be updating our default version in create to ~0.5 as well, so new deployments that don't specify a version will be on the latest.  F# support now in preview  Thanks to the excellent work by the F# team including Don Syme and Tomas Petricek, we're happy to announce we finally support F# in a first-class fashion in Azure Functions. Previously, we just invoked your F# script via fsi. Today, it now running hot in our runtime, with support for input and output bindings. Note that this new F# experience is incompatible with the previous versions.  Here's a quick sample that would work off of a Queue trigger.  let Run (input: string, log: TraceWriter) =       log.Info(sprintf \"F# script processed queue message '%s'\" input)  If you are familiar with the C# experience, you'll remember the TraceWriter. This is because we support all the same types that C# supports. We haven't finished updating the documentation yet, but we'll be soon updating the C# docs to be the .NET docs.   For those curious in how it was built, feel free to check out PR #577.  Other breaking changes &amp; improvements  In addition to F# support, we have a few other breaking changes and notable improvements. You can read our full release notes on 0.5 release on GitHub.   Now using Node v6.4.0 (previously v5.9.1) - next update will be to Node v6 LTS sometime October. HTTP Trigger now supports binding to body/querystring properties. Event Hub trigger can now configure maxBatchSize and prefetchCount for advanced scenarios. C# Package Restore automatic restore improvements Logging improvements for performance and usability File Watcher can now be configured for where to look for changes. context.bindingData property casing is now lower camel cased (previously upper camel cased) Twilio is now supported as a binding by the host.  Portal updates  We also have some large updates to the portal experience rolling out today. Below are some highlights:   Localization is now available for many languages Tabs have all been moved to the left nav, rather than left and top. This change happened to improve usability in understanding Functions vs Function Apps. Actions for certain output bindings on Integrate tab. We found it was common to copy+paste settings from an output binding to a new trigger, so we added a button to do it for you. Dropdown pickers for connections - if you have an existing connection to Storage/etc., we'll show you those in a dropdown menu, rather than always having to choose from the picker blade (which can have LOTS of choices for large, shared subscriptions). Documentation is now available in the Integrate tab. This will hopefully make it more obvious how to use the bindings when you add them/modify them, rather than knowing where in the main docs site to look. You can now delete/rename files from the file explorer menu on the Develop Tab. Better whitespace usage on Integrate tab App Settings, Kudu, and Console now available from the Function App Settings menu, rather than having to jump through Advanced Settings.  What comes next?  With this release complete, we'll be starting our next wave of planning. We need and look forward to your feedback. You can submit general feedback on feedback.azure.com or, if you feel familiar with our host or portal, you can submit issues directly on GitHub (Host GitHub &amp; Portal GitHub). Most of our planning happens on GitHub, so you can see things coming as they are in progress.   Feel free to ask questions below or reach out to us on Twitter via @AzureFunctions. We hope you have fun with the new changes. We're looking forward to seeing what you do!       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/09/01/Azure-Functions-0.5-release-and-August-portal-update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Troubleshooting FAQ for MySQL in-app",
        "excerpt":"      mksunitha     9/8/2016 1:09:42 PM  Here are some troubleshooting guidelines for MySQL in-app feature:  1. I cannot to access the database using Phpmyadmin  When you access PHPmyadmin for MySQL in-app and the page returns a login page or “cannot connect: invalid settings” error. There can be two causes for this issue:  MySQL process may not be running.  Check process explorer if MySQL is running for your web app. You can access the process explorer in the portal. Select your web app -&gt; Tools -&gt; Process explorer   There will be mysqld.exe process visible in the process explorer.  If the process mysqld.exe is not visible in the process explorer, then browse the web app or ping your web app which would trigger mysqld.exe process to run. Check process explorer again to verify that mysql process is running and browse phpmyadmin.   You have two instances of PHPmyadmin installed  With MySQL in-app we already preconfigure and setup PHPmyadmin. If you install PHPmyadmin from Site extensions gallery, then you will end up having two instances of PHPmyadmin. To identify if you have two instances both the conditions below will be true:  PHPmyadmin folder exists in D:\\home\\siteextensions folder web app is using MySQL in-app feature  To resolve this, remove the site extension. Access the site extension gallery and click on remove button. Restart your web app and access your database with PHPmyadmin .  There may be a connection strings in application settings.  Check in your web app application settings if there is a connection string. PHPmyadmin uses MYSQLCONNSTR_ to connect to the MySQL server. If you have a connection string in application setting change the connection string  type to Custom , so you can still have the information if needed or delete it.  This will force PHPmyadmin to access MYSQLCONNSTR_localdb and connect to the MySQL in-app server.    File server storage is in read only mode Click here to learn more  2. My application cannot connect to MySQL in-app database  If your web app is unable to connect to MySQL in-app database, it could result from :  MySQL process is not running for your application:  You can access the process explorer in the portal. Select your web app -&gt; Tools -&gt; Process explorer. There will be exe process visible in the process explorer. If the process mysqld.exe is not visible in the process explorer, then restart the web app and browse the web app. Now check process explorer again to verify mysqld.exe loads and check if your web app is functioning correctly. Your web app is not configured correctly to use MySQL in-app: MySQL in-app does not use port 3306 for MySQL server and hence DO NOT hard code the database information in your application configuration file. If the MySQL port used by your web app as using in not available during the situations mentioned below, the MySQL port will change:during an upgrade of azure app service  when your web app is scaled up/down when your app is moved to a different app service plan when you migrate your app from one subscription to another subscription    To make your app resilient, use environment variables as shown here. 3. I cannot import my database with PHPmyadmin  PHPmyadmin allows your to import a database , but this  may fail due to:  MySQL server used when exporting the database is different than the MySQL version used in MySQL in-app and the schema changes are not supported in the version of destination MySQL server.The version on MySQL in-app is 5.7.9.0. You verify this check by checking the version number folder in MySQL folder \"D:\\Program Files (x86)\\mysql\\5.7.9.0\" PHPmyadmin version used for exporting the database varies with PHPmyadmin version used to import the database schema. The PHPmyadmin version that is used with MySQL in-app is 4.5.1. During export make sure the schema is supported. A workaround is to use mysqlimport.exe found in D:\\Program Files (x86)\\mysql\\5.7.9.0\\bin on the Kudu Debug console \"D:\\Program Files (x86)\\mysql\\5.7.9.0\\bin\\mysql.exe\" --user=azure --password=password --port=PORT --bind-address=127.0.0.1  DATABASE_NAME &lt; exportedfile.sql    The exported database file is greater than 8MB. PHPmyadmin is a php application , and the max_upload_size is 8MB for PHP on Azure app service. You can either  modify the max_upload_size to your desired value before doing an import as per instructions mentioned here  or use mysql utilities in Kudu debug console to do the import with this sample command \"D:\\Program Files (x86)\\mysql\\5.7.9.0\\bin\\mysql.exe\" --user=azure --password=password --port=PORT --bind-address=127.0.0.1  DATABASE_NAME &lt; exportedfile.sql   Note: When using mysqlimport.exe via Kudu debug console , the browser session timesout after 10 mins. If you have a large file then add the app setting SCM_COMMAND_IDLE_TIMEOUT=3600 for your web app prior to running mysqlimport.exe. 4. I cannot write to the database  OR I cannot create a comment or post on WordPress application  Turn on PHP error logs and if the error log states that the \"InnoDB is in read only mode\". This means file server storage is in READ ONLY mode , note that the file server is shared by your web app and MySQL database. The file server can be in read only mode due to   an upgrade on the service : Once the upgrade is completed you should be able to write to the database. This usually does not take more than a few minutes. Platform issues : Check the Azure status to see if there are any ongoing issues that could be resulting in this. Network blips : This could impact the site for a couple of seconds if there was network connection loss.  It is recommended to code your application to detect if the storage is in read only mode when using MySQL in-app. This can be done using a simple check to see if the folder wwwroot is writable using is_writable() in PHP before executing any INSERT / UPDATE / DELETE /CREATE Sql queries in your application. 5. How can I change MySQL server configuration  Click on your web app -&gt; application setting , under app settings add the Key/Value pair , for example to increase max allowed packet to 16MB  WEBSITE_MYSQL_ARGUMENTS = --max_allowed_packet=16M      Additional References  Troubleshooting Wiki     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/09/08/Troubleshooting-FAQ-for-MySQL-in-app.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP troubleshooting guide for common errors",
        "excerpt":"      mksunitha     9/14/2016 12:37:03 PM  Here is a troubleshooting guide for PHP errors on Azure app service. 5xx Errors    Multiple loaded extension: You might notice an error in php_errors.log when a extension is not loading. It could be that there is another extension already pre-configured on the platform. Install PHP manager  ( extension as shown in the image) from the portal to check which extension are available and/or enable before bringing in your custom php extension.  MySQL gone away: This error can occurs due to various reasons as listed below:   •    A query was executed after closing the connection to the server. This is a logic error in your application. Review your code and make changes.  •    The connection may have timed-out. You can use mysqli_options() to increase the timeout.  •    Long running query especially using INSERT or REPLACE commands can cause this issue.  •    Since ClearDB is different service, there could have been a networking blip connecting to ClearDB database. To work around this, you can add a retry logic to connect to your database.  •    If you are using ClearDB shared hosting, note that it is shared hosted service and if another user is using up all the resources you might get this error. To work around this, you can add a retry logic to connect to your database.  •    MySQL server may have crashed due to an incorrect query. Review your code to identify the query.   Redis gone away: This can happen due to network blips or if the server is down. As best practice include a retry logic to connect to your Redis server. For further troubleshooting, check this article.  Database deadlock error: Deadlocks occur when are there are multiple requests to write to the same table/ same record (based on the lock configuration on your database) at the same time. To avoid this, you need to include some logic in your app to manage deadlock scenario. Error connecting to database:  Check if your database is accessible. You can use MySQL workbench or mysql command line   Deprecated warning: It is recommended to notices and deprecated errors to reduce the stress on PHP process when writing to the logs especially if you app does generate too many notices and warning. These should b enabled on your staging or dev sites but on your production site it should be disabled. Read this article on how to change the way error is logged in PHP.  Checkout additional articles on PHP troubleshooting. Performance Issues  Best way to identify your application performance issues, is to profile your application. Use Xdebug profiler to profile your application. The most common reasons that could impact performance are:  PHP error reporting is turned on. If your application is returning too many warnings that is causing PHP process to write to php_errors.log. This can impact performance. Your app is making too many I/O operations. Note that the file storage is Azure Storage linked to your web app like a network drive. Too many calls to read or write can impact performance. You can reduce the read operations by using Wincache filecache and Wincache reroute settings. App may be causing an overhead on the database by making too many calls to the database. Use Wincache or Redis cache to reduce the stress on your database.  Security Issues   Using mysql extension: MySQL extension has been officially deprecated . It does not support SSL and does not support for many MySQL features. Using this is a security risk and users can look for the php warning \"The mysql extension is deprecated and will be removed in the future\" and identify if a site is using mysql extension. Upgrade your mysql driver to use mysqli instead of mysql extension.  &lt;?php $mysqli = new mysqli(\"localhost\", \"user\", \"password\", \"database\"); if ($mysqli-&gt;connect_errno) { echo \"Failed to connect to MySQL: (\" . $mysqli-&gt;connect_errno . \") \" . $mysqli-&gt;connect_error; } echo $mysqli-&gt;host_info . \"\\n\"; ?&gt;   Disable development configurations: Disabling all your development environment configuration such as debug configuration. This opens your application to security risk allowing access to malicious users to information on your web app.  Using \"admin\" username for your web app administration dashboard : All CMSs like WordPress, Drupal etc. provide you're with an administration dashboard. admin is the most common username used for a super administrator user and can be easily hacked by malicious users. Hence NEVER use admin as a username for your super administrator for your web application. It is recommended to enforce a strong username and password for a super administrator users.        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/09/14/PHP-troubleshooting-guide-for-common-errors.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Get some hands-on time with Serverless development right now, for free",
        "excerpt":"      Yochay Kiriaty     10/4/2016 4:38:07 PM  If you are reading this blog, you have most likely heard the term Serverless once or twice in the past few months. In a nutshell, Serverless means a fully managed platform capable of running your code (in the form of functions), at almost any given scale while paying only for the time when your code is running. Serverless is sometimes categorized as ‘reactive’ compute, where functions are executed (react) when specific events occur. For the purpose of this blog, I will focus on the developer experience.  There are several options to get firsthand experience with Serverless development, but all options require creating an account (typically providing credit card information) with a vendor. This changes today. Now you you can get a peek into the world of Serverless for free (no credit card required) with no commitment. If you have a Microsoft, Google, or Facebook account you can get started immediately. To get an hour of free Azure Functions experience browse to https://functions.azure.com and click the big green Try-It-For-Free button. Azure Functions is a Serverless compute, event driven experience that extends the existing Azure App Service platform. Azure Functions can scale based on demand and are billed only for resources consumed.  Try Azure Function experience gives you the ability to create Azure functions and run them, even without an Azure account. Since this a “Try” experience, you don’t have access to all binding and triggers supported by Azure Functions, and you only have one hour each time you log-in. However, even with these limitations you can create cool Serverless examples.  Ready? let’s get started   Let’s start out by using the Try Azure Functions experience to create a simple HTTP trigger function..  Here is a very simple HTTP trigger “Hello World” example. Try it yourself:  Login to Try Functions (go to https://functions.azure.com and click the green Try-It-For-Free button) Choose Webhook + API scenario (many other templates are available for other scenarios) Choose your programming language between C# or JavaScript (node.js). Azure Functions support additional languages like F#, Python, PowerShell and CMD. Click “Create this function” button, which will prompt you to login Login with your selected social identity, wait for few seconds… and you have an HTTP trigger function ready for use       You can copy the Azure Function URL (highlighted below) and paste it into your browser. You should receive a response. You might want to add &amp;name=YourName to the Function URL as the default http trigger template expects name query parameter. Just like that, you created a fully working HTTP endpoint in the cloud.    While this was is an impressive example of how easy it is to create an HTTP endpoint in the cloud, it turns out you can do quite a lot more!  Let’s put together the following scenario. Upload an image that includes some text in it, run an OCR on the image to extract the text, store the text, and finally retrieve both image and text. For small images or for a low volume of image uploads, you can probably do it all in a single Function. However, we want to leverage the Serverless nature of Azure Functions to create a scalable and highly performant design. To do so, we will create three functions:  An HTTP trigger function exposing simple REST API to upload an image. A blob trigger function that will extract the text from the image when it id uploaded to the blob storage. Another HTTP trigger function exposing simple REST API to query the results of the text extraction.      First Function – a simple REST API uploading an image to Azure Blob  You can imagine a scenario in which you have a web or mobile app that needs to upload images for processing. A function receiving the uploaded image can expect an HTTP POST from an HTML form that might look like this:      &lt;label&gt;         Using JQuery     &lt;/label&gt;     &lt;input name=\"file\" type=\"file\" id=\"me\" /&gt;     &lt;input type=\"button\" id=\"Upload\" value=\"Upload\" /&gt; &lt;/form&gt;     We want our function to receive an image and store it in Azure Blob Storage. This is a classic reader/writer pattern, where you want your API layer to do as little complex computing as possible.  The Azure Functions concept of Bindings enables developers to directly interact with the input and output values of Functions data sources. Those include Azure Storage Queue, Tables, and Blobs as well as Azure Event Hubs, Azure DocumentDB and more. Click here for full list of binding.  Let’s add an Azure Blob output binding. On the Integrate tab, click New Output and choose Azure Storage Blob.    The Blob parameter name, is an input argument (parameter) passed to your Function. Just like you would expect when programing any regular function. Azure Functions takes it one step further, enabling to use such bindings without knowing anything about the underlying infrastructure. This means that you don’t need to know how Azure Storage works or install Storage SDKs to use Azure Blob as your function output. You just use the outputBlob object in your function, save the image to that blob and the uploaded image will appear in your Storage Blob. In the try experience you don’t have a direct access to the underline storage account powering your Functions. However, you will see it in action by the time you complete the 3rd function. Make sure you update the Path to include “.jpg”, and hit Save.    In the function code, we refer to outputBlob as an object that is ready to be used. This function is implemented in C# and uses StreamProvider to read the image data from the HTTP request and store it to an Azure Blob. I don’t have any idea how Azure Storage works. Behind the scenes Azure Functions takes care of moving data in to and out from my functions. It is like magic, quick and easy to use. #r \"Microsoft.WindowsAzure.Storage\"  using System.Net; using Microsoft.WindowsAzure.Storage.Blob;  public static HttpResponseMessage Run(HttpRequestMessage req, Stream outputBlob, TraceWriter log)  {     log.Info($\"C# HTTP trigger function processed a request. RequestUri={req.RequestUri}\");      HttpResponseMessage result = null;            if (req.Content.IsMimeMultipartContent())     {             // memory stream of the incomping request              var streamProvider = new MultipartMemoryStreamProvider ();              log.Info($\" ***\\t before await on ReadMultpart...\");             req.Content.ReadAsMultipartAsync(streamProvider);             log.Info($\" ***\\t after await on ReadMultpart...\");                          //using a stream saves the 'last' iamge if multiple are uplaoded             foreach (HttpContent ctnt in streamProvider.Contents)             {                 // You would get hold of the inner memory stream here                 Stream stream = ctnt.ReadAsStreamAsync().Result;                 log.Info($\"stream length = {stream.Length}\"); // just to verify                                  // save the stream to output blob, which will save it to Azure stroage blob                 stream.CopyTo(outputBlob);                  result = req.CreateResponse(HttpStatusCode.OK, \"great \");             }                     }         else         {             log.Info($\" ***\\t ERROR!!! bad format request \");             result = req.CreateResponse(HttpStatusCode.NotAcceptable,\"This request is not properly formatted\");         }     return result; }    Second Function – Performs OCR  Let’s create the second function, called ImageOCR. This function will be triggered every time a new image file is uploaded to the blob storage container (named outcontainer) by the first function. Then the function will run OCR on that image to extract text embedded in it. Note, this function will run only when a new image (or any other file…) is uploaded to the blob. Again, this is Serverless in its best form, your code will run only when needed and you will pay only for that time.    Make sure the Azure Storage Blob container name you use to trigger is the same as the Blob container name used to write the image from the first function. If you have not changed the default, the container name of the first function is outcontainer. #r \"System.IO\" #r \"System.Runtime\" #r \"System.Threading.Tasks\" #r \"Microsoft.WindowsAzure.Storage\"  using System; using System.IO; using System.Text; using System.Threading.Tasks; using Microsoft.WindowsAzure.Storage.Blob; using Microsoft.ProjectOxford.Vision; using Microsoft.ProjectOxford.Vision.Contract; using Microsoft.WindowsAzure.Storage.Table;  public class ImageText : TableEntity {     public string Text { get; set; }     public string Uri {get; set; } }  public static void Run( ICloudBlob myBlob, ICollector outputTable, TraceWriter log)  {      try       {         using (Stream imageFileStream = new MemoryStream())         {              myBlob.DownloadToStream(imageFileStream);              log.Info($\"stream length = {imageFileStream.Length}\"); // just to verify              //             var visionClient = new VisionServiceClient(\"YOUR_KEY_GOES_HERE\");              // reset stream position to begining              imageFileStream.Position = 0;             // Upload an image and perform OCR             var ocrResult = visionClient.RecognizeTextAsync(imageFileStream, \"en\");             //log.Info($\"ocrResult\");              string OCRText = LogOcrResults(ocrResult.Result);             log.Info($\"image text = {OCRText}\");              outputTable.Add(new ImageText()                             {                                 PartitionKey = \"TryFunctions\",                                 RowKey = myBlob.Name,                                 Text = OCRText,                                 Uri = myBlob.Uri.ToString()                             });                     }      }     catch (Exception e)      {         log.Info(e.Message);     } }  // helper function to parse OCR results  static string LogOcrResults(OcrResults results) {     StringBuilder stringBuilder = new StringBuilder();     if (results != null &amp;&amp; results.Regions != null)     {         stringBuilder.Append(\" \");         stringBuilder.AppendLine();         foreach (var item in results.Regions)         {             foreach (var line in item.Lines)             {                 foreach (var word in line.Words)                 {                     stringBuilder.Append(word.Text);                     stringBuilder.Append(\" \");                 }                 stringBuilder.AppendLine();             }             stringBuilder.AppendLine();         }     }     return stringBuilder.ToString(); }  The function is triggered by any file uploaded to the blob container. The default input parameter type of the function is string, but I will be using ICloudBlob, as I want to read the image as a stream and I want to get the image file name and URI. As you can see, Azure Functions binding provides a very rich experience.  To perform the OCR on a given image, I am going to use using Microsoft Cognitive Services , also known as Project Oxford. I could use any 3rd party tool, bring a dll that implements the algorithm, or write my own. However, leveraging other services as much as possible is a core tenant of Serverless architecture. If you don’t have a Cognitive Services account, sign up for free at https://www.microsoft.com/cognitive-services  Using the Cognitive Services is very easy, it comes down to two lines of code:   var visionClient = new VisionServiceClient(\"YOUR_KEY_GOES_HERE\");    // reset stream position to begining    imageFileStream.Position = 0;    // Upload an image and perform OCR    var ocrResult = visionClient.RecognizeTextAsync(imageFileStream, \"en\");  In order to make the ImageOCR function code work, you’ll need to import ProjectOxford assemblies. Azure functions support project.json files to identify nuget packages (for C#) to be automatically restore with the function. For node.js Azure Functions support npm.  In the Functions UI, click on View files and add project.json with the following text. once you save this file, Azure Functions will automatically restore the ProjectOxford package.       In order to make the ImageOCR fFunction code work, you’ll need to import Project Oxford assemblies. Azure Ffunctions supports a project.json files to identify nuget NuGet packages (for C#) to be automatically restored with the functionFunction. For node.js, Azure Functions supports npm.  In the Functions UI, click on View files and add project.json with the following text. Oonce you save this file, Azure Functions will automatically restore the Project Oxford packages.   project.json    {     \"frameworks\": {       \"net46\":{         \"dependencies\": {           \"Microsoft.ProjectOxford.Vision\": \"1.0.370\"         }       }     }   }     We want to save the results somewhere. In this Try Functions example we are using Azure Storage Table. Note – if you have an Azure Subscription, you can use many other Data Services provided by Azure to store and process the results.  Let’s add an output binding to Azure Table Store       Next, change the Table name from the default to ImagesText. The Table parameter name, outputTable will be used in the function code.       And again, just like with the blob, I don’t need to know a lot about how Azure Storage Tables work. Azure Functions is doing all the heavy lifting. We are using the ImageText table to store the image Uri (pointer to the blob storing the image), the OCR results, and the table keys in the form of a GUID.  You have now completed the creation of a function that scans an image, extracts text from it and stores the results into persistent storage. Third Function – simple REST API to query OCR results  The last function we are going to create is of type HTTP trigger and will be used to return list of images and the text we extracted from the images in the second function.  This time we will add an Azure Storage table as an input binding, because you would expect your function to receive the table store object to work with and extract the data. As before, make sure you are using the same table name you used in the second function. Note the Partition Key, which is optional was hard-coded for TryFunctions.    The function input argument is of type IQueryable&lt;ImageText&gt;, which represent a collection of results queried from Table Storage. Its ready to use without any knowledge of how Azure Table Storage works, I get a list I can work with. We create a SimpleImageText object representing the response and return a JSON representation of the data.   #r \"System.IO\"   #r \"System.Runtime\"   #r \"System.Threading.Tasks\"   #r \"Microsoft.WindowsAzure.Storage\"   #r \"Newtonsoft.Json\"    using System;   using System.Net;   using System.IO;   using System.Text;   using System.Threading.Tasks;   using Microsoft.WindowsAzure.Storage.Table;   using Newtonsoft.Json;    public static async Task Run(HttpRequestMessage req, IQueryable inputTable,  TraceWriter log)   {       log.Info($\"C# HTTP trigger function processed a request. RequestUri={req.RequestUri}\");        var result = new List();        var query = from ImageText in inputTable select ImageText;       //log.Info($\"original query --&gt; {JsonConvert.SerializeObject(query)}\");        foreach (ImageText imageText in query)       {           result.Add( new SimpleImageText(){Text = imageText.Text, Uri = imageText.Uri});           //log.Info($\"{JsonConvert.SerializeObject()}\");       } //    log.Info($\"list of results --&gt; {JsonConvert.SerializeObject(result)}\");        return req.CreateResponse(HttpStatusCode.OK, JsonConvert.SerializeObject(result));   }    // used to get rows from table   public class ImageText : TableEntity   {       public string Text { get; set; }       public string Uri {get; set; }   }    public class SimpleImageText   {       public string Text { get; set; }       public string Uri {get; set; }   }    We created three functions, it is time to test them.  You can use any of your favorite tools to generate HTTP calls, including CURL, writing a simple html / Java script, or anything else. To test both HTTP functions I’ll use Postman, using form-data as a Body to POST to the first function URL. You should receive “great” as a response and if you look at the first function log, in the Try Azure Function UI, you will notice traces from your function. If something went wrong, try debugging it… or ping me on Twitter (@yochayk)       Assuming your first function worked, go to the OCR image function and upload another image. You will notice that the OCR function got triggered, which means your first function successfully saved the image to storage and your second function picked it up. Again, you should see in the log traces from your function.  Use Postman to call the last function and you should see JSON array including two images and the text extracted from them.       here is repo with the function. Note, my solution is a little more complex and includes handling multiple uploaded files and adding a SAS token to the container.  One small note: if you want to view the images, you will need to generate a SAS token for the container, as by default, an Azure Blob Storage container permission blocks public read access. I’ve added the required code, which generates a 24 access token to images, to the ImageViewText functions. You will also need to pass the blob container as input argument for the functions.   // IQueryable return list of image text objects   // CloudBlobContainer used to generate SAS token to allow secure access to image file   public static async Task Run(HttpRequestMessage req, IQueryable inputTable, CloudBlobContainer inputContainer,  TraceWriter log)   {       log.Info($\"C# HTTP trigger function processed a request. RequestUri={req.RequestUri}\");        //get container sas token       var st = GetContainerSasToken(inputContainer);       //log.Info($\"token --&gt; {st}\");       var result = new List();        var query = from ImageText in inputTable select ImageText;       //log.Info($\"original query --&gt; {JsonConvert.SerializeObject(query)}\");        foreach (ImageText imageText in query)       {           result.Add( new SimpleImageText(){Text = imageText.Text, Uri = imageText.Uri + st});           //log.Info($\"{JsonConvert.SerializeObject()}\");       }        return req.CreateResponse(HttpStatusCode.OK, JsonConvert.SerializeObject(result));   }    // used to get rows from table   public class ImageText : TableEntity   {       public string Text { get; set; }       public string Uri {get; set; }   }    public class SimpleImageText   {       public string Text { get; set; }       public string Uri {get; set; }   }    // generate 24 hour SAS token for the container. Will allow read for all images   // TBD -  shoudl be done once every 24 hours via timer, rather than each time in the funciton    static string GetContainerSasToken(CloudBlobContainer container)   {       //Set the expiry time and permissions for the container.       //In this case no start time is specified, so the shared access signature becomes valid immediately.       SharedAccessBlobPolicy sasConstraints = new SharedAccessBlobPolicy();       sasConstraints.SharedAccessExpiryTime = DateTime.UtcNow.AddHours(24);       sasConstraints.Permissions = SharedAccessBlobPermissions.Read;        //Generate the shared access signature on the container, setting the constraints directly on the signature.       string sasContainerToken = container.GetSharedAccessSignature(sasConstraints);        //Return the URI string for the container, including the SAS token.       return sasContainerToken;   }     With the updated ImageViewText function you can now test your application with a simple Single Page Application I host on Azure Storage http://tryfunctionsdemo.blob.core.windows.net/static-site/test-try-functions.html   This simple HTML application has two text box for you to paste the URL of your function. You upload an image by dragging and dropping. You can get images by clinking the GetImages button. The screen capture shows the network calls and console for getting images. You can see on the console, the get images return array of images, with respective URIs and each image text, which we use to then display. Note the images have SAS tokens.  Hope you enjoy trying Azure Functions as much as I enjoyed writing this little demo. If you have any issues ping me on Twitter (@yochayk).     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/10/04/Get-some-hands-on-time-with-Serverless-development-right-now,-for-free.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service Mobile Apps .NET Client SDK 3.0.1 Release",
        "excerpt":"      Mimi Xu (Azure)     10/6/2016 1:53:07 PM  We just rolled out Azure Mobile Client SDK 3.0.1 and Azure Mobile SQLiteStore 3.0.1! Here are the updates we made:  This Mobile Client SDK release is out of 3.0.0-beta! The previous Mobile SQLiteStore 2.x.x libraries depending on SQLitePCL, which uses the Android system SQLiteStore, no longer works with Android Level 24/Android N. Starting with Android Level 24/Android N, the Android system SQLiteStore cannot be accessed expect through the android.database.sqlite Java wrapper (Eric Sink has a great blog post here detailing the issue). This enforcement from Android impacts customers working with native Android, Xamarin.Android, and Xamarin.Forms Android. This 3.0.1 release updates the Mobile SQLiteStore library to take dependency on SQLitePCLRaw.bundle_green and SQLitePCLRaw.Core to resolve this problem. We unified versions across .NET Client SDK and SQLiteStore library to make dependencies and developer experience more straightforward.  To take advantage of the releases, simply uninstall dependencies to your client project and grab the latest versions with Visual Studio package manager. Let us know if you bump into any issues!     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/10/06/App-Service-Mobile-Apps-.NET-Client-SDK-3.0.1-Release.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Upgrade ClearDB MySQL database in Azure portal",
        "excerpt":"      mksunitha     10/6/2016 10:52:42 AM  ClearDB MySQL database now supports single step upgrade in Azure portal. If you using a ClearDB database you may at some point in time hit quota limitations on ClearDB such as max connections or storage limits . For more details in pricing tiers and quota limits click here. How to upgrade your ClearDB MySQL database   Login to Azure portal Click on All resources and select your ClearDB MySQL database Click on Settings-&gt;Scale up your database    4. Select the pricing tier. Currently on single step upgrade is supported , which means if the current pricing tier is Mercury , you can upgrade to Titan . You cannot upgrade from Mercury pricing tier to Venus pricing tier at the skipping other pricing tiers during the upgrade.  Key things to remember:   Currently this feature does not support downgrade from higher pricing tier to a lower pricing tier. If you are using a database on Jupiter tier. You will not see scale up database setting in the Azure portal .            ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/10/06/Upgrade-ClearDB-MySQL-database-in-Azure-portal.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing Azure App Service Companion preview",
        "excerpt":"      Byron Tardif     10/10/2016 12:04:17 PM  UPDATE: Azure App Service companion is now available in the Apple App Store for your iOS devices   Today when you are managing your existing Azure App Service assets you have two options, the Azure Portal, or Azure CLI both of these experiences are great when used in your laptop/desktop regardless of what operating system you are using. However, neither of them are tailored for use in mobile scenarios. This is where Azure App Service Companion comes into play.  The goal for Azure App Service Companion is to provide the basic functionality that you need when you are on the go, without requiring you to use your laptop. All in a native experience for your device.   Azure App Service Companion allows you to:  Monitor your App Service instances View custom alerts based on site status Troubleshoot sites from anywhere           The initial preview release for the app is now available in Google Play, we will be adding more functionality and new features in the coming weeks.  If you have any questions about this app or App Service in general be sure to check our forums in MSDN and Stack Overflow. For any feature requests or ideas check out our User Voice  In order to use the full capabilities of this application, you need to have an active Microsoft Azure subscription. To learn more about Azure subscriptions, see http://aka.ms/AzureSubscriptions.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/10/10/Announcing-Azure-App-Service-Companion-preview.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Streamlined integration of App Service and Application Insights",
        "excerpt":"      Byron Tardif     10/10/2016 9:34:51 AM  Application Insights helps you detect and diagnose quality issues in your web apps and services, and enables you to understand what users actually do with them.  We believe that Application Insights provides great value to Azure App Service users and that’s why we have made it super easy to enable this for your app from within the Azure portal.    The new Application Insights experience can be started form the Application Insights menu item in the monitoring section for any Web, Api or Mobile app.    If your app is not already configured to use Application Insights, the UX will allow you to link it to an existing Application Insights resource or create a new one on the fly.    Once the Application Insights resource has been created and the link between it and your app is in place, you will start to see data stream into the UX, assuming there is currently traffic on your app.  You can get even more data, customize views, queries and a lot more by going to the Application Insights resource blade:  You can learn more about Application Insights here  If you have any questions about this UX or App Service in general be sure to check our forums in MSDN and Stack Overflow and for any feature requests or ideas check out our User Voice      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/10/10/Streamlined-integration-of-App-Service-and-Application-Insights.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Mobile Apps .NET SDK v3.0.2 Released",
        "excerpt":"      Adrian Hall (MSFT)     10/11/2016 1:42:04 PM  Today, we released a patch version of the Azure Mobile Apps .NET SDK.  If you have already adjusted your clients to use v3.0.1, then this update does not provide any benefit.  However, if you are upgrading from v2.x to get support for Android Nougat, you should use v3.0.2.    Here are the improvements:   (#233, #235, #240) The .NET SDK v3.0.1 required iOS and Android developers to create the offline database file prior to its use.  This is no longer a requirement. (#236) The SQLitePCL.Batteries.Init() initialization code was called multiple times.  We also suggested that you call it yourself.  You no longer have to call it yourself, and it is only called once. (#231, #232) We have updated documentation.  The documentation now clarifies our supported platforms, and the HOWTO includes the new instructions for working with offline data.   In addition, we've updated the quick start projects that you can download from the Azure portal to use the new SDK.  As always, we encourage you to post on Stack Overflow if you are running into problems.  If you find a bug or want a feature, please file an issue on our GitHub repository.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/10/11/Azure-Mobile-Apps-.NET-SDK-v3.0.2-Released.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Mobile Apps iOS SDK 3.2.0 – Refresh Token, iOS 10Swift 3 Support, and Performance Improvement",
        "excerpt":"      Mimi Xu (Azure)     10/12/2016 8:54:25 AM  We are excited to bring you the latest release of our Mobile Apps iOS client SDK 3.2.0 (CocoaPods). There are a few updates in this release:  We extended support for Refresh Token for all of our iOS customers. This feature was previously only captured in our Managed SDK 2.1.0 and later versions to enable a smoother development experience around identity provider token expiry. For more information on this feature, see the Refreshing User Logins in App Service Mobile Apps blog post. We added support for the latest iOS environments iOS 10. It also works with Xcode 8.1 and Swift 3. We optimized network performance by reusing NSURLSession objects. This is particularly apparent in long-running async operations like data pulls. (Shout out to Damien Pontifex for his continuous support in helping to improve our iOS SDK through open source contributions).  The latest Mobile Apps iOS Quickstart is also available and compatible with this release of the iOS SDK.  Try these out and let us know what you think!     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/10/12/Azure-Mobile-Apps-iOS-SDK-3.2.0-Refresh-Token,-iOS-10Swift-3-Support,-and-Performance-Improvement.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure App Service Companion preview now available for iOS",
        "excerpt":"      Byron Tardif     10/19/2016 9:29:46 AM  On October 10 we released the preview for Azure App Service companion to the Google Play Store and today we are expanding the preview to iOS devices as well.  As with the Android version of the app the focus is to provide the basic functionality that you need when you are on the go, without requiring you to use your laptop. All in a native experience for your device.   Azure App Service Companion allows you to:  Monitor your App Service instances View custom alerts based on site status Troubleshoot sites from anywhere           If you have any questions about this app or App Service in general be sure to check our forums in MSDN and Stack Overflow. For any feature requests or ideas check out our User Voice  In order to use the full capabilities of this application, you need to have an active Microsoft Azure subscription. To learn more about Azure subscriptions, see http://aka.ms/AzureSubscriptions.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/10/19/Azure-App-Service-Companion-preview-now-available-for-iOS.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions portal and host improvements",
        "excerpt":"      Donna Malayeri     10/26/2016 2:00:59 AM  Based on lots of great customer feedback, we've redesigned the Azure Functions portal experience. Now you can see more of your code and see your logs and the Run window at the same time. The Run window has new features for HTTP-triggered functions: you can now specify the HTTP verb and add query parameters and request headers. This makes it easy to test these functions without leaving the Functions portal.  Aside from the visual improvements, we've released a lot of great new functionality in the Azure Functions 0.7 host and 0.8 host, including support for custom routes and route templates. Portal  You can now view the editor in a classic three-pane view, where your code is at the top, logs are at the bottom, and the Run tab is on the right. You can show and hide the logs and the Run tab to allow more room for editing code. Check out the new buttons on the right (highlighted with a purple rectangle in the screenshot below).    Clicking on the Run button will pull up the test harness, which will let you easily craft HTTP calls without having to launch a new tool. Just choose your verb and add query parameters and headers. (Note that we're not trying to reinvent other great HTTP tools like Fiddler or Postman, but we've heard from customers that it's convenient to quickly run HTTP triggered functions without leaving the Azure portal.)    HTTP and Webhook triggers now have richer options in the Integrate tab. You can now easily restrict the permitted HTTP verbs by choosing \"Selected methods\" and checking off the appropriate options.   API Routing  The portal is not the only place we've made changes--the Azure Functions Host is now at version 0.8. By popular request, we've added the following:  Custom route support. You can now specify complex route constraints, such as \"route\": \"products/{Category:alpha}/{Id:int}\". The supported constraints are the same as those in ASP.NET Web API Attribute Routing. Route prefix customization. Customize the api route prefix (or remove it completely) in host.json.  To learn more, see Route support in the Azure Functions triggers and bindings developer reference. Provide feedback  As always, we're interested in your feedback. There are a lot of channels available:  Ask questions below! Ask product questions on the Azure Functions MSDN forum and StackOverflow, where you'll get answers directly from the engineering team. Submit general feedback on feedback.azure.com. Reach out to us on Twitter via @Azure with the hashtag #AzureFunctions.  Our development is done in the open, so we encourage you to watch issues, ask questions and see our progress. You can submit issues directly on GitHub (Functions Host repo and Functions Portal repo). If you're not sure where an issue belongs, you can file it on the Azure-Functions GitHub repo.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/10/26/Azure-Functions-portal-and-host-improvements.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Making Azure Functions more “serverless”",
        "excerpt":"      Chris Anderson (Azure)     11/15/2016 10:00:07 AM  One of the principles we believe in most for Azure Functions is that we want you to be solving business and application problems, not infrastructure problems. That’s why we’ve invested so much in the functions runtime (language abstractions, bindings to services, and lightweight programming model) as well as our dynamically scaling, serverless compute model. Given that goal, one thing has always stuck out in our experience: the memory setting you set for each of your Function Apps. The memory setting always felt out of place. Finding the optimal setting required lots of trial and error on the part of our users, and we’ve heard a lot of feedback from users that it’s not something which people want to; that it doesn’t feel very serverless. That is why today, we’re announcing that we’re no longer requiring you to set the memory setting; Azure Functions, in the Consumption Plan, will automatically decide the right resources to have available and only charge you for what you use, not just time but also memory/cpu. How does Azure Functions manage my resources?  The Azure Functions platform collects a lot of data about how much utilization and resources your functions take when they execute. This enables us to make very accurate estimations of what you’ll need and distribute the work behind the scenes. The first time you run your Function, we’ll place it in the best a place possible, and should it appear to need more resources, we’ll find and allocate them automatically. We’ll continually be improving our algorithms to make sure that you have the best experience and that we do it as cost effectively as possible on our side.  We have confidence that we can do this effectively because we’ve been modeling it with real data for a while now. Below is a graph with the actual numbers redacted, but y-axis is in linear GB-sec, and the base is 0; the x-axis is time. The blue line, on top, is the current amount of billable GB-sec. The red line, on bottom, is the new amount of billable GB-sec in our system. This means, overall, our customers are now paying for 5 times less GB-sec than they were before. Today, users can confidently write Functions without worrying about the right memory setting, knowing they’ll pay the least for their functions.   Do I need to rethink how I write my functions?  Overall, no, things work pretty much the same as before, with just one less setting to worry about. The same limits that applied before still apply: 1.5GB max memory and a 5-minute max execution time. The biggest impact that this change has is that you now are assured to be getting the right amount of resources and paying the least amount possible for your function executions. How to think about serverless computing  To help understand the impact of this change, let’s look at computing through an analogy. Imagine that compute works like shipping. Hosting your compute on prem is like buying a truck and paying the drivers yourself; you’re responsible for the hardware and the operational costs of operating that vehicle and the personnel. Infrastructure as a Service (IaaS - aka VMs) are like renting a truck, but still employing your own drivers; you’re no longer responsible for the hardware, but some operational costs (gas, maintenance, etc.) and the personnel costs still fall on you. Moving further up the hierarchy of compute, you can go with a fully managed Platform as a Service (such as Azure App Service) is like hiring a full-service company who will bring their truck and crew for you; you’re not responsible for the hardware or operational costs. But what if I want to just ship a bunch of small packages? Often it doesn’t make sense to pay by the truck, but rather by the package. This is where serverless computing stands to be transformative for how we build applications. We don’t have to focus on how shipping works because it’s not core to our business; we can focus instead on just getting the product to our customers. Each execution is like a package, and we pay for the size of the box.  The change we’re making today, by removing set memory sizes, is made because compute while compute has similarities, it isn’t exactly like shipping physical objects. Knowing how much work is going to come in or what the right amount of compute (CPU/memory/IO) is not as simple as how tall and wide an object is; your resources required can change on each execution or even throughout an execution. Instead, we’ll now trigger your event and find the right size “package” for it, and only charge you for use, both time and resources. The future is even brighter, together  We’re committed to building the best serverless compute with the easiest experience and most powerful features. We want to know what we can make smoother. What questions do you have to ask yourself as you build functions? How can we make things easier, faster, better when you’re building your applications?  Reach out to us in whatever way you prefer with issues, ideas, or questions:  Feedback portal: azure.com GitHub: azure/azure-functions Twitter: #AzureFunctions Stack Overflow: azure-functions tag      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/11/15/Making-Azure-Functions-more-serverless.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "URL Authorization Rules",
        "excerpt":"      Chris Gillum (MSFT)     11/17/2016 3:40:36 PM  One of the goals of Azure App Service Authentication / Authorization is to make it very easy to add \"auth\" to your App Service apps (which is why we often refer to it as Easy Auth). Most of our investments so far have been focused on creating a streamlined authentication setup experience. However, up until now authorization was something developers had to implement mostly on their own. Typically authorization rules involve restricting access to certain resources within your app. Ideally, such authorization rules can be just as simple to set up without writing a bunch of custom code. To that end, we're happy to announce the initial preview of URL Authorization Rules in App Service. Configuration  In the initial preview, URL Authorization Rules are defined in an authorization.json file (if you prefer, we also support the YAML syntax inside an authorization.yaml file).  The feature is enabled automatically when you configure Easy Auth in the management portal and place either an authorization.json file or an authorization.yaml file in the D:\\home\\site\\wwwroot directory of your App Service app. This means you can include the file in your app's source and easily deploy it via Git, Web Deploy, FTP, or any of the continuous deployment mechanisms supported by App Service.  Here is the basic schema of the configuration file in the JSON syntax: {   \"routes\": [     {       \"http_methods\": [ \"GET\", \"POST\", \"PUT\", ... ],       \"path_prefix\": \"/some/url/prefix\",       \"policies\": {         \"unauthenticated_action\": \"AllowAnonymous|RedirectToLoginPage|RejectWith401|RejectWith404\"       }     },     ...   ] }  Now let's talk about what these properties are for:  routes: Required. A collection of URL authorization rules for your App Service app.  In this preview release, each route contains an http_methods, a path_prefix, and a policies property, described below.   http_methods: Optional. An array of HTTP verbs that can be used to trigger a route policy. If not specified, all HTTP verbs can be used to trigger the policy. path_prefix: Required. A relative URL path under which the specified policies will be enforced. More details on this in a subsequent section. policies: A collection of policies to enforce when an HTTP request matches a route. At the time of writing, the only supported sub-property is unauthenticated_action. unauthenticated_action: Required. One of the following values:  AllowAnonymous: Allows anonymous clients to access the resource. RedirectToLoginPage: If a user is unauthenticated, they will be redirected to the login page of the default identity provider that was configured in the portal (for example, Azure Active Directory). RejectWith401: Unauthenticated requests will fail with an HTTP 401 status. RejectWith404: Unauthenticated requests will fail with an HTTP 404 status. You would choose this over RejectWith401 when you want to hide the existence of HTTP routes within your app.       As you can see, there are quite a few ways in which you can configure URL-based authorization policies for your app. Route Evaluation Order and Wildcards  In the simplest case, your authorization.json (or authorization.yaml) file will contain one or more static routes. For example, consider the following authorization.json file contents, which represent authorization rules for an Azure Functions app with two HTTP triggers: {   \"routes\": [{       \"path_prefix\": \"/api/AnonymousHttpFunction\",       \"policies\": { \"unauthenticated_action\": \"AllowAnonymous\" }     },{       \"path_prefix\": \"/api/ProtectedHttpFunction\",       \"policies\": { \"unauthenticated_action\": \"RejectWith401\" }     }] }  All HTTP requests to /api/AnonymousHttpFunction will be allowed, but requests to /api/ProtectedHttpFunction will require a client to be authenticated (e.g. using an access token).  This works well for simple, static APIs but many modern REST-ful APIs will have parameterized URL segments. In those cases, you'll want to take advantage of wildcard segments for your authorization routes. For example, consider a REST-ful API for viewing chapters of books. The name of the book and the chapter may be embedded in the URL: {   \"routes\": [{       \"http_methods\": [ \"GET\", \"HEAD\" ],       \"path_prefix\": \"/api/book/*/chapter/*/content\",       \"policies\": { \"unauthenticated_action\": \"RejectWith401\" }     }] }  In the above example there is a wildcard * for both the name of the book and the chapter number. The * will match any single value within that segment.  If your routes represent a resource hierarchy, you will likely need to configure separate policies for parent and child resources. Consider then the following example: {   \"routes\": [{       \"path_prefix\": \"/\",       \"policies\": { \"unauthenticated_action\": \"AllowAnonymous\" }     },{       \"path_prefix\": \"/admin\",       \"policies\": { \"unauthenticated_action\": \"RedirectToLoginPage\" }     }] }  In this case, all URLs will be publicly accessible to anyone on the internet except those at or under /admin, which require a user to log in first. In the case of a browser client, navigating to /admin or a sub-path like /admin/edit_content.php will result in an automatic redirect to the configured login page. Now, technically a request such as GET /admin/edit_content.php which I used as an example matches both \"/\" and \"/admin\" routes. How do we decide which policy to execute? The answer is that the authorization runtime will always execute the policy with the most specific matching URL path (sometimes known as \"longest-prefix matching\") and only that policy will be executed. Example: File Share  The nice thing about the example below is that it literally requires no code - at all. The idea is that you want to put some files on the web and protect access to them. It's also very easy to set up.  The first thing you'll want to do is create a web app and configure Easy Auth with Azure Active Directory login. You could choose another provider, but AAD is the simplest to set up. This can be done in a few clicks in the portal as shown in the following screenshot. Make sure to select Allow Anonymous requests (no action) under the \"Action to take when request is not authenticated\".  [caption id=\"attachment_2095\" align=\"alignnone\" width=\"851\"] Setting up Easy Auth with Azure AD authentication.[/caption]  Now that your AAD setup is ready, it's time to create the app. Because we're only dealing with file contents, this is easy to setup manually using the Kudu console, which can be found under Settings -&gt; Advanced Tools. Or, you can navigate to it directly at https://{web-app-name}.scm.azurewebsites.net/DebugConsole. Use the following commands to create the necessary files.  cd site\\wwwroot  del hostingstart.html  mkdir public  echo \"hello, public!\" &gt; public\\file1.txt  mkdir admin  echo \"hello, admin!\" &gt; admin\\file2.txt  This will set up your file system structure with some folders and files.  Next we want to enable directory browsing, which is disabled by default. We do this by creating a web.config file in the wwwroot directory. You can create it using the touch web.config command and edit by clicking the edit button and populating it with the following configuration: &lt;!--?xml version=\"1.0\"?--&gt; &lt;configuration&gt;   &lt;system.webserver&gt;     &lt;directoryBrowse enabled=\"true\"/&gt;   &lt;/system.webserver&gt; &lt;/configuration&gt;  Lastly, we need to create the authorization.json file.  You can use the command touch authorization.json to create the file. Then, click the edit button and add the following file contents: {     \"routes\":[{         \"path_prefix\" : \"/public\",         \"policies\" : { \"unauthenticated_action\" : \"AllowAnonymous\" }     },{         \"path_prefix\" : \"/admin\",         \"policies\": { \"unauthenticated_action\" : \"RedirectToLoginPage\" }     }] }  To test this, open a new In-Private/Incognito browser session and navigate to your web app. You should see a list of the directories you created as well as the web.config and authorization.json files (note that if you want to hide these infrastructure files, you can do so using the attrib +h {filename} command in the Kudu console). You can then navigate to the directories in your browser and observe the authorization behavior.  To help understand what's going on under the covers, I recommend enabling Application Logging in the portal and then opening the Log Stream blade to see the authorization logs in real-time.  [caption id=\"attachment_2165\" align=\"alignnone\" width=\"1227\"] Streaming Easy Auth logs in the Azure Portal[/caption] Conclusion  While the example above was a web apps example, this feature works the same whether you're writing a web app, a mobile app backend, an API app, or a Azure Functions app. However, remember that this is an early preview so there are a few things that need to be smoothed out before the feature can be considered GA. For example, when changing the authorization.json (or authorization.yaml) file, you must restart the site before the changes take effect. In the future we would like to have these updates be reflected immediately.  We are also working on additional authorization policies that can be configured. As an example, in a coming update you can expect to see support for restricting access to specified URL routes to Azure AD Security Groups (we actually support this in the runtime today, but need to smooth out the setup experience before we blog about it).  So give this a try and let us know how it goes. If you have questions, please head over to StackOverflow and tag them with azure-app-service or azure-web-sites, so that our automated processes can find them.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/11/17/URL-Authorization-Rules.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Use Azure Functions to run WordPress Cron",
        "excerpt":"      mksunitha     11/29/2016 12:32:02 PM  Cron is a time-based job scheduler and WordPress uses a file called wp-cron.php as a cron job to run scheduled tasks like publishing scheduled posts, managing updates to plugins and themes etc. WordPress is configured to wp-cron.php every time a user  visits your WordPress web app to check if a scheduled task is to be executed.  If your web app does get hundreds of users or more simultaneously , this adds significant overhead to your web app slowly it down for the users visiting it. For such cases it would be beneficial to isolate the wp-cron.php execution from the request made to your web app.  Azure app service offers Web Jobs or Azure functions  to build make a call to wp-cron.php file when it needs to be executed. Advantages of Functions over Web Jobs for your WordPress app  Few things to understand about your application before you make the choice :  If the cron job is CPU intensive and takes a long time to execute , it may put a large burden on your existing resources on the App service plan causing overhead. In such cases it would be more beneficial to use Azure Functions. Cost is the second criteria .  With Azure functions you get 400,000 GB-s execution time for Free which might be sufficient for WordPress app. Even if the execution is higher than 400,000 GB-s , the cost is 0.20 cents for million executions. Functions is still cost effective and it does not add overhead on your web app compute resources.  For this blog post I will show you how to use Azure Functions  so you can leverage server less architecture  and low cost since you pay for the number of times the code is executed due to the event based model.  You can use the same sample script for Web jobs if you intend to use the resources on your we app's app service plan. Click here to learn more about Web Jobs.  Follow the steps below to isolate wp-cron.php execution for your WordPress web app. STEP 1: Disable WordPress cron  Update wp-config.php file   and add this setting shown below to disable wp-cron.php from being executed at every user request. define('DISABLE_WP_CRON', 'true'); STEP 2 : Create a Function App using Timer trigger  Refer to instructions here to create a Function app or use this  sample function app to run WordPress cron  on Github . Azure function supports continuous deployment with Github .  Traditionally wp-cron.php  executes at every request to check if a task is scheduled to run. You can alternatively use the timer triggers which calls the azure functions based on a schedule, one time or recurring.   For example if you want the wp-cron.php to run every 15 mins you can use the following schedule which is Unix Cron like expression. \"schedule\": \"0 */15 * * * *\" To learn more about Timer trigger binding , click here.  There are two primary files :  function.json: This  file specified the bindings for the function app. In this case its a timer trigger as seen below which is scheduled to run every 15 minutes. You can view the json file here. {     \"bindings\": [         {             \"type\": \"timerTrigger\",             \"name\": \"timerInfo\",             \"direction\": \"in\",             \"schedule\": \"0 */15 * * * *\"         }             ] }   run.php : This script just make a HTTP call using PHP CURL and gets a response . Click here to view the script.  The logs will display the information of function starting , completing and the response received from the CURL call to wp-cron.php. In this example with the sample function app return a message \"Running WordPress CRON ..\"   Note: PHP support is still experiment for Azure Functions. You can use C# or Node.js or F# languages to make a HTTP call to the wordpress app wp-cron.php file , for example the URL would be like http://wordpress3295.azurewebsites.net/wp-cron.php?doing_wp_cron. This will trigger the cron to kickoff any scheduled tasks for WordPress app. References  Developer Reference for Azure Functions Best practices for Azure fuctions     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/11/29/Use-Azure-Functions-to-run-WordPress-Cron.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Mobile Apps for Apache Cordova reaches GA",
        "excerpt":"      Adrian Hall (MSFT)     11/30/2016 3:00:50 PM  Today, we are releasing the Azure Mobile Apps SDK for Apache Cordova as a GA product.  This completes the suite of mobile platforms that Azure Mobile Apps supports.  You can read more about this release:   Tutorials (Getting Started, Authentication, Offline Data Sync, Push Notifications) HOWTO API Documentation   The full suite of SDKs for Azure Mobile Apps is:   iOS (Objective-C, Swift 2.2, Swift 2.3, Swift 3.0, Xamarin.iOS, Xamarin.Forms, Apache Cordova) Android (Java, Xamarin.Android, Xamarin.Forms, Apache Cordova) Universal Windows (.NET, Xamarin.Forms, Apache Cordova) Windows Phone 8.1 (.NET, Xamarin.Forms, Apache Cordova)   You can also integrate the same backend into your web and API applications using the Azure Mobile Apps HTML/JavaScript SDK or by integrating Azure Mobile Apps server-side SDKs into your ASP.NET MVC or Node/Express applications.  All the SDKs support similar feature sets:   Data Access of SQL data with an OData v3 query structure. Offline Sync of any SQL table exposed via data access. Social authentication with client-side and server-side code to Facebook, Google, Microsoft and Twitter services. Enterprise authentication using client-side and server-side code via Azure Active Directory. Cross-platform push registration to APNS, FCM, WNS and MPNS using Notification Hubs.   With this release, we are looking to the future.  Some of the things we are looking at right now:   Integration with the Visual Studio Mobile Center SDK. Support for React Native. Support for File Sync to Azure Storage.   You can find details for our various platforms, including quickstart tutorials, HOWTO documentation and in-depth API documentation:   iOS (Swift and Xamarin) Android (Java and Xamarin) Universal Windows Cross-platform C# with Xamarin Forms Cross-platform JavaScript with Apache Cordova   As always, please feel free to leave us feedback.  We listen on Azure Forums and Stack Overflow.  Our SDKs are all open-source, so you can file issues for questions, feature requests and bugs.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/11/30/Azure-Mobile-Apps-for-Apache-Cordova-reaches-GA.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service Continuous Delivery Preview",
        "excerpt":"      Byron Tardif     12/1/2016 10:00:09 AM  Continuing the partnership between App Service and Visual Studio Team Services, we have a new preview experience for setting up a continuous delivery pipeline to automate the source control, build, test and deployment of your solutions to App Service.  The new experience is accessible through the settings menu under App Deployment &gt; Continuous Delivery (Preview)   Some of the highlights features include:  Ability to host your code in GitHub or Visual Studio Team Services Ability to create, deploy and execute load tests against an independent App Service plan. Deployment directly to deploymetn slots following App Service deployment best practices.  You can learn more about App Service Continuous Delivery preview from the announcement in the Visual Studio Application Lifecycle Management blog If you have any questions about this feature or App Service in general be sure to check our forums in MSDN and Stack Overflow. For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/12/01/App-Service-Continuous-Delivery-Preview.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "New Quickstart experience for App Service Web App",
        "excerpt":"      Byron Tardif     12/1/2016 4:41:39 PM  App Service provides you with many options for deploying your code to the cloud. The new Quickstart experience is designed to guide you through the steps to deploy your app using the deployment stack and deployment method of your choice.   To get started go to Quickstart under the App Deployment section of the settings menu:   Chose the development stack you are interested in:   Select a deployment method:   and follow the details instructions provided.   You can start a different scenario by clicking on “Choose another stack”.   If you have any questions about this feature or App Service in general be sure to check our forums in MSDN and Stack Overflow. For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/12/01/New-Quickstart-experience-for-App-Service-Web-App.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Running Azure Functions Locally with the CLI and VS Code",
        "excerpt":"      Donna Malayeri     12/1/2016 9:00:47 AM  Update 5/31: We now have official documentation for the Azure Functions Core Tools and this blog post is now out of date. See Develop and debug Azure functions locally.  After our General Availability release of Azure Functions on November 15, lots of customers have been asking how to develop Azure Functions on a local development machine, before pushing working code to Azure.  I’m happy to announce that we have some great new functionality to share on this front. You can now use your favorite editor and local development tools and trigger from events in your Azure resources. You can use Visual Studio 2015, Visual Studio Code, or just a command line and any code editor. Visual Studio 2015  Customers who use Visual Studio should check out the preview Azure Functions Tools for Visual Studio 2015. This allows you to create local Functions projects, add new Functions from templates within Visual Studio, run functions locally, and debug C# functions. Get the tools and learn more on the Web Tools team blog.   VS Code and azure-functions-cli  If you prefer VS Code or want to debug JavaScript functions, you can use the Azure Functions CLI. Note that currently the Azure Functions CLI only works on Windows, but we’re working on support for other platforms. (Note that C# debugging support is currently only available in Visual Studio, not VS Code.) Installing  Make sure you’re using Node version 6.x LTS or later (required by the Yeoman dependency), then do: npm i -g azure-functions-cli The Azure Functions CLI is actually the Azure Functions “host” packaged with a command line interface and some other utilities. This is the exact same runtime that’s used in Azure, it’s not an emulator or simulator. It is distributed through npm because it uses Yeoman for scaffolding, but the core functionality is just a .NET 4.6 executable. (That’s why it currently only works on Windows.) Creating a function project  When running locally, a function project (the equivalent of a Function App in Azure) is just a directory with the files host.json and appsettings.json. See the product documentation for more about the Azure Functions folder structure.  From a command prompt, do the following: mkdir MyAwesomeFunctionProj cd MyAwesomeFunctionProj func init You’ll see the following output: Writing .gitignore Writing host.json Writing appsettings.json Initialized empty Git repository in C:/CDriveCode/MyAwesomeFunctionProj/.git/ Notice the file appsettings.json, which is where you set local environment variables and connection strings (more on this later). Creating a simple function  Now, let’s create a simple HTTP triggered Node function via func new   I chose HttpTrigger-JavaScript and named it HttpTrigger-JS.   Running the function  This HTTP triggered function is very simple, it just takes in a “name” argument as either a query parameter or JSON body content, and outputs “Hello name”. To edit the function code, let’s open up VS Code: code . In Visual Studio Code, go to View -&gt; Integrated Terminal func run .\\HttpTrigger-JS\\ -c \"{\\\"name\\\": \\\"Donna\\\"}\"   You’ll see that a separate window launches, which is the Functions host. By default, it will listen on http://localhost:7071.  In the Functions host window, you’ll see that the URL of HTTP triggers is listed. You can then use a web debugging tool like Fiddler or Postman to create more complex requests.   Debugging the function in Visual Studio Code  Running a function is great, but debugging is where the magic happens. To run the code and attach the JavaScript debugger, do the following:  In a command prompt (either the Integrated Terminal or a regular command prompt), run the function as before and add the --debug flag: func run .\\HttpTrigger-JS\\ -c \"{\\\"name\\\": \\\"Debugging!\\\"}\" --debug  Add a breakpoint to index.js. In the Debug tab, select F5 or the play button In the terminal or command prompt, press any character and you’ll see your breakpoint being hit!    Running a queue-triggered function  Now let’s create a function that triggers from a queue in Azure. First, run func new and select QueueTrigger-JavaScript. Name the function QueueTriggerJS.  Setting a connection string Next, we need a value for a storage account connection string. You can either do this by editing appsettings.json manually or by using the Azure Functions CLI.  To edit manually:  To go Azure Storage Explorer or the Azure Portal and copy your storage connection string Add the value to appsettings.json: {     \"IsEncrypted\": false,     \"Values\": {          \"AzureWebJobsStorage\": \"DefaultEndpointsProtocol=https;AccountName=youraccountname;AccountKey=XXX\"       } }   Using the Azure Functions CLI:  Log in to Azure, then set the active subscription. You can list your Function Apps in Azure and pull down connection strings for a particular app: func azure login func azure account set  func azure functionapp list func azure functionapp fetch   You’ll see the following output. Settings will be encrypted by default and stored in appsettings.json. Loading AzureWebJobsStorage = ***** Loading AzureWebJobsDashboard = ***** To view settings values on the command line, run: func settings list -a If you want edit the file in an unencrypted form, run: func settings decrypt Editing the Function configuration If you haven’t already, open the Functions directory in Visual Studio Code by running code .  Now, edit QueueTriggerJS/function.json and set the value AzureWebJobsStorage for the value for connection. Your function.json will look like the following: {     \"disabled\": false,     \"bindings\": [         {             \"name\": \"myQueueItem\",             \"type\": \"queueTrigger\",             \"direction\": \"in\",             \"queueName\": \"js-queue-items\",             \"connection\":\"AzureWebJobsStorage\"         }     ] }  Now it’s time to run the function. There are two ways to trigger it: add new items to a queue named js-queue-items or use the Functions CLI to trigger the function directly. Triggering a function using “func run”  To trigger directly, run the following in the Functions CLI: func run .\\QueueTriggerJS\\ --debug -c \"I love this CLI!\" You’ll see the following output: Executing: 'Functions.QueueTriggerJS' - Reason: 'This function was programmatically called via the host APIs.' Function started (Id=c2603348-a0c5-4d7a-b938-5d3e66ed35fd) JavaScript queue trigger function processed work item I love this CLI! Function completed (Success, Id=c2603348-a0c5-4d7a-b938-5d3e66ed35fd) Executed: 'Functions.QueueTriggerJS' (Succeeded) Note: if you this error, it means you haven’t set a value for AzureWebJobsStorage in appsettings.json: Microsoft.Azure.WebJobs.Host: Error indexing method 'Functions.QueueTriggerJS'. Microsoft.Azure.WebJobs.Host: Object reference not set to an instance of an object. Error indexing method 'Functions.QueueTriggerJS'.  Now, let’s run and attach a debugger, the same as before: func run .\\QueueTriggerJS --debug -c \"Foo\" Triggering a function with a queue message  The cool thing about the local development experience is that you can trigger off of Azure resources directly, rather than just simulating via func run.  By default, the Functions CLI will poll for new queue items every minute. For development purposes, it’s helpful to poll more frequently. Add the following to your host.json file, to poll every 2 seconds: {      \"queues\": {         \"maxPollingInterval\": 2000      } }  Launch Azure Storage Explorer and create a queue js-queue-items in storage account you’ve specified in the AzureWebJobsStorage connection string:     Then, in Visual Studio Code, we see out breakpoint being hit:   This is just a taste of what you can accomplish with the Azure Functions CLI. Try it out today and let us know what you think! Provide feedback  The Azure Functions CLI is still in preview and under active development. If you find any issues, please post a GitHub issue and include the title “CLI:”. The CLI is open source and can be found in a branch of the azure-webjobs-script repo. You can also reach out to me on Twitter @lindydonna.  For general feedback and questions about Azure Functions:  Ask product questions on the Azure Functions MSDN forum and StackOverflow, where you’ll get answers directly from the engineering team. Submit feature requests on feedback.azure.com. Reach out to us on Twitter via @Azure with the hashtag #AzureFunctions.      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/12/01/Running-Azure-Functions-Locally-with-the-CLI-and-VS-Code.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Update Changes to MySQL support for Azure Imagine Offer",
        "excerpt":"      mksunitha     12/12/2016 10:45:29 AM  Imagine program provides special Azure access rights to students that are validated through the Microsoft Imagine program. If you are not enrolled , please enroll here.  Azure subscriptions enrolled in this program previously had access to a Free MySQL Database from ClearDB. Moving forward ClearDB FreeDatabase will no longer be supported as part of Imagine program. You can still leverage MySQL from MySQL in-app(Preview) feature.  What Imagine offer students get with MySQL in-app(Preview):  MySQL in-app gives you an experience of native MySQL running locally alongside the web server. One database for One web app .  It is not restricted on App service plan. Storage of 1 GB shared by the your web app's files and database content RAM of 1 GB Phpmyadmin access to manage your database  from Azure portal Supports logging for MySQL server logs and Slow query logs. Note these are turned off by default.  Here is a FAQ to help answer common question due to this change in service for Imagine program.  1.Can I continue to use, my existing ClearDB Free MySQL database?  Yes. You can continue to use your existing ClearDB Free MySQL database.  2. Can I create a new ClearDB MySQL database on my Imgaine program subscription?  No you cannot create a new Free ClearDB MySQL database on your Imagine program subscription. You can purchase a new Azure subscription such as Pay-as-you-go etc.  to be able to create ClearDB MySQL database  3. How can I export my ClearDB database to MySQL in-app(Preview) database?  Check out this article to learn how to export the database and import it in MySQL in-app(Preview) database.  4. How can I access phpmyadmin for MySQL in-app(Preview) database ?  In the Azure portal , under your web app settings menu you have an option to manage your MySQL in-app(Preview) settings.  To learn more , click here.  5. What applications can I install with MySQL from Azure Web Marketplace?  The following application will be available for Imagine  program :  Web app + MySQL WordPress Joomla Drupal 8 MediaWiki PHP starter site PHPBB (with MYSQL )  You can turn on MySQL in-app(Preview) for your web app and bring your own custom PHP code or CMS solution. References   Get started with MySQL in-app (Preview) Importing  MySQL database in MySQL in-app(Preview) database Performance benchmarking for MySQL in-app(Preview) database       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/12/12/Update-Changes-to-MySQL-support-for-Azure-Imagine-Offer.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Mobile Apps Node.js SDK v4.0",
        "excerpt":"      Adrian Hall (MSFT)     12/19/2016 7:56:48 PM  Today, in our final Azure Mobile Apps release of the year, we are releasing a new version of the server-side Azure Mobile Apps Node.js SDK.  It's labelled v4.0 because of important breaking changes, but does not introduce any new features.  Breaking Changes   If dynamic schema was enabled, inserting an item with new columns would also create a deleted column which was unnecessary if the soft delete option was turned off for the table.  With v4.0, the deleted column is not created when it is unnecessary.  This may affect automated clean-up scripts that don't take into account the soft delete setting on the table. (Issue #504)  If an update or delete was performed against soft-deleted records, the server would return a 409 HTTP status code.  This was in contrast with the ASP.NET server that returned a 404 HTTP status code.  The Node.js SDK has been updated to return a 404 HTTP static code. (Issue #497)  Finally, our documentation was out of line with our code with respect to paging options.  Previously, the server would place a hard limit on the number of records returned (the pageSize option), despite the maxTop option being higher.  The pageSize option now only affects the number of records returned if a $top expression is not provided, and the maximum number of records returned is correctly determined by the maxTop option. (Issue #480)   Other Fixes   An issue existed whereby a custom API whose access level was set to 'authenticated' would allow unauthenticated requests.  This only affected apps where the access level was applied to the entire API and not individual methods within the API and who were also using a custom authentication scheme.  Using the App Service Authentication / Authorization mitigated this issue.   With the v4.0 release, this issue has been corrected.  (Issue #514)  User Impact   Any user who is using the server via an Azure Mobile Apps client SDK should not be impacted by any of these changes.  If you use the server directly through the OData interface, then you should review the changes carefully before upgrading.  As always, our team is ready to assist should you have questions.  Please contact us through Azure Forums or Stack Overflow.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/12/19/Azure-Mobile-Apps-Node.js-SDK-v4.0.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Using Azure App Service Authentication with ASP.NET (Classic) MVC Applications",
        "excerpt":"      Adrian Hall (MSFT)     12/21/2016 11:49:17 AM  Azure App Service has a facility called \"Authentication / Authorization\" and it assists primarily with the authentication requirements of Azure Mobile Apps.  However, you can also use this in your web applications to abstract away the authentication needs.  This makes it easy to integrate Facebook, Google, Microsoft Account, Twitter and Azure AD authentication schemes.  This blog post will go through the process of configuring an ASP.NET MVC application to use Azure App Service Authentication.  Step 1: Configure Azure App Service Authentication / Authorization   You can follow our documentation to configure the actual service:   Azure AD Facebook Google Microsoft Twitter   Once you have followed the documentation, you should be able to browse to https://yoursite.azurewebsites.net/.auth/login/provider (where provider is one of aad, facebook, google, microsoftaccount or twitter) to ensure it is working.  Add Azure Mobile Apps to your ASP.NET MVC application   The Azure Mobile Apps .NET Server SDK does a lot of the hard work in handling claims.  To configure authentication, first add the Microsoft.Azure.Mobile.Server.Quickstart NuGet package.  Then add or create a Startup.cs file with the following:   using Microsoft.Owin; using Owin;  [assembly: OwinStartup(typeof(Backend.Startup))] namespace Backend {     public partial class Startup     {         public void Configuration(IAppBuilder app)         {             ConfigureMobileApp(app);         }     } }   Add a suitable App_Start\\Startup.MobileApp.cs file:   using System; using System.Collections.Generic; using System.Configuration; using System.Data.Entity; using System.Data.Entity.Migrations; using System.Web.Http; using Backend.DataObjects; using Backend.Models; using Microsoft.Azure.Mobile.Server.Authentication; using Microsoft.Azure.Mobile.Server.Config; using Owin;  namespace Backend {     public partial class Startup     {         public static void ConfigureMobileApp(IAppBuilder app)         {             var config = new HttpConfiguration();              new MobileAppConfiguration()                 .ApplyTo(config);              config.MapHttpAttributeRoutes();              var settings = config.GetMobileAppSettingsProvider().GetMobileAppSettings();             if (string.IsNullOrEmpty(settings.HostName))             {                 app.UseAppServiceAuthentication(new AppServiceAuthenticationOptions                 {                     SigningKey = ConfigurationManager.AppSettings[\"SigningKey\"],                     ValidAudiences = new[] { ConfigurationManager.AppSettings[\"ValidAudience\"] },                     ValidIssuers = new[] { ConfigurationManager.AppSettings[\"ValidIssuer\"] },                     TokenHandler = config.GetAppServiceTokenHandler()                 });             }              app.UseWebApi(config);         }     } }   Finally, add the following to your Web.config file:     &lt;appSettings&gt;     &lt;add key=\"webpages:Enabled\" value=\"false\" /&gt;     &lt;add key=\"PreserveLoginUrl\" value=\"true\" /&gt;     &lt;add key=\"MS_SigningKey\" value=\"Overridden by portal settings\" /&gt;     &lt;add key=\"EMA_RuntimeUrl\" value=\"Overridden by portal settings\" /&gt;     &lt;add key=\"MS_NotificationHubName\" value=\"Overridden by portal settings\" /&gt;     &lt;add key=\"SigningKey\" value=\"Overridden by portal settings\" /&gt;     &lt;add key=\"ValidAudience\" value=\"https://chapter6.azurewebsites.net/\" /&gt;     &lt;add key=\"ValidIssuer\" value=\"https://chapter6.azurewebsites.net/\" /&gt;   &lt;/appSettings&gt;   &lt;system.web&gt;     &lt;compilation debug=\"true\" targetFramework=\"4.5.2\"/&gt;     &lt;httpRuntime targetFramework=\"4.5.2\"/&gt;     &lt;authentication mode=\"Forms\"&gt;       &lt;forms loginUrl=\"/.auth/login/aad\" timeout=\"2880\"/&gt;     &lt;/authentication&gt;   &lt;/system.web&gt;   Some parts of this will already be available to you.  Make sure the loginUrl in the authentication section matches the provider login URL for the provider that you configured.  You should now be able to attach the [Authorize] attribute to any controller to enable the redirect to the authentication system.  The authentication will happen and then the user will be prompted to \"return to the website\".  Once the link is clicked, the user will be redirected back to your application with authentication.  Your application can use any of the claims available through the /.auth/me endpoint of your application.  They are available in the httpContext.User.Identity.Claims object.  Dealing with Anti-Forgery Tokens   One thing that will break is anti-forgery tokens.  This is because Azure App Service Authentication does not provide the appropriate identityprovider claim that anti-forgery tokens use for configuration.  You have to explicitly set a claim to use.  This can be done anywhere in the application start.  I place mine in the MVC RegisterRoutes() method in App_Start\\RouteConfig.cs.  Add the following line:   AntiForgeryConfig.UniqueClaimTypeIdentifier = ClaimTypes.NameIdentifier;       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2016/12/21/Using-Azure-App-Service-Authentication-with-ASP.NET-(Classic)-MVC-Applications.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions preview versioning update",
        "excerpt":"      Chris Anderson (Azure)     1/3/2017 11:45:39 AM  Azure Functions deprecating preview versions  With Azure Functions recently becoming generally available and making the 1.0 Azure Functions host available, we are now announcing that preview versions of the Azure Functions host (0.x) are deprecated and we're preparing to begin removal of these versions beginning February 1st, 2017. All Azure Functions users should upgrade their version setting to ~1. If you are using preview features, such as PowerShell or F# support, there are additional things to consider around how we will manage versions in 1.x versions.  Deprecation of preview (0.x) versions of Azure Functions host  All preview (0.x) versions of the Azure Functions host are now deprecated. We will be begin removing those versions from the available feed of versions starting February 1st, 2017. Since we've released 1.0, we've been monitoring which versions users are actively using and are happy with the adoption rate of our latest version. We will start by removing the earliest versions, which have the fewest users still active. If you still haven't upgraded to ~1, we strongly recommend that you upgrade as soon as possible.  Any non-security related issues related to these versions, including the runtime, portal, templates, or docs, will generally be closed. Support cases for users still using preview versions of the host will be directed to first upgrade to the latest version of the host. We encourage you to ask any questions you might have about any issues you experience while upgrading, either via Azure Support or via the forums and Stack Overflow. If you have any critical need to keep a preview version around past February 1st, 2017, please reach out to chrande@microsoft.com.   Versioning for preview features in 1.x  Previously, before 1.0, we would introduce breaking changes every minor version. Now that we've introduced 1.0, all \"released\" features, such as JavaScript and C# language support, will not have any breaking changes for all ~1 versions. If you don't plan on using preview features, you don't need to worry about any version updates until we have another major version update. Preview features, such as PowerShell and F# language support, will continue to potentially incur breaking changes between minor versions. We recommend that if you're using preview features, you continue to set your minor version explicitly (i.e. ~1.0), rather than just the major version(~1).   Additionally, we will not be supporting every 1.x version for the lifetime of 1.x. We will deprecate some ~1 minor versions over time. Later this month, we will provide a tentative schedule for how that will work, as well as some additional means for folks using preview features to provide us feedback. We'll also be building some special portal experiences which will make version management even easier for those of you using preview features.  We also really want to thank each and every one of you who gave us a try during our preview and those of you who will continue to use preview features now that we've released 1.0. It means a lot to us and we wouldn't be successful without it. We hope you have as much fun using our preview features as we do making them.  FAQ  When will version \"0.x\" (0.5, 0.6, etc.) be removed?  It will be removed sometime after February 1st, 2017.  What if the preview version I'm using is removed before I perform the upgrade?  Azure Functions will use a newer version automatically. If your Functions are impacted by any breaking changes between host versions, you may experience issues, including downtime that does not count against your SLA, since it is user controlled.  How do I know if I need to upgrade?  If your FUNCTIONS_EXTENSION_VERSION application setting is set not set to a ~1 version (i.e. it is set to 0.9), you need to upgrade. Our portal will provide  warning on the top of the screen if it detects you're behind the latest version.  How do I upgrade?  The easiest way to upgrade is to open the Azure Functions portal and click on the upgrade notice. You can also go to your Function App Settings menu and click on the upgrade version next to where it displays your current version. You can also directly set your Application Setting via the portal, any Azure CLI, or the Azure Resource Management APIs.  If I'm using ~1 today, do I need to worry?  As long as you're not using any preview features (like PowerShell or F# language support), you can rest easy. If you're using preview features, you'll want to manage your minor versions directly. Keep an eye out for some more information on this early next year.  What's the difference between ~1 and ~1.0 for the FUNCTIONS_EXTENSION_VERSION application setting?  When we resolve which Functions host to start up for you, we use the FUNCTIONS_EXTENSION_VERSION application setting to choose the best version for you. If you set your setting to ~1, you'll use the latest version of the host with major version of 1. If you set your setting to ~1.0, you'll only receive patch updates to 1.1. We'll update the minor version every time we have a new version of the host which has breaking changes for preview features.  If I desperately need to stay on a preview version, is there an option for me?  We believe that upgrading to ~1 is the best thing for everyone, but we can work with you to help you upgrade, if you reach out to us. If you're committed to staying on a preview version, we don't offer any official support for this, but you can deploy your own functions extension on App Service plans (not supported on Consumption plans).  Is there a way for me to know if I'll be impacted by a change?  The best way to get an idea of the impact is to read the release notes for any versions between your current version and the targeted upgrade version.  How do I revert to another version (just in case)?  In your app settings in the Functions portal, you'll find a setting  for the runtime FUNCTIONS_EXTENSION_VERSION. You can change this to any version, including a previous version. You can learn more about this here.       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/01/03/Azure-Functions-preview-versioning-update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Mobile Apps .NET SDK Releases",
        "excerpt":"      Adrian Hall (MSFT)     1/10/2017 5:03:53 PM  Today, we are releasing two new .NET SDK releases - v2.0.0 on the server side and v3.1.0 on the client side.  The NuGet packages are available from the main NuGet repository and the symbols have been updated on symbolsource.  Azure Mobile Apps ASP.NET Server SDK v2.0.0   It's been a while since we updated the ASP.NET Server SDK.  We've updated the base framework that we use to .NET Framework 4.6 and updated all the dependencies so that we are using the latest versions that we can while maintaining compatibility as a protocol level.  In addition, we have deprecated the Azure Notification Hubs push registration endpoint.  This is still included in the package, but marked as Obsolete and will be removed in a future version.  You should use the App Service Push endpoint instead.  In your ASP.NET Owin Startup class, you can remove the reference to .AddPushNotifications() from the configuration.  App Service Push has been significantly enhanced over the last couple of months.  It now supports white-listing of tags and automatic addition of tags based on authenticated claims available from the authentication provider.  This lays the groundwork for re-introducing tag support into the client SDKs in a future release.  In the interim, you can build your own Notification Hub Installation class and submit that via the .InvokeApiAsync() method.  For examples on this, check out Chapter 5 of my Azure Mobile Apps book.  We are also releasing the Swagger and Custom Authentication packages as generally available.  You can read about the Swagger customization on our Wiki.  Finally, we've also been working behind the scenes on updating the Azure Storage SDK, updating our testing and build processes so that those are more aptly done in the public, publishing more topics to our Wiki and adding information to our documentation.  Azure Mobile Apps Client SDK v3.1.0   The Client SDK has had the following updates since the last update:   (#266) A bug that caused problems when two libraries both used SQLite.  This was fixed by updating the dependency on the SQLitePCL.raw to the latest version.  Thanks to Eric Sink for the fast turnaround on the fix for this, and for providing an awesome open source project that we can leverage here. (#215) We were inconsistent in the generation of GUID style primary keys between the client and server.  We've standardized the production of keys to a hyphen-less version. (#196) We had a method for querying the underlying SQLite store that was not exposed.  Sometimes, it's good to do queries against the raw tables stored in SQLite.  We now expose the SQLiteStore.ExecuteQueryAsync() method that does the appropriate locking to ensure the operation is safe.   We've also done numerous documentation updates and will be updating the SDK documentation on the MSDN site soon.  As always, you can ask questions on both of these SDKs on Stack Overflow or Azure Forums, or file questions and issues at the GitHub repositories (Server and Client).  Read the Book   On the \"more documentation\" front, I've been hard at work writing the Azure Mobile Apps book for C#, covering the ASP.NET server and Xamarin cross-platform development.  It is nearing completion and all the \"development\" topics have been completed.  You can find the book at http://aka.ms/zumobook.  I would appreciate your feedback on the topics, especially where information is missing.  You can file issues at the GitHub repository.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/01/10/Azure-Mobile-Apps-.NET-SDK-Releases.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Notification Hubs Java SDK Improvements - Direct Send, Cancel Scheduled Pushes, Get Telemetry",
        "excerpt":"      Mimi Xu (Azure)     1/18/2017 10:11:01 AM  We are excited to share some of the recent updates the Notification Hubs team has made to its Java Server SDK.  We have added a cancelScheduledNotification API that lets you delete scheduled notifications provided the scheduled notification ID. We have added sendDirectNotification that can directly push any type of notifications (APNS, GCM, WNS, etc) to a list of device tokens without any device registrations needed with Notification Hubs service. Lastly, getNotificationTelemetry is enabled for customers to easily see telemetry details around each send request.  You will need the following dependencies with the correct versions:  Apache HttpClient Mime 4.5.2 Apache HttpCore 4.4.5  Give them a try and let us know what you think!        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/01/18/Notification-Hubs-Java-SDK-Improvements-Direct-Send,-Cancel-Scheduled-Pushes,-Get-Telemetry.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Parse Server on Azure App Service Updated",
        "excerpt":"      Adrian Hall (MSFT)     1/18/2017 5:19:01 PM  The open-source Parse Server project has moved on since we first published the Marketplace resource for running your own version of Parse Server on Azure App Service.  The Azure version of Parse Server uses all Azure resources - DocumentDb, Storage, Notification Hubs and App Service.  Recently, Parse Server got updated to v2.3.0.  If you wish to deploy a new Parse Server and use the new v2.3.0 codebase, then you can simply deploy the Marketplace resource.  In the Azure Portal, click on the + NEW resource.  Use the search box to search for Parse Server and create the Parse Server on managed Azure services resource.  All the relevant resources will be created for you.  This allows you to get up and running quickly.  If you have an existing Parse Server running with managed Azure services, you will need to upgrade your server rather than deploy a new server.  To do this:   Click Resource Groups and find the resource group containing your parse server resources. Click the App Service that has the same name as your parse server. Click the Application settings node in the menu. Add the following App Settings: WEBSITE_NODE_DEFAULT_VERSION = 4.4.0 WEBSITE_NPM_DEFAULT_VERSION = 3.8.3 You can set these values by scrolling to the App settings section and filling in the key/value fields appropriately, then press Enter. Click Console to open a management console. Type the following: npm install -s buffer-shims npm install -s parse-server@2.3.x  Restart your App Service.   This will install the latest 2.3.x release of parse-server (currently 2.3.2).  If you notice any red text in the console, then an error has occurred.  You should analyze the error message.  Please report any problems through Azure Forums or Stack Overflow.  Upgrading your Parse Server is identical to upgrading any other server code - try it on a non-production service first and ensure all your client-server communications still work properly.  Things change between Parse Server versions.  You should reach out to the Parse Server project directly if you are experiencing problems in your code.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/01/18/Parse-Server-on-Azure-App-Service-Updated.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Preview API Apps Deprecation",
        "excerpt":"      Alex Karcher     1/18/2017 10:46:13 AM  Affected Product: Azure Preview API Apps (v1) Deprecation Date: January 18th, 2017 Removal Date: March 14th, 2017 Mitigation: Redeploy workload to App Service API Apps (v2)  Today we are announcing the deprecation of Preview API Apps, referred to as v1 API Apps for this article. v1 API Apps are deprecated immediately and will be removed from Azure on March 14th. App Service API Apps, referred to as v2 API Apps for this article, are a GA product and still under active development. Redeploy all v1 API App workloads to v2 API Apps by March 14th to avoid a service interruption.  We are excited at the growth we have seen since upgrading v1 API Apps to the App Service infrastructure and announcing general availability of v2 API Apps over a year and a half ago. Read the original announcement for all the improvements introduced in v2 API Apps.  Logic App Impact Logic Apps had moved away from using the preview API Apps v1 based connectors almost 1 year ago and has since become generally available with over 100 managed connectors.  Please migrate your preview Logic Apps to our GA schema and discontinue use of the preview API APP v1 based connectors, as those connectors will be removed on March 14th, 2017.  API Gateway API Gateway resources are also deprecated and will also be removed following the API App removal timeline. API Gateway resources are created in each resource group that contains a v1 API App and have the resource type \"Gateway\" in the portal.  Identifying Preview API Apps (v1) v1 API Apps are only visible in the \"All Resources\" page of the Azure Portal, and on the page of the resource group they belong to. They are not visible in the \"App Services\" page of the Azure Portal by design. v1 API Apps have the App Type \"API App\" and the Resource Type \"Microsoft.AppService/apiapps\" in the Azure portal   Opening the App settings blade on a v1 API App will show an upgrade notice as well.  Identifying App Service API Apps (v2) v2 API Apps have the App Type \"App Service\" and the Resource Type \"Microsoft.Web/sites\" in the Azure portal, and are still under active support and development.  Upgrading Preview API Apps (v1) Follow this guide to redeploy your v1 API App workload to a v2 API App.  Upgrading Logic Apps v1 Connectors Use the GA release of Logic Apps with equivalent managed connectors in place of the v1 preview Connectors.  To check that you are no longer consuming a v1 connector, stop all of your v1 API Apps from the portal and check that your logic apps run successfully.  All v1 connectors will be classified as preview API Apps in the portal, shown above.  Preview (v1) API App Not Accessible in Portal The portal experience for some v1 API Apps and connectors may be unavailable. We recommend you use Azure Resource Explorer or the Azure Resource Manager REST APIs directly to manage these v1 API Apps.  In the Azure Resource Explorer navigate to your subscription, then your resource group. Note that your v1 sites will have both a core site, under Microsoft.AppService, as well as a container site under Microsoft.Web &gt; Sites. The core site contains your business logic, and the container contains your Azure configuration, such as deployment slots and networking settings.  Deprecation Timeline March 14th: v1 API Apps stop running on Azure March 28th: v1 API App data deleted from Azure  Additional Support If you have any issues moving to v2 API Apps please check our MSDN forums, or contact support directly     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/01/18/Preview-API-Apps-Deprecation.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Mobile Apps iOS SDK v3.3.0 Released",
        "excerpt":"      Adrian Hall (MSFT)     1/19/2017 3:19:29 PM  Today we are releasing the Azure Mobile Apps iOS SDK to CocoaPods and other online properties.  This is a drop-in replacement for the existing SDK.  We only have one feature fix in this release.  We updated the authentication code to support the SFSafariViewController.   This release affects you if you use Google Authentication and a server-flow.  If your code looks like this (Objective-C):  [client loginWithProvider:@\"google\" controller:self animated:YES completion:^(MSUser *user, NSError *error) {     [self refresh]; }];  Or the Swift equivalent:  client.loginWithProvider(\"google\", controller: self, animated: true) { (user, error) in     self.refreshControl?.beginRefreshing()     self.onRefresh(self.refreshControl) }  Then you are affected by this change.  Late last year, Google made changes to their OAuth authentication scheme.  The net effect was that a mobile client could no longer use a WebView to deliver the authentication flow to the user.  A secure web flow would be needed.  The supported method on iOS is the SFSafariViewController and this release changes the underlying web view capabilities for authentication to this new mechanism.  This wasn't just a client-side code change.  It involved changing the server-side authentication code worldwide in Azure App Service.    As with any release, we have done numerous small changes to make the experience for the developer better, particularly as it pertains to warnings that are delivered during the development process.  We are also in the process of moving all our examples to Swift 3.0.  The new SDK fully supports Swift 3.0 and XCode 8.2.  We will be deprecating the support for Swift 2.x in the next release.  Although we support XCode 7.0 for Objective-C usage, you will need XCode 8.2 for Swift support.  You can download the SDK from Cocoapods, take a look at the API directly or reference our tutorials and HOWTO documentation.  We're also active on Azure Forums and Stack Overflow.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/01/19/Azure-Mobile-Apps-iOS-SDK-v3.3.0-Released.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Revisiting Windows Azure Pack Web Sites V2 Support Lifecycle Dates",
        "excerpt":"      Andrew Westgarth     1/19/2017 10:00:00 AM  Windows Azure Pack Web Sites V2 is an on-premises, high density, multi-tenant web hosting for service providers and enterprise IT and provides an experience similar to the predecessor to Azure App Service, Azure Web Sites.  The product is deployed on top of Windows Server 2012 R2 and is an optional add-on to Windows Azure Pack.  With the release of Windows Server 2016, the Windows Azure Pack team amended the support lifecycle to reflect that Windows Azure Pack V2 from Update Rollup 11 is supported on Windows Server 2016, however this is not the case for Windows Azure Pack Web Sites.  Windows Azure Pack Web Sites is only supported on Windows Server 2012 R2 and is subject to the same support lifecycle dates that were previously published for Windows Azure Pack running on Windows Server 2012 R2.  We understand this is causing some confusion and concern amongst customers so this blog post is intended to clarify the position for users of Windows Azure Pack Web Sites. Windows Azure Pack Web Sites v2 Mainstream support ends on 11th July 2017  Windows Azure Pack Web Sites has a direct dependency on Windows Server 2012 R2 and as such will adhere to the following support lifecycle dates:    Lifecycle Start date 14th January 2014   Mainstream Support End Date 11th July 2017   Extended Support End Date 12th July 2022    Guidance on what is covered under Extended Support can be found at https://support.microsoft.com/en-us/help/17140/general-lifecycle-policy-questions But Windows Azure Pack can be deployed on Windows Server 2016, what about Web Sites?  Windows Azure Pack Web Sites does not support deployment on top of Windows Server 2016.  Windows Azure Pack can be deployed on Windows Server 2012 R2 and with Update Rollup 11 can be deployed on Windows Server 2016 but Windows Azure Pack Web Sites is ONLY supported on Windows Server 2012 R2. What about Updates?  Update Rollups for Windows Azure Pack Web Sites will continue to be published until July 2017, after that date no regular updates will be published.  Questions?  If you have any questions or feedback around this clarification and Windows Azure Pack Web Sites please add them to the comments on this post and I will respond.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/01/19/Revisiting-Windows-Azure-Pack-Web-Sites-V2-Support-Lifecycle-Dates.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "ClearDB maintenance for Mercury databases on Microsoft Azure",
        "excerpt":"      mksunitha     1/25/2017 9:01:25 AM  We are conducting an assessment on ClearDB MySQL databases associated with Azure customers. We have found several instances where subscriptions are deployed in ClearDB but have no corresponding Azure account associated with them.  To synchronize the ClearDB and Azure services, any MySQL database that does not have a valid Azure account will be frozen on January 25. This may impact some Azure users.  If your account is frozen and you wish to sustain the ClearDB MySQL database services from Azure, please take the following steps:  Provision a new, empty ClearDB database in Azure to restore your data into. Once created, please open a Support ticket with Azure Support or ClearDB support with the following infromation:  The database name that was  newly created with Azure subscription ID Old database name  , ClearDB database hostname and the associated Azure subscription ID Our support teams will work will provide you a back up of your database. Please import the database content using MySQL workbench into the newly created database .    The reason behind these steps being taken is due to inconsistency in purchase order records for these databases and their subscriptions. The steps above will help resolve this. We apologize for any inconvenience you have incurred.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/01/25/ClearDB-maintenance-for-Mercury-databases-on-Microsoft-Azure.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service Companion for iOS update",
        "excerpt":"      Byron Tardif     2/22/2017 10:43:11 AM  We have just released an update for our App Service Companion app for iOS  Some of the key new features include: \t Ability to “favorite” apps for quick access New grouping option in the app list to quickly navigate through large app collections. Support for Push notifications for recomendations New native UI built specially for iOS  If you have already installed App Service Companion you should soon see the update from the App Store or you can click on the banners below to install it now for your respective platform                      Favorites &amp; Application Grouping  The application list lets you view all apps or a filtered view of just your favorites.  You can add or remove items to the favorite list by swiping left in the application list or from the app actions menu.  You can now group applications in the app list by: \t Subscription Resource Group Region App type                   App actions and Metrics  Application actions are grouped under the action menu, application actions include: \t Start Stop Restart Browse Favorite  Metrics graphs under the app’s monitoring view now let you select different time grains to get a better view of your app’s activity \t 1 hour 1 day 1 week             If you have any questions about this app or App Service in general be sure to check our forums in MSDN and Stack Overflow. For any feature requests or ideas check out our User Voice            ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/02/22/App-Service-Companion-for-iOS-update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions Proxies public preview",
        "excerpt":"      Matthew Henderson - MSFT     2/22/2017 9:00:13 AM  Since we first released Azure Functions, we've seen a lot of customers using the service to build APIs. Functions is a fantastic way to quickly express an action, and the consumption plan is a great billing model for many types of applications.  However, we've also heard that dealing with multiple functions could be easier. It's often difficult to manage large solutions within a single function app. There are also quite a few customers that want to use microservices architectures, with deployment isolation between individual components. Splitting the work into multiple function apps works for most triggers, but it's a bit trickier for APIs. Each function app has its own hostname, so there can be many hosts to keep track of, without a unified API surface. This can make things difficult for client applications, especially when the client needs to switch between environments for testing.  Today, we are pleased to announce the public preview of Azure Functions Proxies, a new capability that makes it easier to develop APIs using Azure Functions. Proxies lets you define a single API surface for multiple function apps. Any function app can now define an endpoint that serves as a reverse proxy to another API, be that another function app, an API app, or anything else.  You can learn more about Azure Functions Proxies by going to our documentation page. The feature is free while in preview, but standard Functions billing applies to proxy executions. See the Azure Functions pricing page for more information. Creating your first proxy  To create a proxy, head to any function app. In the left-hand navigation, you should now see a Proxies section. Select \"New proxy\" to get started. You will need to provide a name for the proxy, the endpoint you wish to expose, and the backend endpoint that will serve the request.    Proxies exist as peers to functions in a function app. They are configured just like HTTP-triggered functions, and from a client perspective, they look the same. However, the proxy behavior is independently enabled and versioned. If this is the first proxy you've created for a function app, you will need to enable the feature in function app settings. Getting in touch with the team  Please give Azure Functions Proxies a try and let us know what you think! We have some additional capabilities planned for this scenario, but as always, we'd love to hear what matters most to you.  If you run into any problems, let us know on the forums, ask a question on StackOverFlow, or file an issue on GitHub. If you have any additional features you would like to see, please let us know on Uservoice.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/02/22/Azure-Functions-Proxies-public-preview.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing Azure Functions support for Serverless Framework",
        "excerpt":"      Chris Anderson (Azure)     2/23/2017 8:00:44 AM  Today we’ve officially announced preview support for the Azure Functions Serverless Framework plugin. The Serverless Framework is an open source tool which allows you to deploy auto-scaling, pay-per-execution, event-driven functions to any cloud. It helps abstract away the details of your Serverless resources and lets you focus on the important part – your application. With the release of our new plugin, it’s one of the fastest ways to deploy a serverless application, ever.  You can learn more about the plugin in the Azure Functions Serverless Framework documentation.  You can also check out our npm package serverless-azure-functions. Getting started  Now let’s see a quick hello world example 1. Set up boilerplate  To setup the boilerplate, follow these instructions:  Recommend using Node v6.5.0 Install the serverless tooling - npm i -g serverless Create boilerplate (change my-app to whatever you'd prefer) -serverless install --url https://github.com/azure/boilerplate-azurefunctions --name my-app cd my-app npm install  2. Set up credentials  We'll set up an Azure Subscription and our service principal. You can learn more in the credentials doc.  Set up an Azure SubscriptionSign up for a free account @ https://azure.com.  Azure comes with a free trial that includes $200 of free credit.   . Get the Azure CLI  npm i -g azure-cli   Login to Azure  azure login  This will give you a code and prompt you to visit aka.ms/devicelogin. Provide the code and then login with your Azure identity (this may happen automatically if you're already logged in). You'll then be able to access your account via the CLI. Get your subcription and tenant id  azure account show  Save the subcription and tenant id for later Create a service principal for a given &lt;name&gt; and &lt;password&gt; and add contributor role.  azure ad sp create -n &lt;name&gt; -p &lt;password&gt;  This should return an object which has the servicePrincipalNames property on it and an ObjectId. Save the Object Id and one of the names in the array and the password you provided for later. If you need to look up your service principal later, you can use azure ad sp -c &lt;name&gt; where &lt;name&gt; is the name provided originally. Note that the &lt;name&gt; you provided is not the name you'll provide later, it is a name in the servicePrincipalNames array.  Then grant the SP contributor access with the ObjectId  azure role assignment create --objectId &lt;objectIDFromCreateStep&gt; -o Contributor   Set up environment variablesYou need to set up environment variables for your subscription id, tenant id, service principal name, and password.  # bash  export azureSubId='&lt;subscriptionId&gt;'  export azureServicePrincipalTenantId='&lt;tenantId&gt;'  export azureServicePrincipalClientId='&lt;servicePrincipalName&gt;'  export azureServicePrincipalPassword='&lt;password&gt;'   # PowerShell  $env:azureSubId='&lt;subscriptionId&gt;'  $env:azureServicePrincipalTenantId='&lt;tenantId&gt;'  $env:azureServicePrincipalClientId='&lt;servicePrincipalName&gt;'  $env:azureServicePrincipalPassword='&lt;password&gt;'    3. Deploy to Azure  Run the deploy command serverless deploy  4. Test  Run the invoke command serverless invoke function -f httpjs      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/02/23/Announcing-Azure-Functions-support-for-Serverless-Framework.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Making your APIs available to PowerApps and Microsoft Flow",
        "excerpt":"      Matthew Henderson - MSFT     2/23/2017 8:00:36 AM  Azure App Service and Azure Functions are both commonly used for building organizational APIs. These might include important business logic needed by many apps and activities. Traditionally, most of these clients are written by professional developers, but Microsoft also offers solutions that enable anyone in an organization to build solutions.  PowerApps and Microsoft Flow are services that enable power users within an organization to get more done. Without writing any code, users can easily create apps and custom automated workflows that interact with a variety of enterprise data and services. While they can leverage a wide variety of built-in SaaS integrations, users often find the need to incorporate company-specific business logic.  We've now extended the API Definition feature of App Service and Azure Functions to include an \"Export to PowerApps and Microsoft Flow\" gesture. This walks you through all the steps needed to make any API in App Service or Azure Functions available to PowerApps and Microsoft Flow users. To learn more, see our documentation.  We're hoping to make this experience even easier over time. Please let us know what you think in the Forums (App Service, Functions) or UserVoice (App Service, Functions).       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/02/23/Making-your-APIs-available-to-PowerApps-and-Microsoft-Flow.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Creating a local PFX copy of App Service Certificate",
        "excerpt":"      akurmi     2/24/2017 3:04:03 PM  Introduction  Last year, we introduced ‘App Service Certificate’, a certificate lifecycle management offering. Azure portal provides a user-friendly experience for creating App Service Certificates and using them with App Service Apps. You can read more about this service here. While the portal provides first class experience for deploying App Service Certificate through Key Vault to App Service Apps, we have been receiving customer requests where they would like to use these certificates outside of App Service platform, say with Azure Virtual Machines. In this blogpost, I am going to describe how to create a local PFX copy of App Service Certificate so that you can use it anywhere you want. Prerequisites  Before making a local copy, make sure that: 1. The App Service Certificate is in ‘Issued’ state 2. It’s assigned to a Key Vault (Step 1 in the link shared above). Creating a local copy of the issued SSL certificate using PowerShell  You can use the following PowerShell script to create a local PFX copy.  You need to first install Azure PowerShell and have the required modules installed. Follow this blog to install the Azure PowerShell commandlets.  To use the script, open a PowerShell window, copy the entire script below (uncomment Remove-AzureRmKeyVaultAccessPolicy line if you want to remove Access policies after export, check your permissions to see if you want to remove the policy) and paste it on the PowerShell window and hit enter. Function Export-AppServiceCertificate { ###########################################################  Param( [Parameter(Mandatory=$true,Position=1,HelpMessage=\"ARM Login Url\")] [string]$loginId,  [Parameter(Mandatory=$true,HelpMessage=\"Subscription Id\")] [string]$subscriptionId,  [Parameter(Mandatory=$true,HelpMessage=\"Resource Group Name\")] [string]$resourceGroupName,  [Parameter(Mandatory=$true,HelpMessage=\"Name of the App Service Certificate Resource\")] [string]$name )  ###########################################################  Login-AzureRmAccount Set-AzureRmContext -SubscriptionId $subscriptionId  ## Get the KeyVault Resource Url and KeyVault Secret Name were the certificate is stored $ascResource= Get-AzureRmResource -ResourceId \"/subscriptions/$subscriptionId/resourceGroups/$resourceGroupName/providers/Microsoft.CertificateRegistration/certificateOrders/$name\" $certProps = Get-Member -InputObject $ascResource.Properties.certificates[0] -MemberType NoteProperty $certificateName = $certProps[0].Name $keyVaultId = $ascResource.Properties.certificates[0].$certificateName.KeyVaultId $keyVaultSecretName = $ascResource.Properties.certificates[0].$certificateName.KeyVaultSecretName  ## Split the resource URL of KeyVault and get KeyVaultName and KeyVaultResourceGroupName $keyVaultIdParts = $keyVaultId.Split(\"/\") $keyVaultName = $keyVaultIdParts[$keyVaultIdParts.Length - 1] $keyVaultResourceGroupName = $keyVaultIdParts[$keyVaultIdParts.Length - 5]  ## --- !! NOTE !! ---- ## Only users who can set the access policy and has the the right RBAC permissions can set the access policy on KeyVault, if the command fails contact the owner of the KeyVault Set-AzureRmKeyVaultAccessPolicy -ResourceGroupName $keyVaultResourceGroupName -VaultName $keyVaultName -UserPrincipalName $loginId -PermissionsToSecrets get Write-Host \"Get Secret Access to account $loginId has been granted from the KeyVault, please check and remove the policy after exporting the certificate\"  ## Getting the secret from the KeyVault $secret = Get-AzureKeyVaultSecret -VaultName $keyVaultName -Name $keyVaultSecretName $pfxCertObject= New-Object System.Security.Cryptography.X509Certificates.X509Certificate2 -ArgumentList @([Convert]::FromBase64String($secret.SecretValueText),\"\",[System.Security.Cryptography.X509Certificates.X509KeyStorageFlags]::Exportable) $pfxPassword = -join ((65..90) + (97..122) + (48..57) | Get-Random -Count 50 | % {[char]$_}) $currentDirectory = (Get-Location -PSProvider FileSystem).ProviderPath [Environment]::CurrentDirectory = (Get-Location -PSProvider FileSystem).ProviderPath [io.file]::WriteAllBytes(\".\\appservicecertificate.pfx\",$pfxCertObject.Export([System.Security.Cryptography.X509Certificates.X509ContentType]::Pkcs12,$pfxPassword))  ## --- !! NOTE !! ---- ## Remove the Access Policy required for exporting the certificate once you have exported the certificate to prevent giving the account prolonged access to the KeyVault ## The account will be completely removed from KeyVault access policy and will prevent to account from accessing any keys/secrets/certificates on the KeyVault,  ## Run the following command if you are sure that the account is not used for any other access on the KeyVault or login to the portal and change the access policy accordingly. # Remove-AzureRmKeyVaultAccessPolicy -ResourceGroupName $keyVaultResourceGroupName -VaultName $keyVaultName -UserPrincipalName $loginId # Write-Host \"Access to account $loginId has been removed from the KeyVault\"  # Print the password for the exported certificate Write-Host \"Created an App Service Certificate copy at: $currentDirectory\\appservicecertificate.pfx\" Write-Warning \"For security reasons, do not store the PFX password. Use it directly from the console as required.\" Write-Host \"PFX password: $pfxPassword\" } Now you will have a new command called Export-AppServiceCertificate, use the command as follows  Export-AppServiceCertificate -loginId yourarmemail@domain.com -subscriptionId yoursubid -resourceGroupName resourceGroupNameOfYourAppServiceCertificate -name appServiceCertificateName Once the command is executed, you would see a new file in the current directory called ‘appservicecertificate.pfx’. This is a password protected PFX, the PowerShell console would display the corresponding password. For security reasons, do not store this password in a text file. You can use the password directly from the console as required. Also, don’t forget to delete the local PFX file once you no longer need it. Exporting the certificate with the chain included for App Service Web App consumption.  The pfx created by the above commands will not include certificates from the chain. Services like Azure App Services expect the certificates that are being uploaded to have all the certificates in the chain included as part of the pfx file.  To get the certificates of the chain to be part of the pfx, you will need to install the exported certificate on your machine first using the password that is provided by the script, make sure you mark the certificate as exportable.    Once you have installed the exported certificate open the certificate from your certificate store and navigate to the Certification Path tab, it would look something like below,    Now go to https://certs.godaddy.com/repository and download the intermediate certificates and the root certificate. Install all of the certificates downloaded to the same store as your certificate. Once you confirmed that all the certificates in the chain have been installed we can export the certificate with the chain by going to the certificate store, right clicking on the SSL certificate we exported and installed and clicking of All Tasks -&gt; Export ...  In the wizard, make sure you select the option, \"Yes, export the private key\"  And then under the Personal Information Exchange property, make sure the option \"Include all certificates in the certification path if possible\" is checked.    Once exported into a new pfx file we can check if the new pfx has the certificate chain included in it by running the command, certutil -dump &lt;path of the certificate file&gt; You will see the list of the certificates that are part of the pfx from the root to your certificate. A pfx file created with the above steps with all the certificates of the chain contained is well formed and can be uploaded to App Service Web Apps with confidence. Note the CA part of the uploaded pfx file will be discarded when we process the uploaded certificate, we store all the intermediate certificates associated with the certificate to enable the chain to be remade properly in the runtime. Once all the export operation is complete and you have successfully uploaded your certificate clean your machine of any trace of the SSL certificate by deleting the certificate from the store to secure your certificate. Things to note  If you create a copy of App Service Certificate this way, it won’t have any impact on existing App Service SSL bindings that were created using the portal experience. It also won’t affect any such SSL bindings you may create in the future. You can still Rekey and Renew an App Service Certificate with one click even after making a copy but you would be responsible for creating a new local copy with the new certificate and updating all services that are using the old certificate. Tips  This section compares this method of certificate deployment with the built-in Azure portal experience for Web Apps. It also contains recommendations you should follow when you use the PFX copy elsewhere.     Title    Azure portal Deployment    Deploying local PFX copy    Recommendations      Auto/Manual Renew    When an App Service Certificate is renewed, all the corresponding App Service SSL bindings are updated automatically    When a certificate is renewed, you would need to manually update all the services that are using a local copy.    Turn off Auto renew as you won’t know when exactly an App Service Certificate gets renewed with Auto renew and this would end up breaking your SSL endpoints. Manually renew such App Service Certificates before they expire      Rekey    Just like renewal, the corresponding SSL bindings are updated automatically    Just like renewal, you would need to manually update all such services.          Deployment    When deploying certificate this way, you don’t need any file locally and there won’t be any secrets to clean up    When deploying certificate this way, you would have the PFX certificate on local disk.    Always delete the local copy once you no longer need it as you can create a PFX copy as many times as you want. Also, never store the password shown in PowerShell console locally. This way, even if somehow an adversary gets hold of your local disk, he still won’t be able to use the PFX certificate as it’s protected by a strong password      Getting in touch  If you have an App Service Certificate that you would like to use outside of App Service ecosystem, then give this a try and let us know how it goes. If you run into any issues, please let us know on the App Service forum.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/02/24/Creating-a-local-PFX-copy-of-App-Service-Certificate.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing general availability for MySQL in-app",
        "excerpt":"      mksunitha     3/6/2017 11:00:24 PM  MySQL in-app was a preview feature launched last year in August.  The feature primary objective was to make it easier to build and test MySQL based applications on App Service.  Today, I am excited to announce general availability of MySQL in-app feature.  Note : This MySQL in-app is specific to Windows version of Azure app service. If you are looking for local mysql on Linux MySQL app service , click here.  We have rolled out a database migration feature from MySQL in-app that allows you to export your database content from localdb database provided by MySQL in-app and import it into a production database. A production database can be managed MySQL service or your custom MySQL server solution.  See options for production MySQL database in Azure.  This feature will be continue to accelerate your development and testing scenarios . Here are key benefits of using this feature :  It supports any runtime stack that is available in App Service (Windows) applications such as Node JS , .NET , Python , PHP etc. For  Python, Node JS , .NET do make sure you have the appropriate libraries or drivers with your code in order to connect to MySQL database provided with MySQL in-app It’s cost-effective since there’s no additional cost to use this feature and you only pay for the App Service plan (since resources are shared). The MySQL and Web processes are co-located in the same environment (hence the term in-app) which means storage is shared. Includes support for slow query logging and general logging, which you’ll need to turn on as needed (this feature impacts performance, so you shouldn’t use it all the time). One click migration of your database from MySQL in-app to a production MySQL database solution. Azure offers many solutions for MySQL , including:  Azure database for MySQL(Preview) Marketplace solutions for MySQL, MariaDB, and other MySQL-compatible solutions from partners like Bitnamiand MariaDB Community-contributed Azure Resource Manager (ARM) templatesdeploying on VMs MySQL on virtual machine on Linuxor Windows OS      If you intend to use this feature for PRODUCTION web application , your web application must meet one or more of the criteria below :  your application is read only web site [ when file server is in read only mode , the database is read only as well ] your application does not need auto scale File servers may go into read only mode from 1 to 6 mins depending on whether an upgrade is occurring or any intermittent storage connectivity issue occurs. For example if you use wordpress and during this time you cannot write a post or edit content. You can retry in a few minutes and it will work. If this is okay for your production app then use MySQL inapp Review your user traffic on your application and test to see if your application can run on one instance. If it can manage the load , you can use MySQL inapp for production.  The reason for the criteria mentioned above is due to the lack of support for auto scale on App service with MySQL in-app.       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/03/06/Announcing-general-availability-for-MySQL-in-app.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Migrate development database on MySQL in-app to production MySQL database",
        "excerpt":"      mksunitha     3/6/2017 10:56:56 PM  MySQL in-app feature on App service  has announced general availability today.  The feature has been keen on improve the experience of developing MySQL based applications on Azure App Service.  Once your application is ready to go live , you need to migrate the database content to your production database.  This can be tedious  task when done manually .  In the MySQL in-app management settings ,  we now have, we have an option for easily exporting your localdb database from MySQL in-app to a production MySQL database.  This blog will discuss how to perform this migration of your database. Follow the steps below :     1. Create a production MySQL database using any one these options. For this blog post I am using a production Azure database for MySQL(Preview). For details , refer to How to create MySQL database from Portal or How to create MySQL database using CLI.  2. Copy the connection string for the Azure database for MySQL(Preview) database.  If you are using a different database solution for production , collect the database connection information for your production database.    3. Login to the Azure portal . Click on your web app using MySQL in-app. Select MySQL in-app setting for your web app and Click on Export button under MySQL in App Export   4. You have a choice of using a connections string for your production database or enter the credentials manually. Once the production database connection information has been entered , click on Save to start the process of export.  During the export a connection string will be added to the connection string setting in the portal.    During the export , you cannot make any changes to MySQL in-app configuration in the portal.  All options will be disabled to manage MySQL in-app during export process .You must wait until the export is completed.    8. Once the export is successful , review your production database to make sure all the content was successfully updated.  Note we do not turn off the MySQL in-app feature since your production application may still be using it.  Update your application to connect to the production database and test your application before going live with your application. After successful testing , you can now turn off MySQL in-app feature for your web app to continue using production database.            ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/03/06/Migrate-development-database-on-MySQL-in-app-to-production-MySQL-database.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "JanuaryFebruary 2017 App Service Update",
        "excerpt":"      Byron Tardif     3/9/2017 4:00:58 PM  Diagnose and solve problems  App Service has a new experience for Diagnose and solve problems. With this new UI we make it easier to distinguish between application issues (your code) and platform issues (App Service). We also provide quick solutions (Fix it!) tailored to the problems you might be experiencing.  The UI provides a view of the health of your application, health of the platform as well as traffic over the last 24 hours. If any availability issues are detected in that time window, they are listed below the graphs. You can drill down into more detail from there.  If the issue is currently ongoing we try to provide a custom solution specific to the issue we detected. This should point you in the right direction to fix your problem and help get your application back into a healthy state.  You can reach the new experience by clicking on the Diagnose and solve problems item in the general section of any Web, Mobile or API app.    GA for MySQL in App  The MySQL in-app feature enables running MySQL natively on the Azure App Service platform. While this feature is ideal for small applications running on a single instance, or for development scenarios, you will need a full fledged MySQL resource that you can manage and scale independently for any production scenario.  To ease the migration from your MySQL in App to an external MySQL database we have added Export functionality in the portal to make this a turnkey experience.  You can read more about MySQL in App in the MySql-in-app general availability announcement, and learn how to Migrate development database on MySQL in-app to production MySQL database using the export experience.       Improved integration with PowerApps and PowerFlows  Under the API definition feature for any Web, API or Mobile app you will find the new Export to PowerApps + Micosoft Flow button:  Clicking on it will provide the necessary instructions based on your API metadata to allow your PowerApps + Microsoft Flow apps to consume it:       Export App Service certificates to use with other Azure Resources  Certificates purchased through App Service certificates can now be exported to use with other Azure Resources:  App Service on Linux  We released a few new built-in containers including support for Node 6.9.3 as well as Ruby 2.3:  Bitbucket has also been added as a supported Deployment source under Deployment options:    App service Companion  We have a new App Service Companion for iOS update that includes new functionality such as support for Push Notifications and ability to Favorite apps for quick access.     If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/03/09/JanuaryFebruary-2017-App-Service-Update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions F# support is now generally available",
        "excerpt":"      Chris Anderson (Azure)     3/16/2017 10:00:21 AM  Today, we’re happy to announce that F# is now generally available for all users of Azure Functions. Now that the API is stable, anyone can build production applications with Functions written in F#. You can get started today by using one of the F# templates in the portal today. Getting started with F#  and HTTP triggers  Whether you need to expose a new HTTP endpoint for an API or WebHook, or process items from a queue, now F# developers can take full advantage of these Azure Functions capabilities.  Here’s a quick sample of how easy it is to set up an HTTP Trigger:  Create a new Function App (if you don’t have one already):  Then, you can create a new F# Function from the “+ New Function” menu  Once you click on create, you’ll have your Function shortly appear. You can copy the URL to invoke it (1) and click on the Logs button (2) to view your streaming logs from your Function.   Next Steps  You can continue to learn about F# on Azure Functions by following some of the links below:  Try Functions for free! Azure Functions F# Developer Reference Running Azure Functions Locally Reach out to the team on GitHub        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/03/16/Azure-Functions-F-support-is-now-generally-available.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Publishing a .NET class library as a Function App",
        "excerpt":"      Donna Malayeri     3/16/2017 1:00:00 PM  Update #1: The Azure Functions CLI has been renamed to Azure Functions Core Tools.  Update #2: We now have Visual Studio 2017 tooling for Azure Functions! You can use WebJobs attributes to configure triggers and bindings, so there is no need to manually author function.json. For more information, see the following:  Visual Studio 2017 Tools for Azure Functions Azure Functions Visual Studio Tooling video  With our new Azure Functions runtime support for precompiled functions, you can now use familiar Visual Studio features such IntelliSense and unit testing. These features were among the top requests after we launched the preview Visual Studio Tools for Azure Functions. This also enables an improved development workflow for customers who feel that that class libraries are a better fit for their application.  Azure Functions now supports publishing a class library as the implementation for one or more functions in a Function App. We’ve also recently made several runtime improvements to make assemblies much more useful, such as shadow-copying managed assemblies to avoid file locking issues and restarting the Functions runtime to pick up newly deployed binaries.  Using Visual Studio 2015 or 2017, you can try precompiled functions today with a few manual tweaks to your project. The manual steps are needed because the existing Functions project type (.funproj) has no build action, since it contains only script files. With the setup below, you'll instead use a web project which will provide the full development experience of IntelliSense, local debugging, and publishing to Azure.  The next version of Visual Studio tooling for Azure Functions won’t require this manual configuration, as it will be directly based on class libraries. In fact, the Visual Studio experience will be optimized around class libraries, while the Functions portal will continue to use script files.   Performance benefits of class libraries  Aside from the tooling experience, another advantage of using a class library is that you’ll see improvements to “cold start,” particularly when running on a Consumption plan. Cold start occurs on the first request to a Function App after it has gone idle, which happens after 5 minutes of inactivity. When a Function App starts up, it indexes all functions and compiles C# and F# scripts into an assembly in memory. So, compilation time will add to cold start time. Customers aren’t charged for cold start since function execution hasn’t started, but it does cause a delay in event processing. Use a Web Application project with a customized start action  A Web Application project is really a special kind of class library, which means it produces an executable .dll as the build output. To enable local running and debugging, modify the start action of the web project to launch the Azure Functions Core Tools.  Here are some sample projects set up this way:  HttpTrigger sample CoderCards – trading card generator with blob trigger  Project setup – Visual Studio 2015 or 2017   From the New Project dialog, choose ASP.NET Web Application (.NET Framework) with the empty site template. Open the project properties. In the Web tab, choose Start External Program For the program path, enter the path to func.exe for the Azure Functions Core Tools.  OR, if you've installed the Visual Studio Functions Tooling, the path will look something like C:\\Users\\USERNAME\\AppData\\Local\\Azure.Functions.Cli\\1.0.0-beta.93\\func.exe If you've installed the Azure Functions Core Tools through NPM, the path will be something like C:\\Users\\USERNAME\\AppData\\Roaming\\npm\\node_modules\\azure-functions-core-tools\\bin\\func.exe   For Command line arguments, set host start For Working directory, specify the root of the web project on your machine (unfortunately, this isn’t set automatically.)    Here's a YouTube video that walks through these steps. Downloading existing function code  If you’ve already developed your functions in the Azure Portal, you can download your code and settings with the following steps.  Install the Azure Functions Core Tools from npm.  If you’ve installed the Visual Studio Tools for Azure Functions, just add func.exe to your path from %USERPROFILE%\\AppData\\Local\\Azure.Functions.Cli\\1.0.0-beta.93 (or the latest version on your machine).   Go to the Kudu console for your Function App in Function App Settings -&gt; Kudu. Navigate to site and click on the download icon to the left of wwwroot (click on the animated gif below). Or, from an authenticated session, go to https://your-function-app.scm.azurewebsites.net/api/zip/site/wwwroot/. Unzip the file wwwroot.zip on your local machine. From that directory, run the following:  [sourcecode language=\"plain\" light=\"true\" gutter=\"false\"] func azure login (optional) func azure account list (optional) func azure account set func azure functionapp list func azure functionapp fetch-app-settings [name] [/sourcecode]    This will create a local file called appsettings.json. These settings are only used locally by the Functions Core Tools. Since this file contains secrets, be sure not to check this file in to source control! (The Azure Functions Core Tools adds appsettings.json to .gitignore for you.)  Animated gif:   Project content   Copy your downloaded files to the web project folder (including appsettings.json). Include the script files and function.json in the project. F5 should now work and successfully attach a debugger. But, you’re still using script files.  Converting to class files  To convert script files to C# class files, most changes are straightforward. The one manual step is to modify function.json to point to a class library instead of a script file (step #7 below). The next version of the Visual Studio tooling will eliminate this manual step.  Rename .csx to .cs and add a class declaration and optional namespace declaration. Remove #load and replace #r with assembly references. If you’re using TraceWriter, add the NuGet package Microsoft.Azure.WebJobs and the statement: using Microsoft.Azure.WebJobs.Host If you're using timer triggers, add the NuGet package Microsoft.Azure.WebJobs.Extensions. Add NuGet package references for the packages that are automatically referenced, such as Newtonsoft.Json and Microsoft.ServiceBus. Add explicit namespace import statements if you’re using any of the automatically imported namespaces, such as System.Threading.Tasks. Add any other NuGet packages specified in project.json using NuGet package manager. For each function, modify function.json and specify the scriptFile and entryPoint properties. scriptFile is a path to the assembly and entryPoint is the qualified name of the method. Make sure that function.json is in a directory that matches the function name. See documentation on precompiled functions.  [sourcecode language=\"plain\" light=\"true\" gutter=\"false\"] \"scriptFile\": \"..\\\\bin\\\\Assembly.dll\", \"entryPoint\": \"Namespace.ClassName.Run\" [/sourcecode]  See sample function.json.  Once you compile and run, you should see your class library functions being loaded by the Functions Runtime.   Publish from Visual Studio  You can publish the project to a Function App using the same experience as App Service publish. The project template generates web.config, but publishing this file has no effect (it is not used by the Functions runtime). Each web project maps to one Function App. If you need to publish functions independently of one another, we recommend that you use separate Function Apps.  To create a new Function App, choose Function App in the Create App Service dialog. To publish to an existing Function App, download your publish profile from the Azure Portal and import in the Visual Studio publish dialog.  You can use the Azure portal to run precompiled functions and view execution logs. To make code changes, you should re-publish from Visual Studio. Publish from Azure Functions Core Tools  The Azure Functions Core Tools also provides a publish command, via the following:  [sourcecode language=\"plain\" light=\"true\" gutter=\"false\"] func azure login func azure functionapp publish [name] [/sourcecode]  Building on the server using continuous integration and deployment  There’s another big advantage to using a web project—continuous integration with build on the server just works! Just follow the same steps as continuous deployment for Azure Functions. Your project will be built whenever there is a sync from source control. This will only work if you’re using a Web Application project, but not if you’re using a Functions Project (.funproj).  To see this in action, just fork the HttpTrigger sample project and set up GitHub as your continuous integration source. Provide feedback  Ask questions in the comments section below or reach out to me on Twitter @lindydonna. For general feedback and questions about Azure Functions:  Ask product questions on the Azure Functions MSDN forum and StackOverflow, where you’ll get answers directly from the engineering team. Submit feature requests on feedback.azure.com or the Azure Functions GitHub repo. Reach out to us on Twitter via @Azure with the hashtag #AzureFunctions.      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/03/16/Publishing-a-.NET-class-library-as-a-Function-App.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure App Service (Web, API, Mobile, ASE) &amp; Azure Functions SKU Comparison Matrix",
        "excerpt":"      Cory Fowler (MSFT)     3/23/2017 6:27:19 PM  App Service has come a very long way in the nearly 5 years it has been a service in Azure. Along the way, we've added a number of features, changed the pricing model, we've even gone as far as to make App Service available in an isolated capacity with App Service Environment and with the recent addition of Azure Functions a new type of hosting plan.  With all of these changes it's become clear to us that we need to provide a clear breakdown as to which features are available in which tiers because that enables you, our beloved customers, to be successful on our platform.  In an attempt to clarify which features are available where, we have created the below matrix. We are posting this to our blog first, as we would like to hear your feedback if this is effective way of relaying this information to you. For Example, should we merge the below matrix with the App Service Plan limits page.  Please leave your feedback in the comments below and we will work on getting a more formal piece of documentation together that will provide you with all of the details you need to get to market in the quickest way possible using Azure App Service.        Features SKU           App Deployment Free Shared Basic Standard Premium ASE ILB ASE App Service Linux Consumption Plan (Functions)  Continuous Delivery ✓ ✓ ✓ ✓ ✓ ✓ ✓      Continuous Deployment ✓ ✓ ✓ ✓ ✓ ✓ ✓   ✓  Deployment Slots       ✓ ✓ ✓ ✓      Docker (Containers)               ✓ 1    Development Tools Free Shared Basic Standard Premium ASE ILB ASE App Service Linux Consumption Plan (Functions)  Clone App         ✓ ✓ ✓      Kudu ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ 2 ✓  PHP Debugging 3 ✓ ✓ ✓ ✓ ✓ ✓        Site Extensions ✓ ✓ ✓ ✓ ✓ ✓ ✓      Testing in Production       ✓ ✓ ✓ ✓      Monitoring Free Shared Basic Standard Premium ASE ILB ASE App Service Linux Consumption Plan (Functions)  Log Stream ✓ ✓ ✓ ✓ ✓ ✓ ✓ 4   ✓  Process Explorer ✓ ✓ ✓ ✓ ✓ ✓ ✓   ✓  Networking Free Shared Basic Standard Premium ASE ILB ASE App Service Linux Consumption Plan (Functions)  Hybrid Connections ✓ ✓ ✓ ✓ ✓ ✓ ✓      VNET Integration       ✓ ✓ ✓ ✓      Programming Languages Free Shared Basic Standard Premium ASE ILB ASE App Service Linux Consumption Plan (Functions)  .NET ✓ ✓ ✓ ✓ ✓ ✓ ✓   ✓  .NET Core ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓    Java ✓ ✓ ✓ ✓ ✓ ✓ ✓   alpha  Node.js ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓  PHP ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ alpha  Python ✓ ✓ ✓ ✓ ✓ ✓ ✓   alpha  Ruby               ✓    Scale Free Shared Basic Standard Premium ASE ILB ASE App Service Linux Consumption Plan (Functions)  Auto-scale       ✓ ✓ ✓ ✓   ✓  Integrated Load Balancer   ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓  Traffic Manager       ✓ ✓ ✓ ✓      Settings Free Shared Basic Standard Premium ASE ILB ASE App Service Linux Consumption Plan (Functions)  64-bit     ✓ ✓ ✓ ✓ ✓ ✓ ✓  Always On     ✓ ✓ ✓ ✓ ✓      Session Affinity ✓ ✓ ✓ ✓ ✓ ✓ ✓      Authentication &amp;Authorization ✓ ✓ ✓ ✓ ✓ ✓ ✓   ✓  Backup/Restore       ✓ ✓ ✓ ✓ ✓    Custom Domains   ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓  FTP/FTPS ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓  Local Cache       ✓ ✓ ✓ ✓      MySQL in App ✓ ✓ ✓ ✓ ✓ ✓ ✓ 4      Remote Debugging (.NET) ✓ ✓ ✓ ✓ ✓ ✓     ✓  Security Scanning ✓ ✓ ✓ ✓ ✓ ✓        SSL (IP/SNI)     ✓ ✓ ✓ ✓ ✓ ✓ SNI SSL  Web Sockets 5 ✓ ✓ ✓ ✓ ✓ ✓ ✓     1 Supports a one-time pull model from Docker Hub, Azure Container Registry or a private Docker Registry.2 Kudu on Linux doesn’t have the same feature set as Kudu on Windows.3 PHP Debugging is currently only supported on Windows. PHP Debugging for version 7.x is unavailable.4 ILB ASE has no public connectivity to the internet. Management actions on ILB ASE must be performed using the Kudu Console.5 The number of Web Socket ports are limited by the sku, review the App Service Constraints, Service Limits and Quotas.      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/03/23/Azure-App-Service-(Web,-API,-Mobile,-ASE)-&amp;-Azure-Functions-SKU-Comparison-Matrix.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing Azure Functions OpenAPI (Swagger) support preview",
        "excerpt":"      Alex Karcher     3/30/2017 12:00:37 PM  Today we are announcing preview support for editing and hosting OpenAPI 2.0 (Swagger) metadata in Azure Functions. API authoring is a popular application of Functions, and Swagger metadata allows a whole network of Swagger compliant software to easily integrate with those APIs.    We are adding a Swagger template generator to create a quickstart Swagger file from the existing metadata in your HTTP Trigger Functions. You just fill in the operation objects for each of your HTTP verbs and you’re off!  We host a version of the swagger editor to provide rich inline editing of your Swagger file from within the Function UI. Once you save your Swagger file we’ll host it for you at a url in your Function App's domain.  Head on over to the documentation to learn more Integrations  These features integrate with the existing Azure App Service API definition support to allow you to consume your API on a variety of 1st party services, including PowerApps, Flow, and Logic Apps, as well as the ability to generate SDKs for your API in Visual Studio. Creating your first Open API definition  Check out our getting started guide for in-depth instructions  To create your first OpenAPI (Swagger) definition you must first have a function App with at least one HTTP Trigger Function. Instructions. Next head over to the \"API Definition (preview)\" tab in the lower left hand corner of your Function App. Toggle your Swagger source to \"Internal.\" This will enable hosting and inline editing of an OpenAPI definition for this Function App. Click \"Load Generated API Definition\" to populate the Swagger editor with a quickstart OpenAPI definition.  This definition uses your function.json, represented as the settings in the \"Integrate tab,\" for each Function to populate the definition.   Add an operation object for the POST operation of your function with the expected type of input.  For the HTTP Trigger sample code you can use the following Operation object:    Remove the entries under Paths/api/&lt;yourFunctionName&gt; for every verb except POST. (get, delete, head, etc)  For the default HTTP Trigger, all HTTP verbs are allowed, so our quickstart will have a blank entry for all 8 possible verbs. We want our definition to only contain the available functionality of our API.   Test your Swagger definition  In the right-hand pane of the swagger editor add your API key as Authentication info, click \"try this operation,\" and enter a name to test your Swagger.    Provide Preview Feedback  Try out Swagger support in Functions and let us know how you like it! We are continuing to develop this set of features and would love to know what matters most to you.  If you run into any problems, let us know on the forums, ask a question on StackOverFlow, or file an issue on GitHub. If you have any additional features you would like to see, please let us know on Uservoice.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/03/30/Announcing-Azure-Functions-OpenAPI-(Swagger)-support-preview.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Updating Migrated Azure Mobile Services Sites for Facebook Auth",
        "excerpt":"      Adrian Hall (MSFT)     3/30/2017 11:30:35 AM  If you use a combination of Azure Mobile Services and Facebook authentication, then you will have noticed that the Facebook authentication stopped working yesterday.  This was due to the deprecation of an underlying Facebook OAuth protocol that the service relied on.    If your Azure Mobile Services site has not been migrated yet, we have made changes in the backend to fix the protocol, so no action is required on your part.  We apologize for the downtime that this caused.  If your Azure Mobile Services site has been migrated, then you are in charge of the code that runs your site.  If your site is a .NET site, we have updated the Katana middleware that runs authentication within the site extension.  You need to update an App Setting within your site:   Log on to the Azure portal. Find your Azure App Service site and click it.  The easiest way to do this is to click All Resources then use the Filter by name... box to find your site. Click Application settings (under Settings) in the left-hand menu. Scroll down until you find App settings. Update the MOBILESERVICESDOTNET_EXTENSION_VERSION value from 1.0.478 to 1.0.481. Click Save at the top of the Application settings blade.   If you are running a Node site, then you will need to update the Azure Mobile Services package that is an integral part of the site code to pick up the changes.  To do this:   Log on to the Azure portal. Find your Azure App Service site and click it.  The easiest way to do this is to click All Resources then use the Filter by name... box to find your site. Click Console (under Development Tools) in the left-hand menu. Run the command npm install azure-mobile-services@1.0.1 to update the package.  Let this process complete. Click Overview in the left-hand menu. Click Restart to restart your site.   After the changes, please test the Facebook authentication to ensure it is working.  You can reach out to us on Stack Overflow or Azure Forums to get additional help.  We would like to also take this opportunity to encourage you to update your site to Azure Mobile Apps.  This is the v2 edition of the same service, but contains a different client SDK and server SDK.  If you are a .NET developer, lots of information about developing the service is available in the Azure Mobile Apps Documentation (for Client and Server) and my book.  For Node developers, you can use the Compatibility package to convert your Mobile Services server to a Mobile Apps server.  Again, please reach out to us if you run into trouble.  As a reminder, the Azure Mobile Services reaches its end of life in May, 2017.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/03/30/Updating-Migrated-Azure-Mobile-Services-Sites-for-Facebook-Auth.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "March 2017 App Service Update",
        "excerpt":"      Byron Tardif     4/4/2017 10:56:04 AM  This month we shipped a pair of new features: Remote debugging support for Visual Studio 2017  App Service now supports remote debugging your app form Visual Studio 2017. Remote debugging can be enabled form Application Settings in the menu:    If you want to learn more about remote debugging you apps in App Service and other troubleshooting tools supported by the platform check out this article:  Troubleshoot a web app in Azure App Service using Visual Studio  You can get Visual Studio 2017 here: https://www.visualstudio.com/downloads/  WordPress on Linux (preview)  App Service has always supported running WordPress on Windows based App Service plans, but now you have the option to also run it on Linux. This version of WordPress leverages the App Service on Linux support for container and it’s implemented as a custom Docker image publicly available on Docker hub.    You can read more about App Service on Linux here: Introduction to App Service on Linux and how to Create WordPress using Web Apps on Linux   If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/04/04/March-2017-App-Service-Update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions now has direct integration with Application Insights",
        "excerpt":"      Donna Malayeri     4/6/2017 12:56:15 PM  Today we're encouraging everyone to go give Azure Functions' Application Insights integration a try. You can find full instructions and notes on how it works at https://aka.ms/func-ai. Now it takes (nearly) zero effort to add Application Insights to your Azure Functions and immediately unlock a powerful tool for monitoring your applications.  Application Insights is now available for all Functions users on \"~1\". If you're on \"beta\" now, please switch back to \"~1\" which has the latest version. If you stay on \"beta\", it's very likely you'll be broken by something at some point. Getting Started  It’s fairly simple to get started – there is just two steps.  Create an Application Insights instance.  Application type should be set to General Grab the instrumentation key   Update your Function App’s settings  Add App Setting – APPINSIGHTS_INSTRUMENTATIONKEY = {Instrumentation Key}    Once you’ve done this, your App should start automatically sending information on your Function App to Application Insights, without any code changes. Using Application Insights to the fullest  Now that your Function Apps are hooked up to Application Insights, let's take a quick look at some of the key things you'll want to try. Live Stream  If you open your Application Insights resource in the portal, you should see the option for “Live Metrics Stream” in the menu. Click on it and you’ll see a near-live view of what’s coming from your Function App. For executions, it has info on #/second, average duration, and failures/second. It also has information on resource consumption. You can pivot all of these by the “instance” your functions are on; providing you insight on whether a specific instance might be having an issue or all of your Functions.   Analytics  The analytics portal provides you the ability to write custom queries against your data. This is one of the most powerful tools in your tool box. Currently, the following tables are full of data from the Functions runtime:  Requests – one of these is logged for each execution Exceptions – tracks any exceptions thrown by the runtime Traces – any traces written to context.log or ILogger show up here PerformanceMetrics – Auto collected info about the performance of the servers the functions are running on CustomEvents – Custom events from your functions and anything that the host sees that may or may not be tied to a specific request CustomMetrics – Custom metrics from your functions and general performance and throughput info on your Functions. This is very helpful for high throughput scenarios where you might not capture every request message to save costs, but you still want a full picture of your throughput/etc. as the host will attempt to aggregate these client side, before sending to Application Insights  The other tables are from availability tests and client/browser telemetry, which you can also add. The only thing that’s currently missing is dependencies. There is also more metrics/events we’ll add over the course of the preview (based off your generous feedback on what you need to see).  Example:  This will show us the median, p95, and p99 over the last 30 minutes graphed in a timeplot.    While you can copy+paste this query, I'd recommend trying to type it out yourself to get a sense of the amazing intellisense features that the editor has. You can learn about all the language features with some amazing examples from the Analytics reference page.  You can also pin these graphs to your dashboard, which makes for a really powerful tool for having a way to know how your application is behaving at a glance.   Alerts  While it's great that I can see what's happening and what happened, what's even better is being told what's happening. That's where alerts come into play. From the main Application Insights blade, you can click on the alerts section and define alerts based on a variety of metrics. For example, you could have an alert fire when you've had more than 5 errors in 5 minutes, which sends you an email. You can then create another one which detects more than 50 errors in 5 minutes, and triggers a Logic App to send you a text message or PagerDuty alert. Next steps  Application Insights is now GA'd and ready for production workloads. We're also listening for any feedback you have. Please file it on our GitHub. We'll be adding some new features like better sampling controls and automatic dependency tracking soon. We hope you'll give it a try and start to gain more insight into how your Functions are behaving. You can read more about how it works at docs.microsoft.com     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/04/06/Azure-Functions-now-has-direct-integration-with-Application-Insights.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "New integrated portal for Azure Functions",
        "excerpt":"      Donna Malayeri     4/10/2017 10:30:44 AM  I’m excited to announce a new integrated portal experience for Azure Functions. Previously, there was somewhat disjoint experience between Function Apps and App Service. For many management operations, customers had to navigate to the App Service resource blade, and we heard feedback that customers wanted a more integrated and streamlined experience. In addition, we want to provide an easier way to manage multiple Function Apps from within one view.  We’ve made several enhancements to the experience, including:  A dedicated browse blade for Function Apps. Function Apps are still listed in the App Service blade, but that’s no longer the only way to find Function Apps A tree view that allows viewing and managing multiple Function Apps Filters on subscription and app name, as well as an option to scope the view to just one app One-click access to all App Service platform features A convenient way to manage features that have already been configured Overall UI enhancements to be more consistent with the rest of the Azure portal  For a visual introduction, the short video below walks through the main features. The video is also available on YouTube.  [video width=\"1920\" height=\"866\" mp4=\"media/2017/04/function-navigation-full.mp4\"][/video] Function App browse and management  There is now a new browse blade for Function Apps that you can pin to the left-hand service menu. Under More services, search for Functions.    Once you’re on the browse blade, you’ll see all Function Apps in your active subscription in a tree view on the left. You can filter on one or more subscriptions or search for an app name. In the list view on the right, apps are listed in a grid view that includes the subscription, resource group, and location.  If you select an app in the grid view, you’ll see a scoped view for just that Function App. Clearing the search box at the top will show all Function Apps in the selected subscriptions. See animated gif below.    You can also scope to a particular Function App by selecting the chevron to the right of the app name. The refresh button will update the function and proxies list. On a Consumption plan, the refresh button also synchronizes triggers with the central listener. (This is required if you FTP or Kudu to modify your function.json files.) Function App management  Once you’ve selected a Function App, the Overview tab on the right displays information about your app and is similar to the App Service resource blade. From here, you can stop, restart and delete your app, download the publish profile, and reset publish credentials.  The Configured features section lists any platform features that you’ve customized. For instance, if you have configured a deployment option, you can navigate to the settings directly from the overview page.    The Settings tab includes Function App level settings, such as the runtime version, proxies configuration, and host keys. The Platform features tab lists all relevant App Service settings. If you miss the App Service resource blade, you can still get to it from General Settings -&gt; All settings. Features that are not available for your app are still displayed, but include a tooltip on why they are not available. You can also search settings based on either exact name or a descriptive tag. For instance, searching on “git” will highlight the option Deployment source.    The API definition tab allows you to configure a Swagger API definition. For more information on the feature, see the blog post Announcing Azure Functions OpenAPI (Swagger) support preview. Function navigation  Navigating to an individual function is also much easier. If you select the Functions or Proxies node within a Function App, you’ll see a list of items you can use to navigate. We’ll be making more improvements to the Functions list, including the ability to search functions, change the enabled state, and delete functions. (For more details, see the GitHub issue AzureFunctionsPortal #1062.)    See animated gif below.   New Function page  The New Function page has a few changes. Since the main Function App page now shows the Overview tab, that displaced the Quickstart experience. We’ve incorporated it as part of the New Function page. If a Function App has no functions, you’ll see the quickstart below. To get to the full template view, select Create custom function at the bottom of the page. To get to the quickstart view below from the template view, select “go to the quickstart.”    Upcoming improvements  Today’s release is just the start of the improvements to the Functions portal. Here’s a list of some of the other improvements we have planned:  Option to create a new Function App from the navigation blade. Currently, you have to go to the top-level +New option to create a Function App (AzureFunctionsPortal #986) On Functions grid page, add options for search, enable/disable, and delete (AzureFunctionsPortal #1062) Include pricing tier in Function App list (AzureFunctionsPortal #1030) Add list of keys to Get Function URL dialog (AzureFunctionsPortal #850) Sort templates by scenario, rather than alphabetical (AzureFunctionsPortal #405)  Feedback survey  As this is a big change to the Azure Functions portal, we’d love to hear your feedback. Help improve the product by filling out a 2-minute survey: https://aka.ms/functions-portal-survey. Provide feedback  Ask questions in the comments section below or reach out to me on Twitter @lindydonna. For general feedback and questions about Azure Functions:  Ask product questions on the Azure Functions MSDN forum and StackOverflow, where you’ll get answers directly from the engineering team. Submit feature requests on the Azure Functions GitHub repo or feedback.azure.com. For portal bugs and feature requests, post in AzureFunctionsPortal. Reach out to us on Twitter via @AzureFunctions or use the the hashtag #AzureFunctions.  Acknowledgements  We’d like to thank our Azure MVPs and Azure Advisors for trying out an early version of the portal and providing feedback. Functions team members @bktv99, @crandycodes, and @phaseshake filed the most bugs during the bug bash.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/04/10/New-integrated-portal-for-Azure-Functions.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing Try App Service API Apps",
        "excerpt":"      Alex Karcher     4/14/2017 12:11:52 PM  Today we are very excited to announce the addition of Azure API Apps to Try App Service. You can now create free trial API Apps with no credit card in a matter of seconds!  API Apps provide a streamlined PaaS experience for hosting APIs. Leverage turnkey security, rich Visual Studio integration, and Swagger support to make the process of developing, hosting, and growing your API easy. To learn more about API Apps check out our docs!  Templates  We have two available to showcase API Apps:  API Todo List: A simple REST API that would host the data for a todo list application. Read the Swagger document and then use the built in testing tools, or a 3rd party API testing suite like postman, to play with the API.  API Contacts List:  A combination single page application and backend API. Experiment with adding and removing contacts from your list, and then use the Swagger doc to experiment with the underlying API calls.Swagger UI showing the underlying API in the contacts list API   Click here to go try API Apps!      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/04/14/Announcing-Try-App-Service-API-Apps.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "WordPress on Web app for Containers",
        "excerpt":"      mksunitha     4/16/2017 9:23:18 PM  Web Apps on Linux allows running web apps natively on Linux. WordPress is popular blogging platform primarily used on Linux distributions.  Today we have released WordPress for App Service on Linux in the Azure marketplace that helps you quickly create a WordPress application on Web apps (Linux) .  This docker image enables you to run a WordPress site on Azure Web App on Linux  using either :    Azure Database for MySQL : It is a Microsoft solution for MySQL service on Azure that provides a managed database service for app development and deployment that allows you to stand up a MySQL database in minutes and scale on the fly . Local Database  : You can manually setup your web app to use Local database. This option is not provided from Azure portal for WordPress on Linux template.    Before you begin  If you don't have an Azure subscription, create a free account before you begin. Deploy from Marketplace  Log in to the Azure portal.Click here to create the WordPress application.    Name Description     App Name   Enter a unique app name for your **Web App Name**. This name is used as part of the default DNS name for your app &lt;app_name&gt;.azurewebsites.net, so it needs to be unique across all apps in Azure. You can later map a custom domain name to your app before you expose it to your users     Subscription Select a Subscription. If you have multiple subscriptions, choose the appropriate subscription.   Resource group   Enter a resource group. A resource group is a logical container into which Azure resources like web apps, databases that is deployed and managed. You can create a resource group or use an existing one    App Service Plan   App Service plans represent the collection of physical resources used to host your apps. Select the Location and the Pricing tier. For more information on pricing, see  App service pricing tier     Database Provider Use Azure Database for MySQL for database solution    This will deploy a WordPress custom image on to Web Apps on Linux . Note there might be cold start for the first request to the site created. Using GIT repo for WordPress code  Version 0.3 pulls wordpress code from our GIT repo when you create a when app using this Docker image .  If you have custom code on Github as well , you can edit GIT_REPO after the app is created and GIT_BRANCH values in app settings.  Create a Web App for Containers Add new App Settings     Name Default Value     GIT_REPO https://github.com/azureappserviceoss/wordpress-azure   GIT_BRANCH linux_appservice     Browse your site  Note: GIT directory: /home/site/wwwroot. When you deploy it first time, Sometimes need to check wp-config.php. RM it and re-config DB information is necessary. Before restart web app, need to store your changes by \"git push\", it will be pulled again after restart. How to configure to use Local Database with web app   Create a Web App for Containers Update App Setting WEBSITES_ENABLE_APP_SERVICE_STORAGE = true (If you like to keep you DB after restart.) Add new App Settings     Name Default Value     DATABASE_TYPE local   DATABASE_USERNAME wordpress   DATABASE_PASSWORD some-string    Note: We create a database \"azurelocaldb\" when using local mysql . Hence use this name when setting up the app  Browse your site Complete WordPress install  Note: Do not use the app setting DATABASE_TYPE=local if using Azure database for MySQL How to update WordPress core , theme or plugins  If WEBSITES_ENABLE_APP_SERVICE_STORAGE= false  ( which is the default setting ) , we recommend you DO NOT update the WordPress core version , themes or files from WordPress admin dashboard.   There is a trade off between file server stability and file persistence . Choose either one option to updated your files :  OPTION 1 :  Since we are using local storage for better stability for the web app , you will not get file persistence.  In this case , we recommend to follow these steps to update WordPress Core  or a theme or a Plugins version :  Fork the repo  https://github.com/azureappserviceoss/wordpress-azure  Clone your repo locally and make sure to use ONLY linux-appservice branch  Download the latest version of WordPress , plugin or theme being used locally  Commit the latest version bits into local folder of your cloned repo  Push your changes to the your forked repo  Login to Azure portal and select your web app  Click on Application Settings -&gt; App Settings and change GIT_REPO to use your repository from step #1. If you have changed the branch name , you can continue to use linux-apservice . If you wish to use a different branch , update GIT_BRANCH setting as well.     OPTION 2 :  You can update WEBSITES_ENABLE_APP_SERVICE_STORAGE =true  to enable app service storage to have file persistence . Note when there are issues with storage  due to networking or when app service platform is being updated , your app can be impacted .  How to turn on Xdebug   By default Xdebug is turned off as turning it on impacts performance. Connect by SSH. Go to /usr/local/php/etc/conf.d, Update xdebug.ini as wish, don't modify the path of below line.zend_extension=/usr/local/php/lib/php/extensions/no-debug-non-zts-20170718/xdebug.so Save xdebug.ini, Restart apache by below cmd: apachectl restart Xdebug is turned on.  Limitations   Some unexpected issues may happen after you scale out your site to multiple instances, if you deploy a WordPress site on Azure with this docker image and use the MariaDB built in this docker image as the database. The phpMyAdmin built in this docker image is available only when you use the MariaDB built in this docker image as the database. Please Include App Setting WEBSITES_ENABLE_APP_SERVICE_STORAGE = true when use built in MariaDB since we need files to be persisted.  Change Log   Version 0.3  Use Git to deploy wordpress. Update version of PHP/Apache/Mariadb/Phpmyadmin. Add Xdebug extenstion of PHP. Use supervisord to keep SSHD and Apache. This is NOT compatible with tag 0.2 and tag 0.1 for Docker image wordpress-alpine-php    Migrating an existing WordPress site  This image creates a new WordPress application every time it is deployed. If you are migrating your application to this site , please follow directions to export and import as mentioned on Wordpress Codex.  If you have a complex WordPress application where the above mentioned export and import options are not effective, Web Apps on Linux supports git deployment and you use FTP  or GIT deployment to replace the file system on the site created with this template to bring your own content. You can use PHPmyadmin available with this solution to import your application database content. Troubleshooting  The docker image has been updated from this  docker image  to using a new format where the docker image only contains the server components. The application code for WordPress is deployed via GIT from  github repo . Update your application to use the new image appsvc/apps:apache-php-mysql-0.1   If you have an existing application created using the WordPress image , check the Application setting to verfiy which image is being used with DOCKER_CUSTOM_IMAGE setting . If the setting value is apache-php-mysql-0.1 , no changes needed . If the value is wordpress-0.2 or wordpress-0.1 or wordpress  and  follow the steps below based on the database being used :  Azure Database for MySQL  Create a new web app with WordPress  from the Azure marketplace. Select \"Existing resource group\"  and choose the resource group in which your Azure Database for MySQL  database exists. Select the same app service plan in which the current site assigned to. If using Azure Database for MySQL   , select your existing database that is being used by your web app.   Test the new site to make sure it is working as expected before deleting the older app.   Local database  Backup your web app and database manually. Create a new web app with WordPress  from the Azure marketplace and choose Azure database for MySQL Migrate your database to the new database and your files to newly created web app. Note : There is bug with Local database causing the application to break once the app is  provisioned which will be fixed in early August 2017 . If you wish to use Local database , wait until Local database is support for WordPress template next month.      Using App  Service Storage   If you using a web app that was created from Azure marketplace for Web App on Linux using WordPress , Drupal , Mediawiki and  Joomla  , please add the following app setting WEBSITES_ENABLE_APP_SERVICE_STORAGE app setting to true to continue using App service Storage  (platform SMB share i.e /home/ folder ) . Use the platform file storage in these  two scenarios :  When you scale out using the autoscale feature in Web app for Linux.  If your application modifies the the files system and you need this new changes to the file system to be persistent . For example , with a WordPress app if you install a plugin , Wordpress adds a few files to the files system for the plugin and modifies the database. If you scale up or the instance your app is running on is recycled you will loose the plugin files which can break your production application.   Hence in such cases it is recommended to set the app setting to true.   NOTE: If the setting is not set to true  the changes to the file system are not persisted.       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/04/16/WordPress-on-Web-app-for-Containers.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Mobile Apps Quickstart Samples available as GitHub repositories",
        "excerpt":"      Adrian Hall (MSFT)     4/24/2017 8:57:35 AM  We recently made a change to the way that we manage the Azure Mobile Apps quickstarts.  In the past, when you created a Mobile App, you could go to the Quickstart blade and download a client.  This mechanism is still available to you.  However, we have also made these quickstart projects available as GitHub repositories.  This allows you to fork the repository and start developing without going to the Quickstart blade first.  The project that you download from the Quickstart blade is almost the same as the project you can retrieve from the GitHub repository.  In the case of the GitHub repository version, you will need to set the URI of your Azure Mobile App backend.  The repositories are:   Android Apache Cordova iOS (Swift) iOS (Objective-C) Universal Windows (UWP) Xamarin Android Xamarin Forms Xamarin iOS   In each case, look for the ZUMOAPPURL string in the code and replace it with the name of your Mobile App backend.  For the C# projects, this has been placed in a file called `Locations.cs`.  In the other projects, it is embedded in the service handler file, so search for the string.  There will be one match.  There are other great samples using Azure Mobile Apps for you to check out as well:   FieldEngineer is a project for handling field-workers logistics. MyDriving brings together IoT and Mobile to analyze car telemetry. ContosoInsurance demonstrates an example customer-side insurance car claim service.   We are always expanding the samples we offer, so check back often!         ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/04/24/Azure-Mobile-Apps-Quickstart-Samples-available-as-GitHub-repositories.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "April 2017 App Service update",
        "excerpt":"      Byron Tardif     5/1/2017 1:28:42 PM  This month we rolled out a new experience for Azure Functions, new Hybrid Connections UX and new integration with Azure CDN.  New experience for Azure Functions    We have fully re-vamped the portal experience for Azure functions, some of the improvements include:   A dedicated browse blade for Function Apps.  A tree view that allows viewing and managing multiple Function Apps  Filters on subscription and app name, as well as an option to scope the view to just one app  One-click access to all App Service platform features  A convenient way to manage features that have already been configured  Overall UI enhancements to be more consistent with the rest of the Azure portal  You can read more about this in the announcement blog.     New experience for Hybrid Connections  Azure App Service, hybrid connections can be used to access application resources in other networks. It provides access FROM your app TO an application endpoint. Hybrid connections does not know or care what the application protocol is or what you are accessing. It is simply providing network access. Learn more about Hybrid Connections  The new experience makes it easier to create, connect and manage hybrid connections within your web app.  To access this feature go to Settings &gt; Network &gt; Hybrid Connections       New Azure CDN integration  Azure CDN lets you dramatically improve the performance of your application by caching and geo-distributing static content. You can read more about Azure CND here.  Now adding Azure CDN to your web apps is only a few clicks away.  To access this feature go to Settings &gt; Network &gt; Azure CDN       New location for troubleshooting tools    Tools to help you diagnose and debug your app have been moved into Diagnose and Solve problems, the items moved include:   Metrics per Instance (Apps) Metrics per Instance ( App Service Plans) Live HTTP Traffic Application Events Failed Request Tracing logs Diagnostics as a Service Mitigate PHP Debugging (Zend Z-Ray) Security Scanning (Tinfoil)      If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/05/01/April-2017-App-Service-update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Enable PHP error logging in App Service",
        "excerpt":"      mksunitha     5/4/2017 11:03:36 AM  By default PHP error logging is turned off. When your application experiences issues , it would be beneficial to turn the logging on to investigate to root cause of the issue and mitigate it. There are different ways to do this based on whether you are using App Service on Windows or Linux.  Follow the steps below to turn on PHP error logging:  App Service on Windows: Create .user.ini or modify an existing .user.ini file under your web app root directory D:\\home\\site\\wwwroot.You can do this by updating your root directory via FTP , GIT , or Kudu with this change. In this file add the following line log_errors = On  App Service on Linux: Create a .htaccess file or modify an existing .htaccess file under web app root directory /home/site/wwwroot. You can do this by updating your root directory via FTP or GIT with this change. In this file add the following line log_errors = On    Note  Remember to turn OFF your PHP error logging when you have completed your investigation. By leaving the setting ON can have big impact on your web app performance.       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/05/04/Enable-PHP-error-logging-in-App-Service.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing Try App Service Web App on Linux (Containers)",
        "excerpt":"      Apurva Joshi (AJ)     5/10/2017 9:06:33 AM  Web App on Linux is now available for Try App Service. You can now create free trial Web App running on Linux App Service without credit card. All you need is an MSA account.  App Service Web App on Linux (Preview) enables developers to run their cloud apps natively on Docker Containers for Linux. It makes it easier to migrate existing apps hosted and optimized for the Linux platform into Azure App Service. Furthermore, with custom Docker Container support, developers can implement applications in many programming languages and stacks while taking advantage of Docker tooling as well as the industry leading PaaS capabilities of Azure App Service.   Templates  With the initial release, there are two templates available for Web App on Linux.  NodeJS Web App on Linux PHP Web App on Linux   These templates deploys a container with respective runtime, where you can choose to deploy your NodeJS or PHP Web App and give Web App on Linux a try using your MSA account.  Once your trial Web App is created, you can simply manage it using Azure Portal by clicking on “Manage in Azure Portal” option or using CLI option. Once you are logged into the portal it gives you full access to Azure App Service Web App on Linux, where you can test out all the features like slots, SSH, Auto Scale as well as bringing your own container.  Your trial Web App will expire in 30 minutes, but you can sign up for 30 day free trial.  Click Here to Get Started      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/05/10/Announcing-Try-App-Service-Web-App-on-Linux-(Containers).html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Application Insights integration with Functions now in preview",
        "excerpt":"      Chris Anderson (Azure)     5/10/2017 8:00:44 AM  Azure Functions support for Application Insights has moved out of limited beta and into a wider public preview. We’ve also added support to add Application Insights on create, as well as, a direct link from Azure Functions’ portal to the Application Insights blade. We’ve also added additional settings to help control what data get sent and how much to send, helping you to control the volume of data that is sent. Getting Started  To get started with Azure Functions and Azure Application Insights, you can create a new Function App and set the Application Insights toggle to “On”, which will create an Application Insights resource for you, automatically.    If you want to use add an existing Application Insights resource or you have an existing Azure Function App, you can add Application Insights by adding an App Setting with your instrumentation key.  Create an Application Insights instance.  Application type should be set to General Grab the instrumentation key   Update your Function App’s settings  Add App Setting – APPINSIGHTS_INSTRUMENTATIONKEY = {Instrumentation Key}      Once you’ve done this, you can navigate to your Application Insights resource from the “Configured Features” page of your Function App.   Using Application Insights  Live Stream  If you open your Application Insights resource in the portal, you should see the option for “Live Metrics Stream” in the menu. Click on it and you’ll see a near-live view of what’s coming from your Function App. For executions, it has info on #/second, average duration, and failures/second. It also has information on resource consumption. You can pivot all of these by the “instance” your functions are on; providing you insight on whether a specific instance might be having an issue or all of your Functions.  Known issues: there are no dependencies being tracked right now, so the middle section is mostly useless for now. If you send your own custom dependencies, it’s not likely to show up here since they won’t be going through the Live Stream API since you’re normally using a different client, today.   Metrics Explorer  This view gives you insights on your metrics coming from your Function App. You can add new charts for your Dashboards and set up new Alert rules from this page. Failures  This view gives you insights on which things are failing. It has pivots on “Operation” which are your Functions, Dependencies, and exception messages.  Known issues: Dependencies will be blank unless you add custom dependency metrics. Performance  Shows information on the count, latency, and more of Function executions. You can customize this pretty aggressively to make it more useful. Servers  Shows resource utilization and throughput per server. Useful for debugging Functions that might be bogging down your underlying resources. Putting the servers back in Serverless. J Analytics  The analytics portal provides you the ability to write custom queries against your data. This is one of the most powerful tools in your tool box. Currently, the following tables are full of data from the Functions runtime:  Requests – one of these is logged for each execution Exceptions – tracks any exceptions thrown by the runtime Traces – any traces written to context.log or ILogger show up here PerformanceMetrics – Auto collected info about the performance of the servers the functions are running on CustomEvents – Custom events from your functions and anything that the host sees that may or may not be tied to a specific request CustomMetrics – Custom metrics from your functions and general performance and throughput info on your Functions. This is very helpful for high throughput scenarios where you might not capture every request message to save costs, but you still want a full picture of your throughput/etc. as the host will attempt to aggregate these client side, before sending to Application Insights  The other tables are from availability tests and client/browser telemetry, which you can also add. The only thing that’s currently missing is dependencies. There is also more metrics/events we’ll add over the course of the preview (based off your generous feedback on what you need to see).  Example:  This will show us the distribution of requests/worker over the last 30 minutes.     Configuring the telemetry pipeline  We wanted to be sure you can still control what data and how much gets sent, so we’ve exposed a handful of configuration settings for your host.json which allows you to finely control how we send data. We our latest updates to the configuration, you can now control the verbosity levels of the various telemetry pieces, as well as enable and configure aggregation and sampling.   Limitations during preview  Now that we’ve moved out of beta, we don’t have any planned breaking changes, but we’ll still consider the feature in preview from a supportability point of view. Once we’ve had a wider set of users using Application Insights and we complete some missing features like automatic dependency tracking, we’ll remove the preview flag. This means if you should avoid using our Application Insights integration for business critical applications, and instead continuing to instrument your code yourself with Application Insights.        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/05/10/Application-Insights-integration-with-Functions-now-in-preview.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions API development updates",
        "excerpt":"      Matthew Henderson - MSFT     5/10/2017 12:00:32 PM  From HTTP triggers to proxies, Azure Functions provides a variety of tools to make developing serverless APIs quick and easy. The team has been hard at work on improvements to the API development story, including new capabilities for Azure Functions Proxies, as well as a faster way to get your APIs into PowerApps and Microsoft Flow.  Request and response transforms for Azure Functions Proxies  Azure Functions Proxies now allows you to modify requests to and responses from the backend. A new feature of proxies.json allows you to set properties of the HTTP message, including headers, query string parameters, request methods, and response status codes. This can be used to more easily integrate with existing backends or to create mock APIs. As a part of this update, you are also now able to bind parameters from the request/response. For example, you could reference {request.querystring.name} as a part of your backend URL or map them into a new header. To learn more about request and response transforms, see the Proxies documentation.  Express export to PowerApps and Microsoft Flow  App Service and Azure Functions now let you leverage your API from PowerApps and Microsoft Flow with just a few clicks. The Export to PowerApps + Microsoft Flow gesture has been expanded to include an express option, allowing you to do everything right within the Azure portal.    The new gesture will prompt you to select an environment in which the API should be created. You will only be able to use this capability for environments in which you have create API permissions. If you don't have the right permissions, you can still use the \"Manual\" option to get your metadata and provide it to an environment administrator, who can create the API for you.  As part of the express flow, you will also need to provide any security properties that are defined in your OpenAPI (Swagger) document. Note that API keys are currently not supported. If your API does require a key to be provided, you will need to configure this within PowerApps or Flow after exporting.  Beyond that, it's as simple as clicking \"OK\" and seeing your custom API created instantly. This is a great complement to the recent preview of Swagger support for Functions. Now you can create, document, and publish an API to PowerApps and Flow all as a part of your normal Functions workflow.  Providing feedback  As always, we love getting feedback. Let us know how these features work for you, and if there are other parts of API development that could use improvement. You can always reach us in the Forums (App Service, Functions) or on UserVoice (App Service, Functions).      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/05/10/Azure-Functions-API-development-updates.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Connect Azure App Service to Azure database for MySQL and PostgreSQL via SSL",
        "excerpt":"      mksunitha     5/10/2017 8:10:26 AM  Azure Database for MySQL (Preview) and Azure Database for PostgreSQL  (Preview), both services support Secure Sockets Layer (SSL)  encryption. By default if you create a MySQL or PostgreSQL server using this server SSL is required to connect to all databases on that server. With Web Apps , the application needs to provide the certificate authority (CA) is one that the client trusts for the connection to succeed. This involves a few steps .  Follow the steps below to add SSL to an existing application on Azure App Service. Note: These instructions are same whether you are using Windows or Linux based Azure App Service.  Follow the steps in this article on configuring SSL on Azure database for MySQL or PostgreSQL. Create a bin folder under D:/home/site/wwwroot and place the certificate (.pem file generated from step #1) in bin folder.  You can do this directly by accessing  the file server for web app using FTP or Git or Kudu . Log in to Azure portal. Select your existing Web app and click on Application settings. Add the following app setting for your web app: For MYSQL :  For PostgreSQL : Now SSL certificate is added to your web application . Your application code needs to be updated to use this certificate authority when connecting to the database.  Please refer to the documentation of your application framework on how to consume the certificate authority to connect to the database via SSL.  Here are a few examples below. Connect to MySQL server with SSL for WordPress app  Add the following to wp-config.php to connect to the MySQL database via SSL define('MYSQL_CLIENT_FLAGS', MYSQL_CLIENT_SSL); define( 'MYSQL_SSL_CA', getenv('MYSQL_SSL_CA'));  Note:  If you are using PHP 7.X version , you need another flag  MYSQLI_CLIENT_SSL_DONT_VERIFY_SERVER_CERT for any PHP based application. For example with WordPress , you need to update MYSQL_CLIENT_FLAGS as shown below  define( 'MYSQL_CLIENT_FLAGS', MYSQLI_CLIENT_SSL | MYSQLI_CLIENT_SSL_DONT_VERIFY_SERVER_CERT );  Connect to PostgreSQL server with SSL for Drupal app  Add the following to site/default/settings.php  and add PDO options for SSL $databases = array (   'default' =&gt;    array (     'default' =     array (       'database' =&gt; 'databasename',       'username' =&gt; 'username',       'password' =&gt; 'password',       'host' =&gt; 'hostname',       'port' =&gt; '3306',       'driver' =&gt; 'mysql',       'prefix' =&gt; '',       'pdo' =&gt; array(         PDO::PGSQL_ATTR_SSL_CA =&gt; getenv('POSTGRESQL_SSL_CA'),      ),     ),  ); Connect to MySQL server with SSL for Drupal app  Add the following to site/default/settings.php  and add PDO options for SSL $databases = array (   'default' =&gt;    array (     'default' =&gt;      array (       'database' =&gt; 'databasename',       'username' =&gt; 'username',       'password' =&gt; 'password',       'host' =&gt; 'hostname',       'port' =&gt; '3306',       'driver' =&gt; 'mysql',       'prefix' =&gt; '',       'pdo' =&gt; array(         PDO::MYSQL_ATTR_SSL_CA =&gt; getenv('MYSQL_SSL_CA'),         ),       ),   ); Connect to PostgreSQL server with SSL for Django app  Add the following to settings.py  and the options for SSL  DATABASES = {     'default': {         'ENGINE': 'django.db.backends.postgresql_psycopg2',         'NAME': 'dbname',         'USER': 'dbuser',         'PASSWORD': 'dbpassword',         'HOST': 'dbhost',         'OPTIONS': {             'sslmode': 'require',             'ca':os.environ.get('POSTGRESQL_SSL_CA', '')         },     }, }      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/05/10/Connect-Azure-App-Service-to-Azure-database-for-MySQL-and-PostgreSQL-via-SSL.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Create Django Web app with PostgreSQL",
        "excerpt":"      mksunitha     5/10/2017 8:00:57 AM  This tutorial describes how to get started running Django on Azure Web Apps with Azure Database for PostgreSQL(Preview). Web Apps provides limited free hosting and rapid deployment, and you can use Python. Before you begin   If you don't have an Azure subscription, create a free account before you begin. Deploy from Marketplace  This blog post describes how to get started running a Django app with postgresql from Azure marketplace . This marketplace solution creates the following resources : Web Apps on Windows  and Azure Database for PostgreSQL (Preview).  Log in to the Azure Portal. Launch the Django + PostgreSQL template in the Azure marketplace to get started. Provide the necessary information for web app and database to be deployed.        Name Description     App Name   Enter a unique app name for your **Web App Name**. This name is used as part of the default DNS name for your app &lt;app_name&gt;.azurewebsites.net, so it needs to be unique across all apps in Azure. You can later map a custom domain name to your app before you expose it to your users     Subscription Select a Subscription. If you have multiple subscriptions, choose the appropriate subscription.   Resource group   Enter a resource group. A resource group is a logical container into which Azure resources like web apps, databases that is deployed and managed. You can create a resource group or use an existing one    App Service Plan   App Service plans represent the collection of physical resources used to host your apps. Select the Location and the Pricing tier. For more information on pricing, see  App service pricing tier     Server Name Enter a postgresql database servername   Server admin login name Enter a postgresql database administrator username    Server admin password Enter a postgresql database administrator password   Version Azure database for PostgreSQL(Preview) currenlty supports PostgreSQL 9.5 version   Pricing tier Choose Basic or Standard pricing tier. For more information on pricing, see  App service pricing tier    Database Name Enter a database name for your web app    You can watch the progress by clicking the bell icon at the top of the portal page while the app is being deployed.    When the web app creation is finished, navigate in the Azure portal to the resource group to view the web app and PostgreSQL server.   Select the web app line and then click Browse.   Develop your application  The Django + PostgreSQL template contains the Django framework on top of which you can build your application. You can create an Django app using  Kudu.  To access Kudu , select your web app in the portal and click Advanced Tools -&gt; Go .   Click on Debug Console  to access the CMD  prompt. In the console run the following commands  under wwwroot folder. env\\scripts\\python.exe env\\scripts\\django-admin.exe startapp myapp   This will create myapp folder with starter Django app . For more details in Django app, see Get started with Django .   Database configuration  You can access the database information within Azure portal by clicking in Application settings -&gt; Connection strings. It is best practice to use App Settings for storing your database information instead of hard coding it in your settings.py file. Create these app settings in Azure portal for your web app.    Update DATABASES setting in local settings.py file in your application. to read from App Settings environment variables. DATABASES = {    'default': {    'ENGINE': 'django.db.backends.postgresql_psycopg2',    'NAME': os.environ.get('DATABASENAME', ''),    'USER': os.environ.get('DATABASEUSER', ''),    'PASSWORD': os.environ.get('DATABASEPASSWORD', ''),    'HOST': os.environ.get('DATABASEHOST', ''),    'PORT': '5432',   } }  Database Management  Use PgAdmin PostgreSQL Client to manage your PostgreSQL server and database remotely. Django Poll application sample  You can deploy your own app via GIT or use this sample Django-poll application. Fork this sample repository or download to locally to start using the sample. For more information to setup GIT, see Local Git Deployment to Azure App Service. Next Steps   Django Documentation Python Tools for Visual Studio Documentation      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/05/10/Create-Django-Web-app-with-PostgreSQL.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Introducing Azure App Service Support Center",
        "excerpt":"      Apurva Joshi (AJ)     5/10/2017 8:35:13 AM  “Why was my Web App down?”  “How do I fix it?”     These are the common questions with no easy answers. Wouldn’t it be nice if solutions on what to do next are readily available? The Azure App Service Support Center is the answer. You can access it via “Diagnose and solve problems” in the web app settings blade.    There are many reasons why a web app could experience a downtime – for instance, platform service outages, application code bugs, CPU or memory exhaustion, new deployment having unknown bugs, app crashes, faulty VM instances, abnormal recycles, port or socket exhaustions, exceptions in code, thread exhaustions and many more.  In this initial release of Azure App Service Support Center, we are optimizing for the following scenarios  Service outages, platform health issues Abnormal CPU usage Abnormal memory usage Application code issues  Platform Incidents  In the case of a platform incident, your app may be affected. In such cases, Microsoft engineers will have already been engaged to resolve the issue. The “Diagnose and Solve problems” blade will highlight this scenario right away making isolating the issue obvious. Screenshot below is an example of such an incident.   CPU and Memory Issues  High CPU or Memory usage can cause your web app to have downtime. In this case, you can identify the specific instances and web apps consuming resources. Solutions for these issues include  Advanced application restart – restart a specific web app process on a specific instance Restarting the web app – restart the web app on all instances Scale up – scale up to instances with larger memory and more CPU  Screenshot below is an example of such an incident.   Application code issue  Often, issues within the application code are the cause of downtime. These could include bugs, race conditions, external dependencies or your web app throwing exceptions. The failed requests log analysis, threads analysis detectors can determine when failures are a result of an application issue or a result of a platform issue. As instructed in the screenshot below, remote profiling is the best way to troubleshoot application specific issues.  Screenshot below is an example of such an incident.     How does it all work?  Under the covers, the user experience is powered by a big data solution, where we mine large amounts of platform and application data to perform intelligent pattern analysis algorithms and surface most relevant observations and problems. Internally we refer to these algorithms that perform analysis as “detectors”. Each detector analyzes the data and determines the appropriate solutions to fix your problem when it is happening.  The “Solution” option will be displayed when our detectors have determined that there is a mitigation step you could take to recover your web app. In addition, the troubleshoot section contains other mitigation options as well as specific troubleshooting tools.  The goal of this new self-service diagnostics blade is to answer the questions Why was my Web App down? and How do I fix it? The detectors will provide insights and solutions that enable users to quickly mitigate and diagnose any issues. As you continue to use self-serve diagnostics, we will be adding new detectors and improving the existing ones with richer data and solutions that are more precise. Full List of Detectors   Service Health - This detector looks at ongoing and past service incidents. Whenever this happens, Microsoft engineers are engage very quickly and start working to solve the problem CPU Analysis - This detector can identify instances where there is high CPU usage. It can also determine the specific site process within the app service plan that is using the most CPU. Memory Analysis: This detector can identify instances where there is high Memory usage. It can also determine the specific site process within the app service plan that is using the most Memory. Failed Requests Analysis: This detector looks for requests with 5xx http status code, detailed error codes and win32 status codes. It tracks the request’s journey all the way to your application code. If errors are happening purely in application layer (not in platform pipeline) this detector provides suggestions on debugging application code Site deployments: This detector looks for web and kudu deployments as a possible cause for downtime. Site Crashes: This detector looks for abnormal terminations (crashes) of w3wp (application code) processes. Worker Availability: This detector gives you insights into whether the problem is happening on a specific instance, which could point to a resource constraint or another problem with that instance alone. Process Restarts: This detector considers possible reasons that could have caused the application code to restart (w3wp process). Process restarts can cause transient availability issues. Reasons for process restart include: user initiated, config updates, auto heal, resource contentions, etc. Site quota exceeded: This detector indicates when failures are a result of a site in Free or Shared SKU exceeding a quota. When sites exceeded quota limits, the platform turns it off temporarily. Port and Socket Exhaustion: This detector figures when an outbound network connection is rejected because of port exhaustion. Thread and Handle usage: This detector detects if there is abnormally high usage of threads or handles that could affect application’s uptime.  We hope this initiative helps you isolate and root cause issues with your web apps easily. As always, please provide feedback by simply clicking on the smiley - feedback icon at top left corner of the blade.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/05/10/Introducing-Azure-App-Service-Support-Center.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Connecting existing Web App to Azure database for MySQL (Preview)",
        "excerpt":"      mksunitha     5/16/2017 9:11:12 AM  The following steps show how to connect your existing web app on Azure App Service running on MySQL in-app or other MySQL solutions in Azure to Azure database for MySQL (Preview). Before your begin  Log in to the Azure portal . Create a MySQL database on Azure database for MySQL (Preview) service . For details , refer to How to create MySQL database from Portal or How to create MySQL database using CLI. Firewall configuration  Azure database for MySQL provides tighter security using Firewall to protect your data. When using this service with App Service Web Apps , you need to keep in mind that the outbound IPs are dynamic in nature .  To make sure the availability of your web app is not compromised , we recommend to all the rule to allow ALL IPs as shown in the image below.  Note: We are working with Azure database for MySQL (Preview) team for a long term solution to avoid allowing all IPs.   You can explicitly add all the outbound IPs for your web app to MySQL server configuration . To learn more , see how to get outbound IPs for App Service.  App service infrastructure tries to  keep the outbound IPs the same as best as we can , but when recycle or scale operation occurs  it may change since we add new machines on every region frequently to increase our capacity to server customers.  If this changes , the app will experience downtime since it can no longer connect to the database.   Keep this mind when choosing one of the option mentioned above. SSL configuration  Azure database for MySQL (Preview) has SSL Enabled . If your application is not using SSL to connect to the database , then you need to Disable SSL on MySQL server. For details on how to configure SSL , See using SSL with Azure database for MySQL (Preview).    Note that some applications frameworks may not support SSL , hence check your application framework documentation on whether to disable or enable SSL. Migrating from MySQL in-app database to Azure database for MySQL (Preview)  You can migrate MySQL in-app database to Azure database for MySQL (Preview) using Export feature. Note in order to use this feature to export the database , you need to :  Disable SSL since the feature does not work with MySQL database connected via SSL. Allow all IPs is configured on your MySQL server  App Service Back up and Restore features  Currently backup and restore feature does not work with SSL enabled for Azure database for MySQL (Preview). Disable SSL if you are planning to backup/restore the database using App service backup feature . Azure database for MySQL (Preview) also offers backup feature , for more details see here.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/05/16/Connecting-existing-Web-App-to-Azure-database-for-MySQL-(Preview).html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Wiki  WordPress on App Service",
        "excerpt":"      mksunitha     5/16/2017 9:19:59 AM  The Azure Marketplace provides a wide range of popular web apps developed by open source software communities, for example WordPress. The following table of content below will get started on running WordPress on App Service from creating , managing , configuring , performance and troubleshooting WordPress app. WordPress and Azure App Service   What is WordPress? Create WordPress on App Service  Managed MySQL solutions for WordPress   How to purchase Azure Database for MySQL  service MySQL in-app (local mysql) for App Service Connecting Existing web app to Azure database for MySQL  Connect to Azure database for MySQL  using SSL   MySQL on Virtual machines (IaaS)   Deploy a WordPress web app backed with MySQL replication cluster Build your own Master-Master MySQL Cluster using Percona Clusterand learn more on how to manage the cluster Deploy WordPress backed by MySQL replication cluster with master-slave configuration  Migrating and Configuring WordPress Application   Migrating WordPress Deploy your files to Azure web apps Export and Import MySQL Database to Azure database for MySQL (Preview) Use MySQL Workbench to export and importdatabase Export and Import to MySQL in-app database Custom domain for WordPress multisite Use Azure CDN with WordPress  Troubleshooting WordPress Application   How to troubleshoot your WordPress app Gather usage telemetry using Azure Application Insights service Run Zend Zray profiler against your web app to diagnose issues and performance Use Kudu Support portal to diagnose and mitigate issues in real time How to backup your web appand How to restore your web app Secure WordPress  Enable WordPress logs WordPress tools for App service : WordPress Buddy+  Performance   How to speed up WordPress web app How to enabled redis cacheusing redis cache plugin How to enable memcached object cache for WordPressusing memcached plugin Enable wincache with W3 total cache plugin How to use supercache plugin to speed up WordPress app How to server caching using IIS output caching How to enabled browser caching for static content WordPress Cron slowing down the app      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/05/16/Wiki-WordPress-on-App-Service.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Deploying Visual Studio 2017 Function Projects with VSTS",
        "excerpt":"      Donna Malayeri     6/1/2017 9:00:28 AM  With the new Visual Studio 2017 support for Azure Functions, you can now author functions using C# class libraries. With the new project type, triggers and bindings are defined using attributes, which are then converted to function.json as a build task.  To build the project on the server with continuous integration, you have two options: 1) the Continuous Integration feature of Functions, or 2) Visual Studio Team Services (VSTS). The code can be hosted on VSTS or an external service such as GitHub or Bitbucket.  The process is quite easy, thanks to a new build template: ASP.NET Core on .NET Framework. If you’re not familiar with VSTS build definitions, read CI/CD for newbies.  To create a build definition, do the following:  From the Build Definitions view in VSTS, select +New. Choose the template NET Core (.NET Framework). Even though we’re not deploying an ASP.NET Core app, this template has the correctly configured tasks for a Functions project. Add a build task for Azure App Service Deploy.  Ensure you use a VS2017 build agent   Choose an Azure subscription and select your Function App under App Service name. Modify the Package or folder setting to use $(build.artifactstagingdirectory)/**/*.zip Save and queue the build.  Here’s an animated GIF that walks through the VSTS configuration steps:             ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/06/01/Deploying-Visual-Studio-2017-Function-Projects-with-VSTS.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "May 2017 App Service update",
        "excerpt":"      Byron Tardif     6/1/2017 5:01:06 PM  Deployment Slot support for Azure Functions (preview)  Azure functions now support creation of deployment slots, just like apps on App Service you can create slots and perform swap operations between slots.   New Backup experience for apps on App Service  We have revamped the backup experience to make it more streamlined and easier to configure.   New Delete experience for apps on App Service  The new Delete experience provides more information about what will be deleted and allows you to opt out of deleting the App Service plan when deleting the last app hosted in it.      App Service support for Azure Database for MySQL and Azure Database for PostgreSQL  App Service fully supports the new Azure Database for MySQL and Azure Database for PostgreSQL.  You can get started using one of the following templates:  Web App + PostgreSQL Web App + MySQL Web App On Linux + MySQL Web App on Linux + PostgreSQL  If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/06/01/May-2017-App-Service-update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "MySQL in-app feature for Web Apps on Linux",
        "excerpt":"      mksunitha     6/7/2017 11:10:51 AM  MySQL in-app for Linux Web App is not the same as MySQL in-app feature for Windows Azure Web App . This applies to WordPress , Drupal , Joomla and Mediawiki Templates on Linux Web App . For Linux web apps , we leverage the docker container to build MySQL as part of the image used to deploy in the Azure portal, for example WordPress on Linux.  These custom images are available on github. The image uses MariaDB 10.0+ server  with the default port 3306 and is installed ,  configured when the docker image runs on the Linux web app.  Get Database connection  You can get the database information from the Azure portal. Select your web app , then select Application Settings -&gt; App settings. This will list out the database information needed for your web application.   Manage your Local database  You can  access and manage the database using PHPmyadmin that is enabled and configured as part of deployment of the docker image. To view PHPmyadmin tool ,use the URL in this format http://hostname/phpmyadmin and enter the credentials to connect.  You can find the credentials for PHPmyadmin in the Azure portal . Select your web app , then select Application Settings -&gt; App settings      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/06/07/MySQL-in-app-feature-for-Web-Apps-on-Linux.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Pick the right data solution for Azure App Service",
        "excerpt":"      mksunitha     6/8/2017 10:02:11 AM  App Service makes building data driven solutions easier via the Azure portal. Azure app service supports various data solutions like SQL , MySQL  etc. To help understand how these data solutions work with App Service (Web Apps, Mobile Apps, Functions) and pick the right solution based on your needs, view the table below.   * Free Azure SQL DB  offers one SQL Database per subscriptions limited to 32 MB for free for one year. ** Both Linux and Windows App service platforms support use of these data solutions , but based on your application framework you may require additional libraries in your application code to connect to the database. *** Currently App Service backup and restore feature does not support database connections over SSL. **** Azure Functions supports Azure SQL DB , MySQL and PostgreSQL via the  .NET SDK of these respective data services. For cosmos DB you can use binding or the SDK.      Azure SQL DB MySQL in-app  Azure Database for MySQL  Azure Database for PostgreSQL  Cosmos DB   Generally available  ✓ ✓ Public Preview  Public Preview ✓   Free Database Tier  * ✓ ✓      Managed Database as a Service ✓  ✓ ✓ ✓   Remotely access database ✓ ✓ ✓ ✓ ✓   Documentation link link link link link   Scalability ✓  ✓ ✓ ✓   Geo Replication ✓    ✓   SSL ✓  ✓ ✓ ✓   Firewall Configuration ✓  ✓ ✓ ✓   Database Sharding /Partitioning  ✓    ✓   Pricing link  link link link   Region Availability  link   Linux Azure Web Apps ** ✓ link ✓ ✓ ✓   Windows Azure Web Apps ** ✓ link ✓ ✓ ✓   App service Backup and Restore *** ✓ ✓ ✓ ✓    Azure Mobile App ✓    ✓   Azure Functions ****  ✓  ✓ ✓  ✓         ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/06/08/Pick-the-right-data-solution-for-Azure-App-Service.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Deployment Slots Preview  for Azure Functions",
        "excerpt":"      Daria Grigoriu     6/13/2017 11:06:52 AM  The Azure Functions Consumption Plan now includes a preview of deployment slots. Deployment slots are a valuable component of a cloud ready application development lifecycle. The feature enables development and production environment separation to isolate critical production workloads. At the same time deployment slots create a natural bridge between development and production where the next version of a Function App staged in a deployment slot can become the production version with a simple platform managed swap action. For more information on the deployment slots concept as used in the context of the broader App Service platform please see this documentation article.  You can explore the deployment slots preview via Azure Portal. Each Function App includes a view of deployment slots. The preview requires a one-time opt-in for each Function App available under the Function App's Settings tab. Opt-out is not available, simply delete deployment slots if no longer necessary.    After preview opt-in the Function App secrets will be updated. Please copy the new secrets under the Manage node for each function. You can add a deployment slot under the Slots view. For the Consumption Plan you can include 1 other slot in addition to production.    Each deployment slot can be treated as a standalone Function App with its own URL, its own content, and differentiated configuration. That means even input and output bindings can be different and the non-production version can be evolved independently without production dependencies if this is a requirement for your specific workload. You can designate configuration elements such as App Settings or Connection Strings as slot specific to make sure they will continue to be associated with the same slot after swap: e.g. a production slot will continue to point to the same production specific storage account.    To swap a non-production deployment slot to production use the Swap action under the Overview tab for your Function App.    You can select the swap type as direct swap or a swap with preview where destination slot configuration is applied to the source deployment slot to allow validation before the swap is finalized. You can also see a configuration diff to make sure you are aware and can react to how configuration elements are impacted by the swap action.    The deployment slots preview will continue to evolve in the journey to general availability. There are some current limitations such as a single instance scale for non-production deployment slots. If your production Function App is running at large scale this limitation may result in a timeframe where throughput is decreased as the platform re-adjusts the scale after swap. For any questions or issues to share with the engineering team regarding the deployment slots preview please use the Azure Functions MSDN forum.  Follow us on Twitter for product updates and community news @AzureFunctions.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/06/13/Deployment-Slots-Preview-for-Azure-Functions.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Custom hostnames with App Service",
        "excerpt":"      akurmi     6/21/2017 11:47:11 AM  Introduction  App Service has been supporting custom hostnames for a while now, you can read about this feature here. App Service has a shared front-end so before you can use a custom hostname with your app, you need to verify domain ownership by creating the required DNS records. This is done to prevent hostname squatting vulnerability. To add a custom hostname to your app, you need to create DNS records for ownership verification and routing.   Details  There are a few ways to add custom hostnames, most commonly used methods are given below:  CNAME: This is the recommended approach and easier of the two as it requires only one DNS record. To add a custom hostname using CNAME method, you need to create a CNAME record on the custom hostname pointing to the default hostname of the App. For example, if you want to add ‘support.api.contoso.com’ to a web app named ‘contoso’ then you should create a CNAME record on ‘support.api.contoso.com’ pointing to ‘contoso.azurewebsites.net’. In this case, the CNAME record is used for both, verification and routing.        DNS Record Type Sub-domain Value   CNAME support.api contoso.azurewebsites.net                A with TXT: In certain scenarios, a customer may not able to create the required CNAME record. For example, a lot of DNS providers don’t allow CNAME record on the root hostname. In that case, a customer can use this verification method. This requires creating two DNS records on the hostname being added. For example, if a customer wants to add ‘contoso.com’ to a web app named ‘contoso’ then he should create:      An A record on ‘contoso.com’ pointing to web app’s IP address. You can get this IP address from Azure portal or by resolving the default hostname locally. One of the convenient ways to resolve hostname is to simply ping it: ping contoso.azurewebsites.net. A record is used for routing traffic to your app. A TXT record on ‘contoso.com’ with value set to the default hostname. In this case, the value should be contoso.azurewebsites.net. TXT record is used for verification.     DNS Record Type Sub-domain Value   A @ &lt;IP Address&gt;   TXT @ contoso.azurewebsites.net            Recent updates  We recently made the following two changes in our hostname management model:  One to many associations between hostname and Azure subscription: Earlier, a hostname could only be used with one subscription on App Service platform. With this change, now a hostname can be shared by multiple subscriptions. Each subscription needs to validate the domain ownership separately by creating the required DNS records. Allowing a subscription to reclaim a hostname by validating domain ownership: App Service platform consists of multiple scale units. A hostname can only be associated with one app on a scale unit. Even two apps in the same subscription cannot share the same hostname on a scale unit. This is by design as App Service runtime should be able to resolve a custom hostname to an App uniquely. We have received multiple customer reported incidents in the past where a customer had a custom hostname in his old subscription that he could not access anymore for some reason and wanted to use the same hostname with another app on the scale unit. This was not allowed earlier even though the customer could revalidate domain ownership. With this change, now App Service customers can do this themselves.  Apart from these two changes, I would also like to cover some of the most common domain related questions we receive our customers: Migrating a live custom hostname without any downtime  If you would like to move a live custom hostname to App Service, then following the typical verification method would cause downtime between updating the DNS records and adding the corresponding hostname to your web app. If you would like to prevent the downtime, then you can use the alternate ‘awverify’ subdomain instead for verification. Say you would like to add ‘www.contoso.com’ to a web app named ‘contoso’ without any downtime. You can follow these steps to achieve this objective.  Create a TXT record on awverify.www.contoso.com with value set to ‘contoso.azurewebsites.net’ for verification         DNS Record Type Sub-domain Value   TXT awverify.www contoso.azurewebsites.net                Add the custom hostname through Azure portal. Once this is done, you can delete the TXT record created in step 1 if you want. Create a CNAME/A record on www.contoso.com to point it to ‘contoso.azurewebsites.net’. This would start routing traffic to your App Service App.          DNS Record Type Subdomain Value   CNAME www contoso.azurewebsites.net    Or        DNS Record Type Subdomain Value   A www &lt;IP Address&gt;            Adding the same custom hostname to multiple web apps  There are scenarios where a customer would like to add the same hostname to multiple web apps in the same subscription, having a geo distributed website is one example. Our custom hostname feature allows you to bypass validation for hostnames that have already been validated. You only need to verify domain ownership when you add a hostname for the first time. For all other apps in the same subscription, you can add the same hostname without creating any DNS records.    Programmatically manage custom hostnames  We have updated our API surface to expose each custom hostname as a separate resource, giving App Service customers the ability to manage each hostname individually. A custom hostname is represented as ‘Microsoft.Web/site/hostnameBindings’ resource. For example, if you want to add ‘www.contoso.com’ to a web app called ‘contoso’ then first you need to create a CNAME record on this hostname pointing to ‘contoso.azurewebsites.net’. After that, you can add the hostname by calling the following ARM API:  ARMClient PUT /subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourceGroups/Default-Web-EastAsia/providers/Microsoft.Web/sites/contoso/hostnameBindings/www.contoso.com?api-version=2016-03-01 \"{'Location':'West US','Properties':{}}\"  You can also use the following ARM template for adding custom hostnames:  https://github.com/Azure/azure-quickstart-templates/tree/master/201-web-app-custom-domain     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/06/21/Custom-hostnames-with-App-Service.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Installing public certificates in App Service",
        "excerpt":"      akurmi     6/27/2017 2:10:45 PM  Introduction  Today, we are announcing the support for installing public certificates in personal certificate stores. We are currently building a user-friendly experience to expose this functionality via Azure portal. In the meantime, you can use ARMClient/Azure Resource Explorer/Azure PowerShell/Azure CLI for calling the corresponding backend APIs to use this feature right away. For this blogpost, I will be using ARMClient to demo these APIs. Details  To support public certificates, we have created a new ARM resource type called ‘sites/publicCertificates’ under ‘Microsoft.Web’ resource provider. Each instance of this resource represents a certificate installed in your App Service. To install a public certificate, you can call the following PUT API on an existing App Service:  ARMClient PUT https://management.azure.com/subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourcegroups/publiccertificaterg/providers/Microsoft.Web/sites/publiccertificatedemo/publicCertificates/currentuser1?api-version=2016-02-01  \"{'Properties':{'Blob':'MIIC/zCCAeugAwIBAgIQjngbV7+4eppN1YUvFh8guDAJBgUrDgMCHQUAMBgxFjAUBgNVBAMTDXRlc3RjZXJ0MS5jb20wHhcNMTcwNDAzMjIyMTI1WhcNMzkxMjMxMjM1OTU5WjAYMRYwFAYDVQQDEw10ZXN0Y2VydDEuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAiq+O7aP68Q5uCr0u0fRlOCXpIYw498Yk2sxdR3ElgF+nD8pmgdrAbGaGlBcxO0i/YrITgD5n73BBL17QPFNx7Y8mHl3U7vOAYkYHVZQlJVc8XPmjmgL6ZGSquPkJhev9vg1U26mJHdjoOprN2dSZIKw7VB+DbBgHipjFsaxe99GocQeQxNoa93wu7uWRgI0foKgYgDBEWbyMSgT6ZXQUwoQVNTDSPmQ8PlNrAOJz3cLM6jp0e0ZKDPJEqRXm3UX6F7DcOR0G7OvUil56Ze9ANNcF2bTwTpdCLPx2OImnKCeb5Vyxg9Ymtu3aAm9U5qX8pXAZu+oU5NAiJx1TvlJkPQIDAQABo00wSzBJBgNVHQEEQjBAgBCqtQL/bkUvJkvip2NwKuuPoRowGDEWMBQGA1UEAxMNdGVzdGNlcnQxLmNvbYIQjngbV7+4eppN1YUvFh8guDAJBgUrDgMCHQUAA4IBAQA9y0GjiioOMjKFLJAqFoePeW2/MH+8QAJYvsmchZ5J8gq4TrpKbw2xrIuHmRmHv+hNAGGMGNoPg9JHHk8YuHCvaNM/10HGu0xHzgG7sEui/3MA7jAbMHQOaE54G4HiBVVFabo6li7WjSsx+RjlxNPtb+GMcBoDBAXcbzBmj/1BPNyrlwdBZHpwwnZBJpH+xHWXwIyyqBBAtQiXv7SSV79bwxPRhvCH6rhF8e0qXNGFHIDTiuDol8+eBBiGOEDwB79zDWLlvbXxKxxtQq2KqKhiLntLs1f9tohF6ad7HN5nK1RLPmqC/hoYA+/Fx5jpoX/pQo3Vlf3KMsr1280JSqq8','publicCertificateLocation':'CurrentUserMy'}}\"  Parameters: /subscriptions/…/sites/publiccertificatedemo: Resource Id of the App Service that would be using the public certificate. This App Service needs to be in a dedicated App Service Plan. publicCertificates/currentuser1: User friendly name of the ‘sites/publicCertificates’ resource that represents this public certificate. blob: Base 64 encoded .cer file that contains a public certificate. publicCertificateLocation: Location in Windows certificate store where this certificates would be installed. We only support 'CurrentUserMy' for public scale units. If your site is inside an App Service Environment, then you can also use ‘LocalMachineMy’.  I have written a simply asp.net page that lists all certificates in CurrentUser-Personal certificate store.   protected void Page_Load(object sender, EventArgs e) {     var store = new X509Store(StoreName.My, StoreLocation.CurrentUser);     store.Open(OpenFlags.ReadOnly);     foreach (var certificate in store.Certificates)     {         Response.Write(string.Format(\"Subject:{0} Thumbprint:{1} SerialNumber:{2} HasPrivateKey:{3} &lt;br /&gt;\", certificate.Subject, certificate.Thumbprint, certificate.SerialNumber, certificate.HasPrivateKey));     }     store.Close(); }  Here is a screenshot of this App Service after executing the ARM client command shared above.   Similarly, we can execute the following ARMClient command to install another public certificate in CurrentUser-Personal certificate store:  ARMClient PUT https://management.azure.com/subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourcegroups/publiccertificaterg/providers/Microsoft.Web/sites/publiccertificatedemo/publicCertificates/currentuser2?api-version=2016-02-01  \"{'Properties':{'Blob':'MI…nc','publicCertificateLocation':'CurrentUserMy'}}\"   Since ‘sites/publicCertificates’ is an ARM resource, you can call other standard ARM APIs to perform CRUD operations.  List all public certificates inside an App Service: ARMClient GET https://management.azure.com/subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourcegroups/publiccertificaterg/providers/Microsoft.Web/sites/publiccertificatedemo/publicCertificates?api-version=2016-02-01  Remove a specific public certificate: ARMClient DELETE https://management.azure.com/subscriptions/fb2c25dc-6bab-45c4-8cc9-cece7c42a95a/resourcegroups/publiccertificaterg/providers/Microsoft.Web/sites/publiccertificatedemo/publicCertificates/currentuser2?api-version=2016-02-01 ARM Template  You can use the following ARM template for installing a public certificate inside an existing App Service.  https://github.com/Azure/azure-quickstart-templates/tree/master/201-web-app-public-certificate Getting in touch  Please give this feature a try and let us know your thoughts. If you run into any issues or have any comments then please let us know on the App Service forum.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/06/27/Installing-public-certificates-in-App-Service.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "FAQ  Azure marketplace for Web Apps",
        "excerpt":"      mksunitha     6/29/2017 6:36:46 PM  Here is a list of frequently asked questions designed to provide a better understanding of the Azure marketplace for Web   How do I submit my Web Application to Windows Web Application Gallery? A. You can submit your application here. Before you submit the application please read through the guidelines and process for submission in this article. Why is Deployment option connected to a github repository when I deploy an application like WordPress from the marketplace? A. The deployment process for application from the marketplace uses a GIT deployment method. This makes it easier for app owners to push updates to the application as quickly as possible and have it available to Azure users. Hence we use a github repository configured by the app owner with the application code that is deployed during provisioning of the application. How long does it take for the Web Application Gallery Team to validate the application? A. Once the application is submitted, it will take 3-5 business days for us to validate the application and send you the status. How do I build a package for Web Application Gallery? A. Please refer to this article on how to to build a package for Azure marketplace. How do I test my application for Windows App Gallery? A. Find the process to test your application in the following article. Can I on-board a commercial application to the Azure marketplace? A. Yes. Commercial application are supported with Bring your own License model (BOYL). Here are two approaches on how to allow an azure user to acquire a license:  Approach 1 :  Ask customer to purchase an license from solution partner website directly. Provision the application solution from the Azure Marketplace When user views the app in the browser ask user to enter the license information Solution partner API are called to validate the license key and allow the user to use the application solution as documented by the solution partner   Approach 2 :  Provision the application solution from the Azure Marketplace When user views the app in the browser the app ask the user to provide the information needed to procure a license key from the run time experience using solution partners APIs.     An application was removed from the marketplace and how do I deploy the same solution? A. If an application is removed from the marketplace , this means it is no longer supported by the application owner in the marketplace. In such cases we remove the application if it does have support from the application owner to maintain fixes or issues. If you want to deploy the same application , you can. Follow these steps to do so :  Create an empty Web App and any additional resources such as MySQL , SQL DB etc that the application may need. Access the web application file storage and deploy the code via FTP or GIT. Browse the application and complete the installation of the application based on the documentation provided in the application framework documentation. If you run into issues , please report these issues in the community forums for the application being used .        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/06/29/FAQ-Azure-marketplace-for-Web-Apps.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "June 2017 App Service update",
        "excerpt":"      Byron Tardif     6/30/2017 3:14:58 PM  This month we shipped improvements to the overview blade, a new unified create experience for both Windows and Linux based apps as well a new recommendation history UX. New App Service Overview blade  The overview blade for Web, Mobile and API apps has been overhauled with new charting controls and performance improvements, this should make browsing through your apps faster. The new charts integrate nicely with Azure Monitor and are perfect for pinning into custom dashboards.   Integrated create experience for Windows and Linux based apps  With this update you can now choose the OS of the App Service plan used to host your app. Learn more about Web App on Linux.   App Service Advisor recommendation history  App Service Advisor provides proactive recommendations on how to solve problems with your application. We have revamped this UI to also include a history of the recommendations that have triggered in the past.    If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/06/30/June-2017-App-Service-update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Alpha Preview for Durable Functions",
        "excerpt":"      Chris Anderson (Azure)     7/6/2017 9:13:39 AM  Last week, we open sourced an early preview version of our new Durable Task Framework extension for Azure Functions (also referred to as Durable Functions) and we now have instructions on how to set it up to test both locally and on Azure. We’re really excited about this binding and expect it to make a difference a lot of scenarios including complex chaining scenarios, fan in/fan out patterns, stateful actors, and scenarios with long callbacks. Introducing Durable Functions  Durable Functions is actually just us doing the work of setting up the Durable Task Framework and managing it for you, at scale. Durable Task Framework was designed to allow you to write code based orchestrations based on async/await in C#. This enabled the following:  Definition of code in simple C# code Automatic persistence and check-pointing of program state Versioning of orchestrations and activities Async timers, orchestration composition,  With Durable Functions, we let you write orchestrators and activities as Functions. Orchestrators can call Activity Functions and wait for an external event. Activity Functions can be written in any language and don’t have any restrictions on them that normal functions don’t have. Combined, this functionality allows a lot of complex patterns to be expressed via code. For instance, the code below will fan out and call various Activity Functions, wait for them all to complete, and then allow you to sum the results (fan in). This pattern was possible before, but involved a lot more code that was unrelated to the business logic.  [code lang=\"csharp\" highlight=\"18,23\"]#r \"Microsoft.Azure.WebJobs.Extensions.DurableTask\"  public static async Task&lt;long&gt; Run(DurableOrchestrationContext backupContext) {     string rootDirectory = backupContext.GetInput&lt;string&gt;();     if (string.IsNullOrEmpty(rootDirectory))     {         rootDirectory = Environment.CurrentDirectory;     }      string[] files = await backupContext.CallFunctionAsync&lt;string[]&gt;(         \"E2_GetFileList\",         rootDirectory);      var tasks = new Task&lt;long&gt;[files.Length];     for (int i = 0; i &lt; files.Length; i++)     {         tasks[i] = backupContext.CallFunctionAsync&lt;long&gt;(             \"E2_CopyFileToBlob\",             files[i]);     }      await Task.WhenAll(tasks);      long totalBytes = tasks.Sum(t =&gt; t.Result);     return totalBytes; } [/code]  In the above code, you can see the highlighted lines fanning out and calling many Functions (18), and then waiting for them all to complete on the second highlighted line (23).  Getting started  This is not a feature for everyone to try. It involves quite a lot of set up and is not very user-friendly yet. We recommend using VS and the local tooling to get started as it is the easiest way, but it requires installing the latest update from VS and the newest Functions tooling, which can take some time to set up. You can find the full instructions on how to get started on the documentation page. Note that the documentation is currently on GitHub but will move to docs.microsoft.com very soon.  If you encounter any issues or have any feedback, please submit it on the github repo. Roadmap  There are a few things we’re still working on before it will be available for a beta quality preview. We’ll blog again once it’s available for a wider preview. Mainly, we are already planning on adding:  Templates for all the primary scenarios Scaling support in Consumption Plan (will not scale properly today) Automatic installation (no dragging/dropping zip files)  We hope to make progress on this during the rest of the summer. What’s next?  For the brave, please try it out. Your feedback will shape the future of this feature. We think having built in support for Functions to call other Functions and orchestrate a set of Functions is a very big step forward for Azure Functions and serverless in general, but want to take our time to make sure we get the model right and the experience of managing it nice and polished.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/07/06/Alpha-Preview-for-Durable-Functions.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Web App PHP updates",
        "excerpt":"      Donna Malayeri     7/10/2017 1:16:26 PM  PHP updated to latest versions  Azure App Service has updated the PHP stacks to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.    PHP Version Change log   5.6.31 http://www.php.net/ChangeLog-5.php#5.6.31   7.0.21 http://www.php.net/ChangeLog-7.php#7.0.21   7.1.7 http://www.php.net/ChangeLog-7.php#7.1.7        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/07/10/Azure-Web-App-PHP-updates.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "FAQ  SSL certificates for Web Apps and  App Service Certificates",
        "excerpt":"      mksunitha     7/24/2017 11:06:00 PM  Here is a list of commonly asked questions for App Service Certificates. How do I purchase and configure a new SSL certificate in Azure for my web app?  To learn how to purchase and set up an SSL certificate for your App Service web app, see Add an SSL certificate to your App Service app.  I am unable to purchase an SSL certificate or App Service certificate ?  This could be caused due to one of the following reasons:  App Service plan is Free or Shared pricing plans. We do not support SSL for these pricing tiers. Subscription does not have a valid credit card Subscription offer does not support purchase an App Service certificate such as Microsoft Student offer Subscription has hit the maximum limit of purchases allowed on a subscription App Service certificate was marked as fraud. You will see this error “Your certificate has been flagged for possible fraud. The request is currently under review. If the certificate does not become usable within 24 hours”   Try any of these solutions based on the cause  Upgrade App Service plan to Standard Pricing tier for Web App Add a valid credit card to your subscription if you don’t have one If you are using Microsoft Student subscription or other Azure subscriptions where App Service certificate is not supported, please upgrade your subscription App Service Certificates has a limit of 10 certificate purchases for Pay-As-Go and EA subscriptions types and for other subscription types the limit is 3. To increase the limit Kindly share the following details with us if you want to increase the purchase limit on your subscription for certificates:  Please articulate the business reason for increasing the purchase limit on your subscription. Monthly spending cap on this subscription if any Does the subscription have a valid credit card associated with the subscription    We shall review and evaluate your business needs internally to either approve or reject your request provided there are no other constraints to meet these needs for you.  If the certificate is marked as Fraud and has not been resolved after 24 hours , then follow the steps below :  Go to App Service certificate in Azure portal Click on Certificate Configuration -&gt; Step 2 : Verify -&gt; Domain Verification Click on Email Instructions which will send an email to GoDaddy to resolve the issue    When does my certificate get renewed?  App Service certificates are valid for one year. If Auto Renew is on for an ASC then it will be renewed automatically before it expires and just like ReKey operation, the linked App Service Apps will be moved to the new certificate. You can change this setting by clicking on ‘Auto Renew Settings’ which is on by default. You can also manually renew a certificate by clicking on Manual Renew irrespective of the current Auto Renew setting if the certificate expiration is within 90 days. How can I Rekey and/or ReSync my app service certificate?  In order to stay compliant, many web companies need to rotate their certificates periodically. Also if a customer believes that his certificate has been compromised then he should rotate the certificate as soon as possible to minimize likelihood of the stolen certificate being used for malicious purposes. Traditionally, this requires obtaining a new certificate from the CA which is as complicated as buying a new one. Once a new certificate is created, you need to update all App Service Apps one by one manually. With ASC, we support one click ReKey. ASC allows you to ReKey a certificate unlimited number of times during its lifetime for free.   Using Rekey and Sync option in the portal : This blade displays the current sync state. You can see the thumbprint of ASC along with the thumbprints of all App Service linked certificates. When these certificates are in sync, all thumbprints will match and when they are out of sync, one or more linked certificate thumbprints will be different from the ASC thumbprint. In order to rotate the certificate, click ReKey at the top. The ASC status will move to Rekey Certificate which may take 5-10 minutes. You dont have to click on Sync since a background task runs every 8 hours to sync the changes in the certificate. To force a sync , you can click on the Sync  button .   I see certificate errors shown when enforcing HTTPS?  If your web app gives you certificate validation errors, it could be due to :   Using a self-signed certificate :  In this case avoid using Self signed certificate since we cannot verify the domain ownership . This is not supported with Azure web apps Missing intermediate certificates when you export your certificate to the PFX file : In this case , recreate the PFX file and follow guidance here to make sure intermediate certiificates are also included when exporting it in PFX format. Domain host name is not added to the Web app:  Please add the domain hostname to your web app as per instructions here If using App Service certificate domain verification is not completed :  In this case , your certificate is not ready to be used. Please complete domain verification step as described here.  Can I get the intermediate certificates for mysite.azurewebsites.net  We support HTTPS on *.azurewebsites.net  domain name. Since this domain is owned by App Service Team , we do not share the certificate information with users for security reasons. We recommend to use a custom domain and bring your own certificate for a production application. Domain verification is not working  for App service certificate ?  We provide alternate solution to manually verify your domain . Manual verification lets you verify domain ownership through your DNS configuration by adding a TXT record.  Follow these steps to complete Manual verification :  Go to the Domain Name Service (DNS) provider for your domain name    Add a Txt record for your domain with value of the domain token showed in the portal .  Wait a few minutes for DNS propagation to take place and click on Refresh button to trigger the verification.  Alternate method to manually verify is the Html Web Page method which can be used to allow the certificate authority to confirm the domain ownership of the domain the certificate is issued for.  Create an HTML filenamed {Domain Verification Token}.html. Content of this file should be the value of Domain Verification Token. Upload this fileat the root of the web server hosting your domain Click on Refresh button to check the Certificate status. It might take few minutes for verification to complete.  For example, if you are buying a standard certificate for azure.com with Domain Verification Token ‘1234abcd’ then a web request made to http://azure.com/1234abcd.html should return 1234abcd.   Important notice : A certificate order has only 15 days to complete domain verification operation, after 15 days the certificate is denied by the certificate authority, you are not charged for the certificate. Please delete this certificate and try again. My SSL certificate is not being auto-renewed ?  All App Service certificates issued prior to March 31st 2017 will receive an email to re-verify their domain at the time of renewal even if the auto-renewal is enabled for your certificate.This is a result of change in GoDaddy policy.  Please check your email and complete this one-time domain verification to continue to auto-renew the SSL certificate. Also , note that GoDaddy does require you to verify your domain once every three years and you will receive a email once every three years  to verify your domain. Can I bring my own SSL certificate and how do I upload/configure it for my web app?  Yes , you can bring your own SSL certificate. To learn how to upload and set up an existing custom SSL certificate, see Bind an existing custom SSL certificate to an Azure web app.  My App Service certificate is flagged for fraud. How do I resolve this?  During the domain verification of an App Service certificate purchase, you might see the following message:   “Your certificate has been flagged for possible fraud. The request is currently under review. If the certificate does not become usable within 24 hours, please contact Azure Support.”  As the message indicates, this fraud verification process might take up to 24 hours to complete. During this time, you'll continue to see the message. If the certificate is marked as Fraud and has not been resolved after 24 hours , then follow the steps below :   Go to App Service certificate in Azure portal Click on Certificate Configuration -&gt; Step 2 : Verify -&gt; Domain Verification Click on Email Instructions which will send an email to GoDaddy to resolve the issue .  My App Service Certificate is still showing old secret value. How can I force a sync with the new secret in my Key Vault’ ?  You can rekey your certificate using a new private key by following the details instructions in this article. How do I buy EV SSL for using with Azure web app  App Service certificate does not support purchasing EV SSL from Azure portal. But there are other options to use EV SSL with Web apps. For details , click here Can I export my App Service certificate for use with other Azure services such as Cloud Services and so forth?  We've gotten a lot of feedback from customers asking for this ability, so we now allow you to export your certificate as a PFX file so that you can use it across multiple subscriptions and Azure services. See this blog post for more information. Can I export my App Service certificate to be used outside of Azure, such as for a website hosted elsewhere?  App Service Certificates can be used for any Azure or non-Azure Services and is not limited to App Services. To do so , you need to create a local PFX copy of an App Service certificate that you can use it anywhere you want. For more information, read Creating a local PFX copy of an App Service Certificate. Can I use my App Service certificate in a different subscription in Azure?  You can migrate your App Service Certificate within the Azure portal. You can also export it as a PFX file for use in another subscription. See this blog post for more information. I have a Free or a DreamSpark Azure subscription. Can I purchase an App Service certificate with my credits?  Because Free and DreamSpark Azure credits are free credits, they cannot be used to purchase App Service certificates. Can I get a refund if I purchase an SSL certificate and then decide that I no longer need it?  Unfortunately, we cannot refund you on the purchase of an SSL certificate. How do I update an SNI or IP based SSL binding on web app ?  Note : When the binding is updated , please wait for 24 hours for the change to reflect in the Azure portal . To avoid downtime with your web app  , make sure you updated the binding for SSL at least a week prior to the expiration of your current SSL certificate.   Login to the Azure portal and select your web app. To update and SSL binding :  Upload a new certificate Click \"Add binding\" in SSL certificates setting for your web app Select your domain Select your certificate Click Add binding. Note that by adding an SSL binding with a hostname used in another binding will override the existing binding.           ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/07/24/FAQ-SSL-certificates-for-Web-Apps-and-App-Service-Certificates.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Assign App Service domain to Azure VM or Azure Storage",
        "excerpt":"      mksunitha     7/31/2017 10:16:06 AM  App Service domains (preview) simplifies to create and manage domains for various Azure services. App Service domains leverages Azure DNS for hosting the domain and GoDaddy as the domain registrar.In addition to the domain registration fee, usage charges for Azure DNS apply. For information, see Azure DNS Pricing.  This tutorial shows you how to buy an App Service domain and assign DNS names a Virtual machine and Azure Storage   Sign in to Azure  Open the Azure portal and sign in with your Azure account.  Navigate to the app in the Azure portal  From the left menu, select New -&gt; Everything -&gt; App Service Domain (preview)    Purchase a domain  In the App Service Domain page, in the Search for domain box, type the domain name you want to buy and type Enter. The suggested available domains are shown just below the text box. Select one or more domains you want to buy.   Click the Contact Information and fill out the domain's contact information form. When finished, click OK to return to the App Service Domain page. Next, select the desired options for your domain. See the following table for explanations:     Setting Suggested Value Description     Subscription Pay-As-You-Go Select a Subscription. If you have multiple subscriptions, choose the appropriate subscription.   Contact Information Enter your contact information  such as address, phone number etc .. Fill out the domain's contact information form. When finished, click OK to return to the App Service Domain page.   Resource Group myprojectgroup Enter a resource group. A resource group is a logical container into which Azure resources like web apps, databases that is deployed and managed. You can create a resource group or use an existing one   Auto renew Enable Renews your App Service Domain automatically every year. Your credit card is charged the same purchase price at the time of renewal.   Privacy protection Enable Opt in to \"Privacy protection\", which is included in the purchase price for free(except for top-level domains whose registry do not support privacy protection, such as .co.in, .co.uk, and so on).   Accept terms and purchase Accept Click Legal Terms to review the terms and the charges, then click Buy.    Assign domain to Azure Virtual machine  Resource Manager VMs can have a Public IP. A VM with a Public IP address may also be behind a load balancer. You can create a DNS A or CNAME record for the Public address. This custom name can be used to bypass the VIP on the load balancer.  To verify if you VM has a public IP , go the resource group used by the VM to see if you have a resource \"Public IP address\" .    You can get the IP address by selecting the Public IP address resource or select your Virtual machine to get the IP address    Select your domain and choose DNS Zone setting    Click on Add a Record Set . Add an A record for your Public IP  configured to a subdomain alias such as www or blog  as shown below. Configure your TTL setting on when your domain should resolve to the new domain hosting service.   Enter your domain in a browser address bar based on your TTL configuration. Add Custom domain for Azure storage  Create an App Service Domain . Once provisioned , select DNS Zone setting and Add a record set .  Create a new CNAME record and provide a subdomain alias such as www or images. Then provide a host name, which is your Blob service endpoint, in the format my-storage-account-name.blob.core.windows.net (where my-storage-account-name is the name of your storage account).    Go to your storage resource in the Azure portal and select Custom Domain setting. In the text box on the Custom domain blade in the Azure portal, enter the name of your custom domain, including the subdomain. For example, if your domain is example.com and your subdomain alias is www, enter www.example.com. If your subdomain is images, enter images.contoso.com. The subdomain is required.    Click on Save. Access your files on Azure storage using the custom domain. Auto Renew your Domain  You can change your billing setup for your domain registration anytime to either enable or disable auto-renew by selecting Domain Renewal setting    App Service domains can be used to setup domain for other Azure services as stated in this article.  Note : The hostname bindings setting only shows Web Apps and Traffic Manager if confugred to your domain for now. Your VM or Storage or any other Azure service using this domain will not show up in hostname binding setting. We will continue to work on improving this experience to display other services assigned to the domain.    Submit your ideas/feedback in UserVoice. Please add [Domain] at the beginning of the title.         ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/07/31/Assign-App-Service-domain-to-Azure-VM-or-Azure-Storage.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "July 2017 App Service update",
        "excerpt":"      Byron Tardif     7/31/2017 3:47:02 PM  This month we rolled out a few major releases for App Service: Public preview for new App Service Environments (ASEv2)  New app service environments offer: faster scale operations, simplified management, more powerful instances (backed by Dv2-series VMs ) amongst may other improvements. Learn more about App Service Environments v2     Public preview for new App Service Premium tier (Premium V2)  The new Premium V2 tier features Dv2-series VMs with even faster processors, SSD storage, and double the memory-to-core ratio compared to the previous compute iteration. Learn more about App Service Premium v2 Preview New App Service Domains Experience  The ability to buy and assign custom domains to you App Service apps has existed in the portal for some time, however we have now extended those domain to be full on managed resources with their own UX independent of the app.  App Service Domains are now also backed by Azure DNS making it easier to use App Service Domains with IaaS instances, Traffic Manager Azure CDN. Learn more about App Service Domains      If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/07/31/July-2017-App-Service-update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "FAQ  App Service Domain and Custom Domains",
        "excerpt":"      mksunitha     8/8/2017 11:58:41 PM  Here are most frequent questions asked about App Service domains . Custom Domains  How do I resolve 404 error \"Web Site not found\"  when I browse my site ?  You are seeing this error due to one of the reasons listed below :  The custom domain configured is missing a CNAME and/or A record . To configure the domain to your app, see how to map an existing domain .  If you added an A record , make sure a TXT record is also added. For more details , see here   The browser client might still be caching the old IP address for your domain. Clear the cache by running the command  ipconfig /flushdns . Verify your domain is pointing to the web app IP address using WhatsmyDNS.net .  I am unable to add a new sub-domain ?  One of the following reasons might be preventing you from purchasing a domain  Check you have permissions to modify the web app and add a sub domain hostname You may have reached the max limit for subdomains . You can add max of 500 hostnames to your web app.  You may have reached max limit for sub-domains if you are using GoDaddy domain hosting.  The current limitation if using GoDaddy is 100. If you need more sub-domains , you may choose to migrate to Azure DNS    Can I  move my web app with a custom domain to another subscription or from ASE V1 to ASE V2?  Yes you can move your web app across subscriptions . Follow the guidance in How to move resources in Azure . There are a few limitations when moving the web app , click here to view the limitations.  For domains attached to your web app , if they are already added to your web app with a hostname binding  then after moving the web app you should see the same host name binding within custom domains setting. No additional steps needed here. Unable to add  custom domain to my Web app ?  This could be due one of the following reasons:  You don’t have permission to add a hostname : Check with subscription admin to make sure you have a permissions to add a hostname Your domain ownership could not be verified : If domain ownership is failing , verify if your CNAME or A record are configured correctly . To map custom domain to web app , create either a CNAME or A Record . If you want to use root domain , you must use A and TXT records as well Your domain is not available to use :  You can use the custom domain with one web app , say for example www.mydomain.com can be added to one azure web app . In order to use the same the domain with another web app , you need to use another subdomain say xyz.mydomain.com but you CANNOT use www.mydomain.com  .    You see the error \"The DNS record could not be located\"  One of the reasons could be causing the issue:  TTL live has not expired. Check you DNS configuration for your domain what TTL is and wait it out. DNS configuration is not right  Try one of these solutions to resolve the issue  Wait for 48 hours and this should automatically resolve. If you can modify the TTL setting in your DNS configuration , go ahead and make the change to 5 minutes or so to see if this resolves the issue Verify your domain is pointing to the web app IP address using net. If not fix the A record to be configured to the right IP address of the web app  App Service Domains    I am unable to purchase a new Domain ?  One of the following reasons might be preventing you from purchasing a domain  Check you credit card on the Azure subscription is still valid If you are not the subscription owner , check you have permissions to purchase a new domain. (i.e Contributor or Owner roles ) You may have reached the limit to purchasing domains on your subscription. The current limit is 20.  Do I have to configure my custom domain for my website once I buy it?  When you purchase a domain from the Azure portal, the App Service application is automatically configured to use that custom domain. You don't have to take any additional steps. Watch how to configure domain on Channel9. You domain is no longer visible in the Azure portal or Domain was accidentally deleted  The domain may have been accidentally deleted by the owner of the subscription. If your domain was deleted less than 7 days ago , the domain has not yet started the deletion process.  Hence you can buy the same domain again on Azure portal under the same subscription (make sure to type the exact domain name in search text box).  You will not be charged again for this domain.  If the domain was deleted more than 7 days ago , please contact Microsoft Azure support for assistance to restore the domain. Can I use a domain purchased in the Azure portal to point to an Azure IaaS VM instead?  Yes you can point the domain to an IaaS VM , Storage etc  . See How to assign domain to a Virtual machine or Azure Storage. Is my domain hosted by GoDaddy or Azure DNS?  You domain is registered with  GoDaddy service but hosted on Azure DNS I have auto-renew enabled  but still received a renewal notice for my domain via email . What should I do ?  You do not need to take any action in this case if you have auto -renew enabled  . The notice email if to just inform you that the domain is close to expiring and to  renew manually if auto-renew is not enabled. Will I be charged for Azure DNS hosting  my domain ?  The  initial cost of domain purchase applies to domain registration only. In addition to the registration cost , there will be incurring charges for Azure DNS based on your usage. See Azure DNS pricing for more details. I purchased my domain earlier from the Azure portal and want to move from GoDaddy hosting to Azure DNS hosting . How can I do this ?  It is not mandatory to migrate to Azure DNS hosting. If you do wish to migrate to Azure DNS , you will see a message in domain management experience within the Azure portal about next steps to move to Azure DNS. Migration from GoDaddy hosting to Azure DNS is a few clicks away and seamless as long as the domain was purchased from App Service. I would like to purchase my domain from App Service Domain but can I host my domain on GoDaddy instead of Azure DNS?  For every new App Service domain purchased in the portal since July 24 2017 , will be hosted on Azure DNS. If you prefer to choose a different hosting provider , you need to go to their website to procure domain hosting solution. Do I have to pay for privacy protection for my domain?  When you purchase a domain through the Azure portal, you can choose to add privacy at no additional cost. This is one of the benefits of purchasing your domain through Azure App Service. If I decide I no longer want my domain, can I get my money back?  When you purchase a domain, you are not charged for a period of 5 days, during which time you can decide that you do not want the domain. If you do decide you don't want the domain within that 5-day period, you will not be charged. (.uk domains are an exception to this. If you purchase a .uk domain, you will be charged immediately and you cannot be refunded.) Can I use the domain in another Azure App Service app in my subscription?  Yes. When you access the Custom Domains and SSL blade in the Azure portal, you will see any domains that you have purchased and you can configure your app to use any of those domains. Can I transfer a domain from one subscription to another subscription?  You can move a domain to another subscription/resource group by using 'Move-AzureRmResource' PowerShell cmdlet. How can I manage my custom domain if I don't currently have an Azure App Service app that is not a free app?  You can manage your domain even if you don't have an App Service Web App. Domains can be used for Azure services like Virtual machine, Storage etc . If you intend to use the domain for App Service Web Apps , then you need to include a Web App that is not on the Free App Service plan in order to bind the domain to your web app. How can I transfer my domain out of Azure  Follow the steps below to transfer out the domain  Login to Azure portal Select your App Service domain that you wish to transfer out Go to Advance management for the domain Click your domain -&gt; manage Under \"Additional Settings\" a. Unlock your domain . Click on Edit for \"Domain lock\" and turn it Off. b. Click on Transfer domains away from Azure to follow instructions to transfer out .      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/08/08/FAQ-App-Service-Domain-and-Custom-Domains.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "New tabbed experience for Azure Functions UX",
        "excerpt":"      Byron Tardif     8/8/2017 4:19:41 PM  Today we are releasing a new tabbed experience for Azure Functions that lets you quickly navigate between multiple features when you are configuring your application.  This new experience was developed as part of the Azure Functions UX open source project with input from Azure Functions MVP community. As part of the efforts to be more customer driven we also opened this feature up in preview through @azurefunctions  Provide feedback on a new #AzureFunctions portal feature! Survey has link to both UI options. https://t.co/oCUBaanQxK pic.twitter.com/YyVSQbId3c — Azure Functions (@AzureFunctions) July 17, 2017  This feature is currently enabled for Function app settings, and API definition feature. We will be adding more items to this experience in the coming months. Features that will open in a tab have a small decorator to indicate they will open in this tabbed experience.  If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.For any feature requests or ideas check out our User Voice       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/08/08/New-tabbed-experience-for-Azure-Functions-UX.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions Tools released for Visual Studio 2017 Update 3",
        "excerpt":"      Donna Malayeri     8/14/2017 11:00:16 AM  We're excited to announce that Azure Functions tools for Visual Studio are out of preview! The tools are now included in the Azure workload of Visual Studio 2017 Update 3. Just update your existing VS 2017 installation to Update 3--there's no need to use the preview channel or manually install the Functions tooling extension.  The tools support building and publishing a class library as the implementation of your functions. Configure bindings and triggers using attributes in your code, rather than a separate metadata file.  To get started with the tools, check out these articles:  Create your first function using Visual Studio Azure Functions Tools for Visual Studio Using .NET class libraries with Azure Functions  Azure Functions Core Tools  Along with this release is the 1.0 version of the Azure Functions Core Tools. These are used by the Visual Studio tools when you run or debug a Function App locally. You can also use the Core Tools directly to retrieve app settings from Azure or publish your Function App. To learn more, see Run locally using the Azure Functions Core Tools.   What's new in this release  If you've used the preview tooling, you've probably seen the package Microsoft.NET.Sdk.Functions. This package is automatically added by the New Function project template and ensures that generated files are always in sync with your code.  In this release, only triggers are generated in function.json. There is a new property in function.json that tells the runtime to use .NET attributes for input and output bindings, rather than function.json configuration:  [sourcecode language=\"plain\"] \"configurationSource\": \"attributes\" // possible values are \"attributes\" or \"config\" [/sourcecode]  If the value of configurationSource is attributes, then the contents of function.json cannot be changed after it is generated. That is because the Functions runtime uses attributes in the assembly to configure bindings and triggers. (If you’re wondering why some properties are still in function.json, it’s because the Scale Controller uses it to make scaling decisions on the Consumption plan.) Functions project type  The Functions project type is a .NET Standard class library though it currently targets net461. This is because the Azure Functions runtime does not yet take a dependency on the .NET Standard 2.0 facades that enable full framework support. Now that .NET Standard 2.0 is RTM, we will make this update in a future release. See Support .NET Standard 2.0 class libraries #1792.  Once we have completed the Azure Functions port to .NET Core 2.0, the .NET Standard 2.0 target will become much more important. At that time, we will change the default in the Visual Studio New Project dialog. Learn more  We’ve seen a great response to our preview tooling and we’re excited to release this version.  For more product news, follow @AzureFunctions. To report bugs or file feature requests, please open an issue on the Azure-Functions GitHub repo. Please include “Visual Studio” in the issue title. For technical questions, please post on the MSDN forums or StackOverflow. The entire Functions engineering team monitors these questions, so you’re sure to get an expert answer.        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/08/14/Azure-Functions-Tools-released-for-Visual-Studio-2017-Update-3.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Introducing Proactive Auto Heal",
        "excerpt":"      Jennifer Lee (MSFT)     8/17/2017 1:24:29 PM  Many of you may be familiar with the Auto Heal feature which allows you to configure limits on your Web App for request count, slow requests, Http status codes, and memory usage. Many times when you are experiencing problems with your Web App that can include slow responses or a non-responsive site, a simple restart of the Web App can solve the problem.  As a result, we are introducing Proactive Auto Heal to expand on the Auto Heal offering. Proactive Auto Heal will only take corrective actions for the sites that we have deemed to be in a bad state for which the best way to recover is to simply restart the Web App. In many situations, your site may go into a bad state, so we are taking this preventative action on your behalf so that ideally your customers will not experience any downtime.  Let’s say you are running your site on multiple instances and one of your instances has a memory leak and is consuming most of the memory on that instance.  This could result in high latencies or unresponsiveness. If you have another Web App running in the same server farm (sharing memory and CPU), the Web App that is hogging those underlying resources may cause problems for other Web Apps running on that instance. With Proactive Auto Heal, the Web App that is taking up a lot of memory for example, would be restarted. If you have multiple instances, only the one in the bad state would be restarted.  It will be automatically enabled for every site, but this will not affect Auto Heal rules that you have already set yourself, as those will take priority. How does Proactive Auto Heal know when to restart my Web App?  Curious about how this feature works behind the scenes? Proactive Auto Heal looks for Web Apps that breaks either of these rules:  Percent Memory Rule: This rule monitors the Web App’s process' private bytes to see if it exceeds 90% of the limit for over 30 seconds. The limit is determined from the amount of memory available for the process as outlined in the chart below. For example, for a 64 bit process on a Medium worker, it would be recycled if the private bytes went above 3.5GB * 90% = 3.15 GB for over 30 seconds.     Instance Size Small Small Medium Medium Large Large   Process Bitness 32 64 32 64 32 64    1.75GB 1.75GB 3.5GB 3.5GB 4GB 7GB     Percent Request Rule: This rule monitors requests that have taken longer than the time limit. It is broken when 80% (or more) of total number of requests have taken 200+ seconds. The rule only triggers when there have been at least 5 requests in a rolling time window of 120 seconds during which the rule is broken. To account for slow application starts (which can be mitigated with our Application Initialization Feature with Slots!), this rule is not active during the process warm up time.  If either of the rules are broken, then the Web App will undergo a overlapped restart of the process. This is NOT an instance restart or an entire Web App restart. In the case when there are multi-instances, the rules are ONLY triggered for the particular instance on which the process breached the rule, leaving the rest of the instances unaffected.  Additionally, to prevent too many restarts (due to the application itself or service related bugs), both rules will be auto-disabled for 3 hours if there are too many restarts detected in a small time window. Opting Out  Because we believe that most customers can benefit from Proactive Auto Heal, we have automatically enabled it by default, so you don’t have to worry about turning this on yourself or early wake up calls perform a manual restart of the process. However, we understand that some of you may be saying, “I don’t want you restarting my Web App!”. For example, this could be because you keep a lot of data in memory and do not want to unknowingly lose this data, which would happen when the process restarts. Here’s how you can opt out:  Go to portal.azure.com and go to your Web App for which you would like to disable the feature. Under Settings go to Application Settings. Under App Settings add “WEBSITE_PROACTIVE_AUTOHEAL_ENABLED” and set it to “False.” That’s it! Proactive Auto Heal is disabled.    If you later decide you would like to enable it again then you can either remove this App Setting or set it to “True”.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/08/17/Introducing-Proactive-Auto-Heal.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Web App on Linux &lt;3 Azure Container Registry",
        "excerpt":"      Ahmed Elnably     8/23/2017 2:26:23 PM  With our latest UX deployment we introduced a new user experience to easily choose Docker images that are stored in an Azure Container Registry (ACR) repo. Moreover we offer you a single click continuous deployment experience using webhooks with the Preview SKUs of ACR.       For more information please check our intro doc at https://aka.ms/webapp-linux, for more information about continuous deployment for containers check the following article https://docs.microsoft.com/en-us/azure/app-service-web/app-service-linux-ci-cd        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/08/23/Web-App-on-Linux-&lt;3-Azure-Container-Registry.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "How-to  For WordPress on App Service (WindowsLinux )",
        "excerpt":"      mksunitha     9/12/2017 3:36:04 PM  With both App Service for Windows and Linux  today , setting up  and configuration of your WordPress app is different in some way based on whether you are using Linux vs Windows . The matrix below can help guide your the appropriate documentation and steps for your WordPress app        Web App on Windows  Web App on Linux (Built-in) Web App for Containers   Overview Web App on Windows Web App on Linux (Built-in) Web App for Containers   How do I create New WordPress app Use the Azure Marketplace Template for WordPress  This template also creates a database for your Web App based on your database provider choice Use Web App on Linux with Built-in PHP runtime   You need to create a database if creating the app using this method.  Read this article to know whether to use built-in or custom docker image Use the Azure Marketplace Template for WordPress on Linux  This template also creates a database for your Web App based on your database provider choice.   How do I modify PHP configuration Add a  .user.ini to site/wwwroot folder and update PHP configuration . Use .htaccess to update PHP configuration if using PHP built-in image or custom image with Apache server Use .htaccess to update PHP configuration if using PHP built-in image or custom image with Apache server  If you are using your own docker image , make the appropriate changes based on your server for example ngnix   How do I debug WordPress WordPress has debugging Capability . For more information , click here   How do I add a domain to WordPress app STEP 1 : Buy a custom domain from Azure and configure your web app Or  use an existing domain to configure your web app.  STEP 2 : WordPress needs additional changes to resolve to the new domain  Login to Wordpress dashboard Click Settings, and then click General. In the WordPress address (URL) and Site address (URL) fields, enter the new domain name or URL you want to use, and then click Save Changes. Now browse your site with the new domain If you are using permalinks and its not resolving with new domain you might need to reset your WordPress site's permalinks. To do this  From the Settings menu, click Permalinks. Note which kind of Permalink you currently use. Select any Permalink setting other than the one you currently use, and then click Save Changes. Select your original Permalink setting, and then click Save Changes.       How to add SSL certificate binding for my domain Bind an existing custom SSL certificate to Azure Web Apps Buy and Configure an SSL Certificate for your Azure App Service   How do I connect WordPress app with a database using SSL For more information click this  link   How do I migrate my database to Azure database for MySQL (Preview) For more information , click this link   Which database provider should I use with WordPress Click this link to help choose the appropriate database provider   How do I migrate existing WordPress app   Identify your app dependencies to understand whether Windows or Linux built-in or Web app for Containers is the right choice Create a Empty Web App on Azure  Choose Windows OS for Windows App Service Choose Linux if you are using built-in PHP . OR You can bring your own custom image  using Web App for Containers   Create a database for your app based on the database provider you have selected Migrate your database , for more information click this link Copy all your files to  Azure web app using FTP or Git Update wp-config.php to point to the desired database for the azure web app If your wp-config.php files has any hard-coded paths please remove them or update them to use  /home/site/wwwroot (Linux) D:\\home\\site\\wwwroot ( Windows)   WordPress stored the URL of your web app in the database. Make sure you update the database to use your-site-name.azurewebsites.net or configure the appropriate domain to your app     Continuous Integration (CI)/Continuous Deployment(CD) For more information , click this link . Here the continuous integration refers to only you application code. For more information , click this link. This depends on how you image is built :  If your image has your application code included , then CI/CD refers to updates to your docker image If your image has only server components like apache , php etc and application code is on VSTS/Github ; then there are two deployments that need to configured for CI/CD : one for your application code and one for your docker image. Refer to this article     Troubleshooting Platform Issues For more information , click this link For more information click this link. Checkout the FAQ as well.   Scaling Application For more information click this link For more information click this link For more information click this link Note: When using Web App for containers you must use the App Settings WEBSITES_ENABLE_APP_SERVICE_STORAGE = true in order to use App Service storage which will allows file changes to persists and be shared by all the instances   Performance Enhancements   WP Super cache :It significantly improves site throughput and correctly handles comments submissions and other visitors’ actions. Azure Redis cache : Azure redis cache can also be integrated with WordPress with the help of WP redis plugin to get better performance. Static content Caching : Cache JS, CSS files Server level caching :  For Windows App Service , you can use IIS output caching, click here.  For App Service on Linux , use caching on Apache . Click here For Web App for Containers , you can include different types of caching within your custom image from local redis to APC or additional caching based on the server you use ( Nginx, Apache etc )            ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/09/12/How-to-For-WordPress-on-App-Service-(WindowsLinux-).html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "August 2017 App Service update",
        "excerpt":"      Byron Tardif     9/13/2017 11:08:56 AM  App Service on Linux and Web App for Containers  On Sept 06 we announce the GA for App Service on Linux and Web App for Containers. This includes new UI integration with Azure Container Registry as well as enabling container based CI/CD deployments.   Azure Functions UX improvements  Browse Azure Function UI now includes the ability to filter and group Function apps as well as the ability to refresh the list:  We also have a new native App Settings experience that leverages the new Azure Functions tabbed experience New File System Storage UX  The new view for file system quota provides more granular information on how this quota is calculated and per app file system usage breakdown. This UI is available for both App and App Service plans and can be found in the menu under Quotas or File system storage respectively.   IP Restrictions  IP Restrictions lets you define an allow list of IP Address that are granted access to your app. You can find this new feature in the menu under Networking&gt;IP Restrictions  Azure Bot Service  Azure Bot Service now provides the option to choose an App Service plan for a bot in Azure Bot Service.       If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/09/13/August-2017-App-Service-update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Function Proxies adds Mock APIs to the Portal",
        "excerpt":"      Alex Karcher     9/14/2017 8:20:46 AM  I’m very happy to announce mock API and HTTP request/response overrides in the Azure functions portal. This feature allows a function proxy to return sample data through a mock API, enabling development against a functions API endpoint without writing any code. Request/response overrides allows API data to be transformed in flight, enabling new API schemas to be supported without modifying a backend API.  This functionality mirrors the existing request/response overrides and mocks previously only accessible through proxies.json  Examples  The following example shows a mock API that mimics the \"hello serverless\" example. The example returns a static response while also inserting text from a request parameter.    The next example performs a transform on requests as they're sent to jsonplaceholder.typicode.com. It changes all HTTP verbs to HTTP GET, and appends the request's verb to the response header.   Learn more  We’ve seen a great response to the proxies preview and we're excited to continue releasing updates  For more product news, follow @AzureFunctions. To report bugs or file feature requests, please open an issue on the Azure-Functions GitHub repo. Please include “Proxies” in the issue title. For technical questions, please post on the MSDN forums or StackOverflow. The entire Functions engineering team monitors these questions, so you’re sure to get an expert answer.      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/09/14/Function-Proxies-adds-Mock-APIs-to-the-Portal.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Processing 100,000 Events Per Second on Azure Functions",
        "excerpt":"      Paul Batum     9/19/2017 7:07:33 PM  Customers often ask us about the scalability/throughput limits of the consumption plan for Azure Functions. The short answer is always \"it depends, what does your workload look like?\". Today I want to talk about running high scale Event Hub / IOT Hub workloads on Functions and some key points to be aware of in order to maximize the performance you get from the platform.  We partnered with the Azure CAT team to build a simple but representative event processing pipeline using Functions and Event Hubs, with telemetry going into Application Insights:    The load generator (also running on Functions) writes batched messages to an ingestion event hub. These messages represent a set of readings from a given sensor. Functions picks up messages from the ingestion event hub, extracts individual readings from the batch and writes them to the target event hub, augmenting the messages with additional telemetry along the way. Two more functions within the same function app (on the consumption plan) each process the individual readings and send aggregated telemetry to App Insights. Performance  We ran the system under a target load of 100,000 events per second for a total of 9 days. Over that time the system processed a total of 76 billion events. We measured the e2e latency of the pipeline i.e. amount of time taken between writing the message to the ingestion hub and processing the message in the weather/seismic function. Here are the results: E2E Latency Percentiles       P50    P90    P95    P99    P99.9    P99.99    Max      1,102.42ms    2,755.56ms    3,788.30ms    11,894.12ms    50,367.23ms    111,240.50ms    239,890.10ms       In simple terms:  half of the messages were processed within 1.2 seconds of being written to the ingestion hub nine out of ten messages were processed in under 3 seconds 999 out of 1000 messages were processed in under 1 minute all messages were processed in under 5 minutes  Monitoring  Azure Functions has two built in monitoring solutions - the WebJobs dashboard and Application Insights (integration between Azure Functions and App Insights is currently in preview). The dashboard was designed with longer running jobs in mind and isn't optimized for scenarios where there are 10,000+ function executions happening per second. Fortunately, App Insights is an incredibly robust telemetry system and we've made sure that it works great with Azure Functions in high scale scenarios.  Turning on App insights is really easy - just add your instrumentation key to your function app and Azure Functions will start sending data to App Insights automatically. For more info see here.  The Azure dashboard is highly customizable and App Insights has great support for pinning its visual components. It only took an hour or two to put together a pretty useful monitoring dashboard for this scenario:   Configuration  We made some notable configuration choices to achieve this result:  the functions process messages in batches the WebJobs dashboard is disabled in favor of using Application Insights for monitoring and telemetry each event hub is configured with 100 partitions data is sent to the event hubs without partition keys events are serialized using protocol buffers  See below for additional details on each of these. Batching  An event hub triggered function can be written to process single messages or batches of messages. The latter has much better performance characteristics. Lets take the splitter function as an example:         public static async Task Run(   EventData[] sensorEvent,   PartitionContext partitionContext,   IAsyncCollector&lt;EventData&gt; outputWeatherData,   IAsyncCollector&lt;EventData&gt; outputSeismicData,   TraceWriter log)   {     foreach (var sensorData in sensorEvent)     {       SensorType sensorType = SensorType.Unknown;        try       {                            if (sensorData.Properties.ContainsKey(\"SensorType\"))         {           System.Enum.TryParse(sensorData.Properties[\"SensorType\"].ToString(), out sensorType);         }          await ProcessEvent(sensorData, sensorType, partitionContext, outputWeatherData, outputSeismicData);       }       catch(Exception ex)       {         telemetryHelper.PostException(ex, sensorData, partitionContext.Lease.PartitionId, sensorType.ToString());       }     }                                      }  The main things to note about this code:  An array of events are passed to the function in one execution An exception handling block wraps the processing of each event  The array based approach performs better primarily due to per function execution overhead. The system performs a number of actions when invoking your function and those actions will only happen once for an array of events rather than once per event. Note: for JavaScript functions you'll need to explicitly set the cardinality property in your function.json to many in order to enable batching (e.g. see here).  This approach to exception handling is important if you want to ensure you don't lose/skip messages. Typically you'll write your exception handler so that it stores the event that failed for later processing/analysis. This is important because Azure Functions does not have any built in dead lettering for Event Hubs. WebJobs Dashboard  As mentioned above, because we were using App Insights for monitoring we disabled the dashboard. To do this simply go to your application setting and remove the AzureWebJobsDashboard setting. Partition Configuration  Azure Functions uses the EventProcessorHost (for more info see here) provided in the Event Hubs SDK to process event hub messages. The way EventProcessorHost works is that each VM running your app acquires leases to some of the partitions, allowing it to process messages on those partitions. This means that if your event hub has only two partitions, only two VMs can process messages at any given time i.e. the partition count puts an upper limit on the scalability of your function.  The basic and standard tiers for Event Hubs have a default limit of 32 partitions per event hub, but this limit can be increased if you contact billing support. By setting the event hubs to have 100 partitions, each function was able to run on 100 VMs simultaneously. We can see this if we look at one minute of telemetry, counting the number of unique VMs that executed the weather function:    We can get an idea of how evenly the work was distributed over those 94 VMs with another simple query:    Partition Keys  The event hubs programming guide has a good summary of partition keys and when you might want to use them. This scenario had no ordering or statefulness requirements so events were generated without partition keys. This increased the overall throughput and availability for the run. Protocol Buffers  If you're writing and reading 100,000+ events a second, you want the serialization and deserialization of those events to be as efficient as possible, both from the perspective of time taken to do the serialization step and also size on the wire. Protocol Buffers is a high performance serialization format that is easy to work with. Here's some example code deserializing and processing a batch of weather readings from an event: if (sensorType == SensorType.Weather) {   var batch = WeatherReadingBatch.Parser.ParseFrom(sensorData.GetBytes());   var messages = batch.SensorReadings     .Select(reading =&gt; EnrichData(enqueuedTime, reading));   await WriteOutput(messages, sensorData.PartitionKey, outputWeatherData); } If you'd like to see the .proto file used for this scenario see here. Cost  The total cost of running the function app and its dependencies for the 9 day run was approximately $1200 USD. Here's what the cost per hour looks like for each service:      Service    Cost per Hour (USD)      Functions    $2.71      Storage    $1.80      Application Insights    $1.03       A few important points to note:  This data does not include the cost of the load generator and Event Hubs as no effort was spent on optimizing these. The Azure Storage cost is based on approximately 50 million transactions per hour. Almost all of these transactions are related to Event Hubs checkpointing. The Application Insights cost is based on 450mb of data ingestion per hour.  We can dive into function app cost in more detail by using the execution count and execution units data available via the Azure Monitor REST API (see here for more info). Querying for one hour of data, we get the following:  Function Execution Count: 6,500,012 Function Execution Units: 90,305,037,184  Note that the function execution units here are measured in mb-milliseconds. To convert these into gb-seconds, divide by 1024000. Putting it altogether (pricing details for functions are here, simple program I wrote to assist is here):  Cost per hour = (6,500,012 executions * ( $0.20 / 1,000,000 )) + ((90,305,037,184 units / (1024 * 1000)) * $0.000016) = $2.71 USD Summary  The consumption plan for Azure Functions is capable of scaling your app to run on hundreds of VMs, enabling high performance scenarios without having to reserve and pay for huge amounts of compute capacity up front. To learn more about Azure Functions and building cloud applications on serverless technology, start here.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/09/19/Processing-100,000-Events-Per-Second-on-Azure-Functions.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Develop Azure Functions on any platform",
        "excerpt":"      Donna Malayeri     9/25/2017 6:00:20 AM  I’m excited to announce that we have ported Azure Functions to .NET Core 2.0! Both the runtime and the Azure Functions Core Tools are now cross-platform. Now, you can debug C# and JavaScript functions on a Mac or Linux using the Core Tools and Visual Studio Code. Both the runtime and the Core Tools are still in preview and we welcome your feedback!  As this is a preview release, there are still a number of feature gaps. For more information, see Azure Functions runtime 2.0 known issues. Running on your local machine  To get the new version of the core tools, pull down the @core tag on npm: npm i -g azure-functions-core-tools@core If you’re using Ubuntu, prefix the command above with \"sudo.\"  If you have problems with the npm install on Mac, use the following: sudo npm i -g azure-functions-core-tools@core --unsafe-perm To learn how to use the tools, see Code and test Azure functions locally. JavaScript (Node 8.5 or higher)  For the easiest installation, you must be running Node version 8.5 or higher. See instructions below for how to target a lower version.  To create a new JavaScript HTTP-triggered function, do the following: mkdir JavaScriptHttp cd JavaScriptHttp func init . func new --language JavaScript --template HttpTrigger --name HttpTriggerJavaScript Run the host. This automatically enables debugging with the Node port 5858: func host start   Open the folder in Visual Studio Code: code .  In VSCode, set a breakpoint at the first line of the function, and attach the debugger (via F5 or the debug toolbar). Then, in a browser, navigate to the URL http://localhost:7071/api/HttpTriggerJavaScript?name=Functions%20Everywhere!  You’ll then see the breakpoint being hit in VSCode!    JavaScript (Node versions prior to 8)  After installing azure-functions-core-tools, run the following commands: npm i -g node-pre-gyp cd %userprofile%/.azurefunctions/bin/workers/node/grpc node-pre-gyp install  Once these tools are installed, you can use the instructions in the previous section to run and debug JavaScript functions. C# .NET Standard 2.0 class library  You can now run and debug C# functions on a Mac or Linux. The Microsoft.NET.Sdk.Functions  is the package that identifies a project as Functions project to Visual Studio and generates function.json from attributes during build. Templates for C# class libraries aren’t yet available in the Core Tools, but you can get a sample from GitHub. Dotnet command line  git clone https://github.com/lindydonna/CSharpHttpCore.git cd CSharpHttpCore dotnet build dotnet publish cd HttpTriggerCore/bin/Debug/netstandard2.0 func host start    VS Code debugging  To debug your C# functions, open the folder containing your .csproj in VS Code. Make sure you have installed the C# extension.  In the debug toolbar next to the play button, select Add Configuration Select .NET Core as the environment, then .NET: Attach to local .NET Core Console App.  This will generate a launch.json configuration for your project. Then, press F5 and select .NET Core Attach. Select the dotnet process with the command line Azure.Functions.Cli.dll host start.  Browse to the URL http://localhost:7071/api/HttpTriggerCSharp?name=CSharpEverywhere!. You’ll then see your breakpoint hit in VSCode.   Visual Studio  First, ensure you have downloaded the @core version of azure-functions-core-tools: npm i -g azure-functions-core-tools@core  Then, add a new launch configuration for the 2.0 version of the Core Tools:  In project properties -&gt; Debug, change Launch to Executable For Executable, use %APPDATA%\\npm\\func.cmd For Application Arguments, use host start For working directory, use $(TargetDir)  F5 will now launch the new version of the Azure Functions Core Tools.   Running Functions 2.0 in Azure  You can also use the .NET Core 2.0 port in Azure by targeting the new Functions 2.0 preview runtime. To use it, select \"beta\" in Function app settings -&gt; Runtime version. Alternatively, you can the app setting FUNCTIONS_EXTENSION_VERSION to the value beta. You will then see a different set of templates available in the Add New Function page.    Since the 2.0 runtime is in preview, there may be breaking changes even in minor releases. So, the 2.0 runtime should not be used for production workloads.  If you navigate to the root of you function app, you’ll see that you’re running the new version:   Connect with us  We've seen a lot of excitement and interest, so we're looking forward to getting your feedback as we finalize the Functions 2.0 runtime.  To report bugs or file feature requests, please open an issue on the Azure-Functions GitHub repo. For technical questions, please post on the MSDN forums or StackOverflow. The entire Functions engineering team monitors these questions, so you’re sure to get an expert answer. For product news, follow @AzureFunctions.      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/09/25/Develop-Azure-Functions-on-any-platform.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "My Intern Project Microsoft Graph Bindings for Azure Functions",
        "excerpt":"      Chris Gillum (MSFT)     9/25/2017 3:42:46 PM  The following is a blog post written by one of our many amazing summer interns, Glenna. I had the pleasure of mentoring Glenna this past summer as she worked on a very exciting internship project: The Microsoft Graph bindings for Azure Functions, which was recently announced at Microsoft Ignite 2017. Glenna worked tirelessly on this project and was responsible for large parts of the implementation as well as presenting the project to her peers and local executives (and she did an excellent job at both). Unfortunately she had to head back to school before we could publish this post, but now that it's been productized and announced we are finally free to unleash it. :) Thank you Glenna for your awesome contributions to our team and to our customers. We can't wait to have you come back and join us full-time after your graduation! As an aside, it's very important to us on the Azure App Service team that our interns get to work on projects that are fun, challenging, have a legitimate business impact, and actually ship to production. The Microsoft Graph bindings and associated Azure Functions portal work is just one example among many others, and we're really excited to be able to finally showcase it. Here is Glenna in her own words (with a few edits from the team based on some changes that were made after she returned to school). Consider the content of this post as supplementary to our official documentation. Personal Introduction    My name is Glenna and I am a software engineering intern on the Azure Functions team in Redmond, WA. As I write this, I am finishing up my last day on my twelfth and final week at Microsoft. My internship was a truly incredible experience. I learned a great deal not just about specific programming languages, but also about good engineering design practices. I got to work on both the nuts and bolts of my features as well as the Azure Functions Portal UX and UI.  I attend the University of Virginia in Charlottesville, Virginia. In May of 2018, I will graduate with a Bachelor of Science in Computer Science. Introduction  Microsoft Graph bindings extend the existing Microsoft Graph SDK and WebJobs framework to allow users easy access to Microsoft Graph data (emails, OneDrive files, events, etc.) from Azure Functions.  By using the Office input, output, and trigger bindings, users can bind to user-defined types, primitives, or directly to Microsoft Graph SDK objects like WorkbookTables and Messages. These bindings handle Azure AD authentication, Azure AD token exchange, and token refresh, allowing users to focus on writing code that utilizes Microsoft Graph data. Features  Currently, the bindings can be grouped into four main categories: Excel, Outlook, OneDrive, and Webhooks. Excel [Input + Output]  The Excel binding allows users to read/write Excel workbooks and tables using different data types, like lists of user-defined types or 2D string arrays. Outlook [Output]  The Outlook binding is an output only binding, and allows users to send emails from their Office 365 email accounts. OneDrive [Input + Output]  The OneDrive binding allows users to read/write files stored in their OneDrive using several different data types (e.g. DriveItems and Streams). Graph Webhooks [Trigger + Input + Output]  There are two bindings associated with Graph webhooks: GraphWebhookTrigger and GraphWebhookSubscription. GraphWebhookSubscription [Input + Output]  The GraphWebhookSubscription input binding allows the retrieval of Microsoft Graph webhook subscriptions that the function app has created. The GraphWebhookSubscription output binding handles webhook subscription creation, as well as renewal and deletion. Without renewal, most Microsoft Graph webhooks expire in 3 days. Deleting a webhook subscription removes the subscription from the Microsoft Graph account, as well as all references to that subscription in your Function app. Both the refresh and delete output bindings are best used in conjunction with the input binding, as they operate on current webhook subscription ids. GraphWebhookTrigger [Trigger]  The GraphWebhookTrigger binding allows users to subscribe to notifications about supported Microsoft Graph resources, including email messages, OneDrive root, contacts, and events.  If you examine the wire protocol, the notification payload from Microsoft Graph is very lightweight; it only contains a webhook subscription ID and the subscribed resource. In order to provide detailed information to the function code, the webhook trigger internally uses a local store of webhook subscription data (stored by the GraphWebhookSubscription binding at subscription creation), maps the webhook subscription ID to a user, performs a silent GET request for the specified resource and transforms that payload into either a JSON object or a Microsoft Graph SDK type (e.g. Message, Contact) which can then be accessed directly by the function code. Identity  Actions mentioned can be performed using the current Office 365 user's identity, or using the Azure AD service principal identity of the function app. Which identity is used is up to the Function author. In order to authenticate against the Microsoft Graph as a specific user, either an ID token or an Azure AD Principal ID must be given to the binding. This identifier can come from a number of different sources. Examples of these sources include the currently authenticated Azure AD user (which can be captured from a session cookie or a bearer token), the content of an HTTP request, a queue, or an app setting. Examples  An easily imagined scenario for these bindings is a business owner with customers who subscribe to their monthly newsletter. Customers provide their names and email addresses, which then must be added to an Excel file of customers.  Using the Excel output binding, the business owner can select which Excel table to modify.   [caption id=\"attachment_5996\" align=\"alignnone\" width=\"997\"] Excel output binding[/caption]  The function code to append the Excel row is only a few lines long. In this example, the function receives a POST request with a user's name and email address and converts it into a custom EmailRow (POCO) type using the runtime's dynamic binding capabilities to remove the need for JSON manipulation.  using System.Net;  public static async Task Run(     HttpRequestMessage req,     IAsyncCollector&lt;EmailRow&gt; outputTable) {     // Get request body     dynamic data = await req.Content.ReadAsAsync&lt;object&gt;();      // Use body data to set row data     var output = new EmailRow {         Name = data?.name,         Email = data?.email     };     await outputTable.AddAsync(output); }  public class EmailRow {     public string Name {get; set;}     public string Email {get; set;} }  Every month, a timer trigger (or some other trigger type) fires and an email, the contents of which are determined by a OneDrive file, is sent out to each customer.  The business owner can select the same Customers Excel file (Excel input binding)...  [caption id=\"attachment_5995\" align=\"alignnone\" width=\"984\"] Excel input binding[/caption]  ...determine which OneDrive file to get the email contents from (OneDrive input binding)...  [caption id=\"attachment_6015\" align=\"alignnone\" width=\"978\"] OneDrive input binding[/caption]  ...and indicate that they would like to send emails via the Outlook output binding.   [caption id=\"attachment_6026\" align=\"alignnone\" width=\"993\"] Outlook mail output binding[/caption]  The code below quickly scans the Excel table and sends out one email per row (customer).  #r \"Microsoft.Graph\"  using System; using Microsoft.Graph;  // Send one email per customer public static void Run(TimerInfo myTimer, TraceWriter log,      List&lt;EmailRow&gt; inputTable, string file, ICollector&lt;Message&gt; emails) {     // Iterate over the rows of customers     foreach(var row in inputTable) {         var email = new Message {             Subject = \"Monthly newsletter\",             Body = new ItemBody {                 Content = file, //contents of email determined by OneDrive file                 ContentType = BodyType.Html             },             ToRecipients = new Recipient[] {                 new Recipient {                     EmailAddress = new EmailAddress {                         Address = row.Email,                         Name = row.Name                     }                 }             }         };         emails.Add(email);     } }  public class EmailRow {     public string Name { get; set; }     public string Email { get; set; } }  The aforementioned goals can be accomplished using just a few lines of code. No manual data entry, no hardwiring, and no additional services.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/09/25/My-Intern-Project-Microsoft-Graph-Bindings-for-Azure-Functions.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Introducing the New App Service Support Center (Preview)",
        "excerpt":"      Jennifer Lee (MSFT)     9/28/2017 7:00:55 AM  “What’s wrong with my Web App? My Web App is down!”     These are tough questions that we know are frustrating for you. It is our priority to make sure that we figure out how to keep your Web App healthy with minimal downtime. However, in the cases where things do go wrong, the problem is that there could be many reasons why. How do you know which of these generic potential issues could be the reason why your Web App is down?   Where do you start your troubleshooting process for your specific Web App?  Many of you may be familiar with the Diagnose and Solve Support Center, our self-serve diagnostic experience that allows you to get a glimpse of how your Web App is performing. Since releasing that experience, we’ve been able to add and improve the detectors that we use to analyze the health of your Web App to perform more precise pattern analyses in an effort to pinpoint Web App errors and provide troubleshooting advice.  As a result, today we are excited to announce the release of our new Diagnose and Solve Support Center (Preview) to help point out what’s wrong with your Web App and guide you to the right information to troubleshoot and ideally resolve the issue easier and quicker than before. Getting Started with the New App Service Support Center  To open the new App Service Support Center, click on “Diagnose and Solve problems” on the left-hand menu. Once in the new App Service Support Center homepage, there are several options. First, you should ask yourself this question: Do you already know what’s wrong with your Web App?    (Note: in this blog post, images will be expanded when clicked). Performing a Health Checkup (Highly Recommended)  If you’re not sure what’s wrong with your Web App, run our new Health Checkup feature by selecting the blue “Yes” button. Health Checkup will analyze your Web App to give you a quick, interactive overview that points out what’s healthy and what’s wrong, telling you where to look to investigate the issue.  Once the Health Checkup report is generated, you can get a quick overview of the status of four different problem categories: Requests and Errors, Performance, CPU Usage, Memory Usage.  [video width=\"1912\" height=\"1092\" mp4=\"media/2017/09/2017-09-29_11h03_03-online-video-cutter.com_.mp4\" poster=\"media/2017/09/App-Service-Genie-Blog-Post-2.png\" loop=\"true\" autoplay=\"true\"][/video]  Highlights:  Quick Overview: red, orange, and green icons appear on the left side of each problem category to indicate the healthiness of that area. You can click on each tab to open up a graph showing more details. View Full Report: this opens up more observations about the issue and suggested solutions as seen in the image below. You can investigate further by selecting the orange bars corresponding with periods of unhealthiness and expanding on observations by clicking \"View Details\" below. Suggested solutions would show up below the observations.   Selecting Tile Shortcuts  If you already know what’s wrong with your Web App, you can investigate further by selecting the tile shortcut that corresponds to the problem category that you’re interested in. Currently, we have five problem scenarios for our tile shortcuts. (Note: Web App Restarted is the only scenario not covered by Health Checkup at the moment):  Web App Down Web App Slow High CPU Usage High Memory Usage Web App Restarted  Let’s say you want to figure out why your Web App restarted. In the homepage, select the “Web App Restarted” tile. This will open a new tab with our Web App Restarted analysis.   One-Stop Shop for Additional Resources  Now, on the right-hand column, we have compiled a list of help links to give you all easy access to variety of different resources with content that can help you troubleshoot your Web App. Just select the + sign next to each title to expand that selection.    Here is a quick overview of the different Additional Resources categories:  Support Tools: additional troubleshooting tools Premium Tools: more additional troubleshooting tools FAQs: links to App Service articles that guide you through common troubleshooting scenarios Resource Center: links to how-to articles and video walkthroughs for those needing a quick-start for App Service Community: links to forums and other locations where you can get help from members of the App Service team and other community members Recent Updates: convenient links to updates to Microsoft Azure services as well as stack specific updates Contribute: link to our Github repository to assemble feedback for Support Center and allow for open source contributions  We need your feedback!  In the coming months, we are planning on adding additional features with a goal that Support Center can guide you step-by-step for a holistic Web App troubleshooting experience. This means that the feedback that you leave is critical for us to determine which features are most relevant for you.  Once Health Checkup is complete, you can leave your feedback in the inline textbox as seen below.    Note: currently, this experience is only for App Service on Windows. Stay tuned!     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/09/28/Introducing-the-New-App-Service-Support-Center-(Preview).html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "September 2017 App Service Update",
        "excerpt":"      Byron Tardif     10/9/2017 2:23:30 PM  Support for Azure Managed Service Identity (MSI)  Managed Service Identity (MSI) let you assign your azure resources an automatically managed identity that can be used to access other Azure and Azure Active Directory managed resources without ever exposing credentials in code. Learn how to leverage MSI with App Service and Azure Functions.      Performance improvements for Azure Functions UX  We have shipped a few behind the scenes improvement to the Azure Functions UX that improves performance up to 40% in some instances. This should result in snappier navigation and more responsive interactions.    If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/10/09/September-2017-App-Service-Update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Durable Functions and Bindings Extensibility Preview Announcement",
        "excerpt":"      Chris Anderson (Azure)     10/10/2017 7:01:45 AM  We’re excited to announce two new preview features in Azure Functions:  Durable Functions: A framework that makes it easy to orchestrate multiple functions and manage state for your serverless apps. Binding extensibility: A capability that allows you to create your own reusable serverless components that can be used from any supported language.  Durable Functions  In serverless functions, as with many application frameworks, it’s commonly recommended to write your code to be stateless, and this is the best practice. What is often not discussed in detail, though, is how one should manage that state. For trivial scenarios like just standard user data, databases are an obvious option, or for messaging between applications, a queue service is sufficient. However, what if your application has need for a more complex, stateful orchestration of multiple components? Without better tools, you’re left to figure out the right way to combine those pieces. This is the problem that the Durable Functions feature seeks to solve; letting developers abstract away the management of state for complex, stateful orchestration. Today, we’re happy to announce that Durable Functions is now in preview.  Durable Functions builds on the Durable Task Framework, which was designed to allow developers to write code based orchestrations using async/await pattern in C#. This enabled the following:  Expression of tasks in simple C# code Automatic persistence and check-pointing of program state Versioning of orchestrations and activities Async timers, orchestration composition  With Durable Functions, we let you write orchestrators and activities as Functions. Orchestrators can call Activity Functions, other sub-orchestrations, and wait for an external event. Combined, this functionality allows a lot of complex patterns to be expressed via code. For instance, the code below will fan out and call various Activity Functions, wait for them all to complete, and then allow you to sum the results (fan in). This pattern was possible before but involved a lot more setup and management code that was unrelated to the business logic.  #r \"Microsoft.Azure.WebJobs.Extensions.DurableTask\"  public static async Task&lt;long&gt; Run(DurableOrchestrationContext backupContext) {     string rootDirectory = backupContext.GetInput&lt;string&gt;();     if (string.IsNullOrEmpty(rootDirectory))     {         rootDirectory = Environment.CurrentDirectory;     }      string[] files = await backupContext.CallFunctionAsync&lt;string[]&gt;(         \"E2_GetFileList\",         rootDirectory);      var tasks = new Task&lt;long&gt;[files.Length];     for (int i = 0; i &lt; files.Length; i++)     {             tasks[i] = backupContext.CallFunctionAsync&lt;long&gt;(             \"E2_CopyFileToBlob\",             files[i]);     }      await Task.WhenAll(tasks);      long totalBytes = tasks.Sum(t =&gt; t.Result);     return totalBytes; }  In the above code, you can see the first set of bold code fanning out and calling many Functions, and then the later bold line waiting for them all to complete. What’s happened since alpha?  Since we initially released the alpha preview we’ve seen lots of great community interest and folks experimenting with Durable Functions. In addition to all that feedback, we’ve also been working on a few important enhancements. You can see all the work highlighted on the GitHub repo for Durable Functions extension. Here are some highlights:  Elastic scaling support for consumption plan Cross platform support by porting to netcore2.0 Better traces and integration with Application Insights Retry support for Activities Improved error handling with timers Portal support and templates Moved to have support only on 2.x version of Azure Functions runtime  Roadmap  In the coming months, we’ll be working towards a GA of the current functionality and investigate the following enhancements:  Support for other languages Improved monitoring and management of orchestrations Improve the underlying messaging/data layer to improve the maximum throughput Dynamic repartitioning of orchestrations  Binding extensibility: goodbye SDKs, hello bindings  Developers are building increasingly complex serverless applications and need better mechanisms for code reuse. Triggers and bindings allow developers to focus on their code and let Azure Functions handle all the logistics of connecting to other services, in a way “reusing” the glue code that we have already written for you. We are now providing a mechanism using which you can author your own custom bindings for Azure Functions, providing more avenues for reuse.  This mechanism (binding extensibility) is a feature of the 2.0 Functions runtime. In fact, Durable Functions is authored as a custom binding for Azure Functions.  Bindings allow you to create reusable serverless components that can be used from any supported language. If you host a developer service, bindings will make it easy for Functions developers to use your product. Developers can also create reusable packages and host them in a central repository, just like a library or SDK.  Binding extensibility allows you to provide a declarative interface for an SDK. For instance, we have a sample Slack output binding that sends a slack message when a customer uses a [Slack] attribute (or the equivalent in function.json):  C# using System.Net; using System.Net.Http; using Microsoft.Azure.WebJobs; using Microsoft.Azure.WebJobs.Host; using SampleExtension;  namespace SampleFunctionApp {     public static class HttpTriggerSlack     {         [FunctionName(\"HttpTriggerSlack\")]         public static string Run(             [HttpTrigger] SlackMessage message,              [Slack(WebHookUrl = \"SlackWebHook\")] out SlackMessage slackMessage,             TraceWriter log)         {             slackMessage = message;              return \"Ok\";         }     } }  JavaScript module.exports = function (context, req) {     context.log('JS HTTP function processed a request: ' + req.body.text);      context.bindings.slackMessage = req.body;     context.done(); };  Creating a custom binding  Currently, extensions can only be authored in C# but can be consumed from any supported language. To get started, please check out the sample WebJobsExtensionSamples, which has a detailed readme on how to get started. There is also a Slack output binding sample.  Reference documentation is available on our wiki: Creating custom input and output bindings. Custom triggers  For custom triggers, we plan to offer integration with Azure Event Grid. Stay tuned for more details on this. Next steps  Please try out Durable Functions and binding extensibility and provide feedback on the experience. We encourage you to try these features in all kinds of interesting ways and help us make them work even better when we GA. As always, we look forward to hearing from you through our Forums, StackOverFlow, or Uservoice.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/10/10/Durable-Functions-and-Bindings-Extensibility-Preview-Announcement.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Retirement of the PHP 5.5 runtime from App Service",
        "excerpt":"      Jennifer Lee (MSFT)     10/11/2017 7:58:58 AM  Strongly Recommended to Upgrade to PHP 5.6, 7.0, or 7.1  Because the PHP Group stated that PHP 5.5 is no longer supported, there won’t be any more updates to that version, including security fixes. To avoid the potential for security issues on App Service, we plan to retire our support of PHP 5.5 in January 2018. Currently, we support PHP 5.6, 7.0 and 7.1. This retirement will impact all customers who are running their Web App on the PHP 5.5 runtime (unless you are using a custom PHP runtime). We strongly recommend that you upgrade to a supported version of PHP because your Web App will be auto-moved to PHP 5.6. For more information on how to migrate from PHP 5.5 to another version of PHP, please review the documentation on the Appendices webpage on PHP.net.   Although we’re removing the PHP 5.5 runtime from the platform, we’re aware that some applications are complex and may be tied to a specific PHP runtime version. In order to continue to support your PHP 5.5 applications, it’s possible to remain on PHP 5.5 runtime. For more information, please visit the \"How to: Use a custom PHP runtime\" section of the  Configure PHP in Azure App Service Web Apps documentation webpage.         ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/10/11/Retirement-of-the-PHP-5.5-runtime-from-App-Service.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Zip Push Deployment for Web Apps, Functions and WebJobs",
        "excerpt":"      Nick Walker     10/16/2017 10:20:11 AM    With our most recent release of Kudu, we have introduced a new deployment option for web apps, Azure Functions and WebJobs: zip push deployment. Zipdeploy combines the simplicity of Kudu’s zip API with the flexibility and robustness of Kudu’s deployment features, like deletion of unused files from old deployments, history tracking and Auto Swap support. Why a new API?  Since App Service and Kudu were first introduced, the deployment needs of developers have evolved.  Availability and adoption of mature continuous integration and delivery (CI/CD) tools and services like VSTS have grown significantly. Developers are increasingly looking to deploy tested, ready-to-run apps from these services instead of from source code. The ability of many app stacks to enable rapid iteration has improved. Many contemporary developer workflows require the ability to quickly deploy directly from a development environment. The introduction of Azure Functions has further driven the popularity of rapid-iteration workflows. The nature of Functions encourages developers to repeatedly prototype and deploy small packages of functionality.  Kudu features a variety of mechanisms for deploying code to App Service that make use of its underlying deployment platform, which provides for safe, tracked deployments. But despite its relative lack of features, feedback has indicated that many developers favor using Kudu’s zip API for deployments, especially in the above scenarios. For many workflows, the pure simplicity and cross-platform availability of the push-based zip API and of zip files themselves wins out over the features of other available deployment mechanisms:  Git deployment restricts your site contents to files that are in the repository and requires a commit to deploy. Triggering deployments with pushes to hosted providers like GitHub requires some setup before getting started. Git deployment also engages Kudu's CI build system by default, which detects your app's runtime stack and generates scripts to do things like restore packages or compile code. This is undesirable when deploying an app that's already been built by your CI/CD service or deploying a working app from your local environment. Web Deploy (aka msdeploy) is extremely powerful but challenging to configure. It's not supported on App Service on Linux and can't be used from non-Windows clients. FTP requires tools that many developers don't have handy or aren't familiar with. Many of them require scripting to achieve the desired result.  Zips are simple and ubiquitous, but without a connection to Kudu's deployment features, the zip API is only fit for general-purpose file transfers and is not robust enough for deployments. Deploying via the zip API can leave old files lying around that can break your application or Function unless you completely erase the existing files first. It doesn't create any deployment history, and there is no first-class way of verifying that deployment operations performed via the zip API are 100% successful.  Why not combine the ease of pushing a zip file up to your site with Kudu's comprehensive deployment features? Enter zipdeploy! Usage  Create a zip file containing the files you want deployed to wwwroot and POST it as binary data to /api/zipdeploy on your site’s Kudu instance.  Here’s how to do it with curl: curl -X POST -u &lt;publishing-user&gt; --data-binary @&lt;zipfile&gt; https://{sitename}.scm.azurewebsites.net/api/zipdeploy Be aware that this operation may delete files currently in your site depending on the contents of your deployment! See Features below for more information.  Add ?isAsync=true to the URL to perform an async deployment. A response will be returned as soon as the file is uploaded, and the deployment will continue on the server. The response will include a Location header with a URL that can be queried for realtime deployment status.  By default, Kudu assumes that zip deployments do not require any build-related actions like npm install or dotnet publish. This can be overridden by setting the SCM_DO_BUILD_DURING_DEPLOYMENT deployment setting to true to enable Kudu’s detection logic and build script generation process.  As with all web app deployments, modifying the files of a running app is a potentially dangerous operation that exposes your app to clients in a partially-deployed state. Apps that need atomic, zero-downtime deployments, smoke testing and/or rollback support should always use a staging environment and a slot swap as part of deployment. Features   Flexibility: Push-based zip deployment eliminates the need to host your build output on the web or create a git commit. Zip deployments do not require any setup in Kudu or the Azure portal and can be run at any time with nothing but an HTTP client, regardless of whether your application is already synced with a source control provider. Deletion of files left over from the previous deployment: Deployments use the KuduSync utility to track and delete files and directories that were created by a previous deployment if they’re not included in the new deployment. Any other files and directories found in the site that aren't being overwritten by the deployment will be preserved, such as files deployed via FTP, created in the Functions portal or created by your app during runtime. Function trigger sync: If you are running Functions on a Consumption plan, modifying their triggers requires a synchronization process that doesn't occur with file-based deployment methods like FTP or the zip API. Zipdeploy will perform this synchronization for you. Efficient file copy: KuduSync will only overwrite an existing file if its last-modified timestamp doesn’t match what’s in the deployment. You can speed up your deployments by using a build process that preserves timestamps on files that do not change across builds. Logging, status tracking and history: Zipdeploy generates live status, deployment logs and recorded history in Kudu's deployment API. However, zip deployments cannot be redeployed. Async support: By adding ?isAsync=true to the URL, a response will be returned as soon as the zip has been uploaded to the site. Deployment will continue asynchronously on the server. The Location header of the response will contain the deployment URL that can be polled for deployment status. Webhooks can be used for fully asynchronous notification of completion. Customization: Deployment-related settings will be respected, including those in app settings as well as configuration placed in a .deployment file located in the root of the zip. Build script support: By default, zipdeploy assumes that the zip contains a ready-to-run app. Kudu's continuous integration build process can be enabled via the SCM_DO_BUILD_DURING_DEPLOYMENT deployment setting, or by providing a custom build command with the COMMAND setting. Safe deployment: Zipdeploy engages Kudu's deployment locks, preventing multiple simultaneous deployments from clobbering your site. Auto Swap and container restart support: A zip deployment will trigger an Auto Swap if your site is configured for it. On App Service on Linux, zip deployment will trigger a restart of the app container.  Feedback  Please give zipdeploy a try and let us know what you think, especially if you're currently using the zip API for deployments. We’d love to hear your feedback – we’ll be watching the Issues tab on Kudu’s GitHub page, as well as the MSDN forums, Stack Overflow and Uservoice.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/10/16/Zip-Push-Deployment-for-Web-Apps,-Functions-and-WebJobs.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Configure App Service Certificate to Azure Virtual machines",
        "excerpt":"      mksunitha     10/26/2017 2:34:38 PM  App Service Certificate can be used for other Azure service and not just App Service Web App. This tutorial shows you how to secure your web app by purchasing an SSL certificate using App Service Certificates ,  securely storing it in Azure Key Vault  , domain verification and configuring it your virtual machine . Before your begin log in to the Azure portal at https://portal.azure.com  Step 1 : Create an Azure Virtual machine with IIS web server  Create an Azure virtual machine with IIS from Azure marketplace or with Azure CLI  . Step 2 : Add a Custom domain to your virtual machine  Purchase a new domain and assign it your Azure virtual machine. For more details , click here . Step 3 : Place an SSL Certificate order  You can place an SSL Certificate order by creating a new App Service Certificate In the Azure portal. Enter a friendly Name for your SSL certificate and enter the Domain Name in Step 1 . DO NOT append the Host name with WWW.   Step 4 - Store the certificate in Azure Key Vault   Key Vault is an Azure service that helps safeguard cryptographic keys and secrets used by cloud applications and services. Once the SSL Certificate purchase is complete, you need to open the App Service Certificates page.  The current status of the certificate  is “Pending Issuance” . Complete the steps below to have an active certificate ready to use.   Click Certificate Configuration inside the Certificate Properties page and Click on Step 1: Store to store this certificate in Azure Key Vault.       From the Key Vault Status page, click Key Vault Repository to choose an existing Key Vault to store this certificate OR Create New Key Vault to create new Key Vault inside same subscription and resource group.  Note :  Azure Key Vault has minimal charges for storing this certificate. For more information, see Azure Key Vault Pricing Details.   Once you have selected the Key Vault Repository to store this certificate in, the Store option should show success.      Step 5 : Verify the domain ownership  From the same Certificate Configuration page you used in Step 3, click Step 2: Verify. Choose the preferred domain verification method.  There are four types of domain verification supported by App Service Certificates: App Service, Domain, Mail, and Manual Verification. These verification types are explained in more details in the Advanced section.  Step 6 : Assign certificate to Virtual machine  Before performing the steps in this section dedicated for Virtual machine , you must have :   associated a custom domain name with your app on the virtual machine. For more information, see Configuring a custom domain name for a web app. Make sure Key Vault has appropriate permissions to be used with Virtual machine . For more information , see Using MSI with Key Vault on Virtual machine  Here are the instructions to assign the certificate to the virtual machine  An issued App Service certificate may be used on any App Service Web App. Follow the steps below to assign the certificate to an App Service App.     Get the Key Vault information for your SSL certificate resource under certificate configuration.  Prepare and Configure the virtual machine to add the Certificate.     An App Service Certificate can be used on multiple Azure Virtual Machines.Learn more    References   Internals of App Service Certificates Get started with Azure Key Vault     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/10/26/Configure-App-Service-Certificate-to-Azure-Virtual-machines.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service Certificates now supports public certificates (.cer)",
        "excerpt":"      mksunitha     11/1/2017 3:11:17 PM  App Service certificates now enables you to upload  public certificate . Previously you had to use Azure resource manage template to upload a public certificate or use ARM client to do the same as described in this article. Today , we have made this experience more user friendly  to allows user to install their public certificates in the personal certificate store.  You can easily add a public Certificate for your App service web app using the Azure Portal. Follow the steps below to upload a public certificate :   Login to the Azure portal and select your web app Click on  SSL Certificates setting -&gt; Upload Certificate. Select Public and upload your public certificate . The .CER file contains information about the certificate ownership and public key.    If you are using an App Service Environment you will be given the option to store either in Current User or Local Machine Store .  Once upload you can see your public certificate installed on your app as shown below   Note SSL certificates is supported only on dedicated App Service Plans and App Service Environments. Things to remember   If your App Service is hosted on a public scale unit then you can only install certificates in CurrentUser Personal Store certificate. If your web app is hosted on an App Service Environments, CurrentUser or LocalMachine-Personal certificate store is only supported.  When using Deployment slots with your application  , keep in mind that the certificates are not sticky and will also get swapped  when you perform a slot swap operation.  Either user your application code to check for multiple public certificates or make sure the correct certificate is upload for slot as well before you swap a slot with production app.      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/11/01/App-Service-Certificates-now-supports-public-certificates-(.cer).html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "October 2017 App Service Update",
        "excerpt":"      Byron Tardif     11/2/2017 2:17:51 PM  Performance  This month we focused on fundamentals including performance improvements for the overview blade. This resulted in slicing the load time for the menu and overview blade to roughly half of what it was before the improvements. Function + Logic apps  Functions and Logic apps work great together and are often developed side by side. We’ve made it easier to move from Functions to Logic apps by including it in the platform features for functions. This will open an new tab where you can quickly switch between resources.   Supports public key certificates (.cer)  Support for public key certificates was one of our most requested user voice features. Public key certificates let you use self-signed certificates for test/development scenarios amongst other things. You can read more about App Service support for Public Key Certificates here:    If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/11/02/October-2017-App-Service-Update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Running a popular Content management solution on Web App for Containers",
        "excerpt":"      mksunitha     11/6/2017 1:34:21 PM  There are multiple options to hosting your Content management solutions (CMS) like WordPress , Drupal , Magento etc. with Linux App Service . The blog post below will cover the key decisions and implementation guidelines when using Web App for Containers for a CMS solution like WordPress or Drupal.  Built images :  App Service team provides your bare bone docker images for PHP , and other frameworks. These images are very basic and help you quickly get started but as your apps grows , these images may be limited to your needs as you are limited from making any changes to these images .  Custom images :  Custom docker images provides you with more flexibility to grow as your apps grows. You have more control on the docker image itself and can modify it with new modules or extensions if and when your app needs these changes . This option make lift and shift of your application more easy since you can replicate you current dependencies as close as possible in the cloud. Checkout an example of using a Python Application with a Custom image.  The recommended approach is using custom images with Web App for Containers when using a CMS solution. File Storage  App Service come with a shared file storage . You must use this storage if :   The application writes to the file system frequently and needs these files to be persisted. You want to use auto-scaling features and you want all the instances to share the same file storage  In order to use the App Service Storage , explicitly include an app setting  WEBSITES_ENABLE_APP_SERVICE_STORAGE = true To better understand this , let me elaborate with an example :  If you have a WordPress app , note that WordPress CMS installs minor version updates to make sure your app has any important fixes needed. This means new files being added or existing files being modified to your application. In such cases , the application needs the files to persist so that you have the latest patches/fixes for WordPress hence this scenario requires the use of App Service Storage .  Most CMS solutions have a variation of this type of application updates . Have a better understating of your application to decide if you want to use App Service storage.  Can I use local storage instead of App Service Storage for CMS solutions  By using the local storage rather than App Service Storage  you do get better stability and there is less impact if the app service storage has  issues.  To use local storage  , set the app setting  WEBSITES_ENABLE_APP_SERVICE_STORAGE = false Lets use WordPress as an example here again. You can use local storage for WordPress app , but this requires a few changes in your code and how the application is used. Here are a few things you would need to do :   Turn off auto update for WordPress Manually deploy the latest WordPress code updates with your docker image Do not install plugins , themes etc. from production site’s WordPress administration dashboard  For other CMS solutions like Drupal , Joomla etc ; you need to understand if there are options on turn on auto-update . The steps #2 and #3 mentioned above will still apply to any other application. This is a key decision to make before taking the next step.  Deployment  There are many deployment options available for your custom images:    Continuous Delivery with VSTS Continuous Deployment with Azure Container Registry (ACR) or Docker Hub  Choose a deployment option  There are two common terms with deployment as seen above  :   Continuous Deployment : Every change made to your docker image  is pushed out to production automatically. Continuous Delivery:  Provides you with a deployment release pipeline. This solution does not mean your code is pushed to production automatically . The goal here is to build  a process that can allow code to be deployed any time . Most Continuous Delivery processes include automated tests and criteria that needs to be met before the changes go to production.  Based on your needs  , pick either Continuous Delivery which we provide using VSTS  or Continuous Deployment with ACR/DockerHub.  Can I deploy my code via GIT  You can have your application source code as part of the docker image or you can have the application code on a git based repository and your docker image on ACR or Docker Hub .  Continuous Delivery with VSTS supports both these scenarios.  If you are not using Continuous Delivery with VSTS ,  the other option you have is Continuous Deployment feature  that support GitHub, Bitbucket, Local GIT etc.  Note :You must use App Service Storage for your files if your application code is separate from your docker image and you choose to deploy the source code separately than the docker image. If your application code is large , there may be some issues with Git deployment for such apps. In those cases use Zip deploy API   Planning  Migration or setting up a new site  The question listed below should help you make the key decisions before implementing a migration of an existing site or setting up a new site:  Should I use a built in image or customer image ? Review your dependencies or requirements to answer this question Should I use App Service Storage or Local Storage ? Does the app need file persistence ? Do I need to run the app on multiple instances with auto-scale or Can I run the app on single instance ?  When running in single instance , you can include local mysql , local redis etc without having to use a cloud service for MySQL and Redis . Note to use Local mysql you need file persistence What deployment strategy works best for  this application ?  Keep in mind to choose an option that helps make deployment even after the site is in production. This will provide a stable , repeatable deployment process. What external dependencies are needed  ? Do I need a cloud based service for my database , twitter/Facebook API etc .  Migration  Migration of an application from On-premise or other cloud solution providers can be challenging tasks.  Here is migration process that is articulated for Web App for Containers.  Identify your application dependencies on premise or local development machine . Such as , webserver , php version , php extensions , web server modules etc . If you are using apache server with say php , you can build a custom image with apache server  , php etc to run on Web app for containers. If you are using nginx  in your current architecture , you can build a custom image with nginx for web app for containers. Identify external dependencies like Database , Redis cache , CDN etc. Find appropriate solutions for these external dependencies in Azure For CMS solutions always build a Custom docker image based on the dependencies you identified from the above step. You can find many samples here  to help get started . Enable SSH in your docker image which can help as a tool to debug your app. Create a Web App For Container from Azure portal Create your external dependencies with the appropriate solutions available in Azure . For example , if your app needs MySQL you can use Azure database for MySQL  for better reliability and performance Make the decision to use Local storage or App Service Storage. To use App Service Storage , edit the app setting  WEBSITES_ENABLE_APP_SERVICE_STORAGE = true Select a deployment option for your application : Continuous Delivery or Continuous Deployment or Git Deployment. Deploy your code to the application and make sure the application code is updated appropriately to use the new dependencies for database , cdn etc in Azure Browse your application once deployed Turn on Diagnostic logs to view your docker logs to investigate any issues if you don’t get the expected results. Troubleshoot your application further using SSH . Tweak your Docker image as needed to resolve any issues . Reiterate the process from step 7 .  If you are still unable to resolve any issues for a given step or have questions , reach out via support forums to get help.  Setting up  CMS solution on Web App for Containers  In the steps below ,  using Drupal CMS as an example  for the CMS solution to be setup and configured on Web App for Containers :   ü  Create a Web App using Web App for Containers using Nginx-fpm and Drush CLI tool  or your own custom Drupal Image. This image does not have Drupal source code as part of the image. Note : When using your custom docker image , make sure it is available in either Docker Hub or Azure Container registry as a private or public repository .  Make sure you application has SSH enabled which can help in troubleshooting.  ü  Use App Service Storage since Drupal requires files to persist when you do install a module or update Drupal modules or Drupal core . Go to your app , select Application Settings -&gt; App Settings.  Now set  WEBSITES_ENABLE_APP_SERVICE_STORAGE =true   ü  Design and then implement your deployment strategy for your application .   ü  Create a MySQL or PostgreSQL database depending on what database driver your application is using with  Azure database for MySQL .  o   If you are migrating an existing application from on-premise or other cloud service provider , import your database content in the database.                                                  ü  Browse your application   ü  If the application does not load as expected , turn on diagnostic logs.   ü  Fix the docker image based on your investigation and update your Docker image.  If you are planning to migrate a WordPress or Joomla or Moodle  CMS solution , the process is exactly the same except for the custom image you plan to use . Here are some samples you can use :  Custom image with Alpine-PHP-MySQL  Custom image with Apache-PHP-MySQL  Performance  There are multiple bake some caching into your docker image , such as using PHP 's caching options such as :  Server level caching based on which web server you are using leverage any modules or configuration that can help boost performance. Framework level caching such as PHP supports various options for caching  APC   if using Apache (or APCu if using Nginx ) Opcache    Using Compression , for example including mod_deflate apache module helps with boosting performance on your application running on Apache web server by reducing the bandwidth on the file and reduces load on the server . This differs based on your web server Enable back-end database caching using Azure Redis Cache service. If you are not using auto-scale feature with web app for containers , you can run a local redis baked into your docker image. Note this will only work if your app is running on one instance Add a CDN  to boost performance of your app.  Other Configurations  Here are a few other configurations you can add to you application  Add a Custom domain Bind an SSL certificate       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/11/06/Running-a-popular-Content-management-solution-on-Web-App-for-Containers.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions Proxies is now Generally Available",
        "excerpt":"      Alex Karcher     11/15/2017 12:30:22 AM  Functions Proxies is an API toolkit built into Functions to enable you to build APIs faster! Proxies makes it easy to perform simple API operations, like nesting multiple Functions together under one API, as well as API fundamentals, like mock APIs, OpenAPI definitions, and monitoring.  Since preview we’ve gotten a lot of awesome feedback and responded with some new functionality to make Proxies even better. We’re now releasing Proxies under General Availability today, November 15th.  Check out what’s new in Proxies at Connect()  New Portal Experience for Proxies  Request and response overrides can now be set in the portal Modify input request to send different HTTP verbs, headers, or query parameters to a backend service Replace backend response status code, headers, and body  Mock API support in Proxies   Using the new editor, you can create mock APIs. You do this by using only response overrides and no backend URL. Mock APIs allow you to create a simple API at your real REST endpoint, allowing developers to start testing API integrations while the API is still under development.  Functions Core Tools (CLI) Support for Proxies  The Functions Core Tools are our set of CLI tools for locally developing Functions, and they now support authoring and running Proxies!  Get started with a new proxy using Function proxy create --name &lt;yourproxyname&gt; When prompted for a template, choosing SampleProxy will create a simple proxy to call httpbin.org/ip and returns your public IP address. Choosing RequestResponseOverride will create a simple mock API that returns  a sample body and header. Note that the template uses “localhost” to reference a local function. This will allow the same Proxy to work in the cloud, once the Function App has a different hostname.    Read more about developing locally in our docs. Application Insights Support               Proxies will now publish telemetry to Azure Application Insights when App Insights is enabled for your function App. This allows for real time analytics steaming, as well as rich historical analysis. With Proxies you can not only measure your serverless API, but also proxy a legacy API and leverage App Insights to measure that API. Read more about our Application Insights support in Functions in the docs.  OpenAPI Support  Proxy rules will now show up in OpenAPI definition templates generated in Functions! A completed OpenAPI definition allows you to import APIs defined in Proxies into a wide range of tools and services, like Logic Apps, Visual Studio solutions, Power Apps, Flow, and Azure API Management.  Read more about Functions OpenAPI support here in the docs.  On by Default  As a part of the GA release, Proxies will now be enabled by default on  all Function Apps! We have also baked in some performance improvements to Proxies.  Get Started Now!               We’re very excited to release Proxies to the world! We’ve already seen the community build awesome widgets for single page applications, serverless URL shorteners, and much more with Proxies, and we’re excited to see what you build next!   Get started at our docs at aka.ms/ProxiesDocs See a video of what’s new with Proxies at Connect() To report bugs, please open an issue on the Azure-FunctionsGitHub repo. Submit any feature requests on our UserVoice For technical questions, please post on the MSDN forums or StackOverflow. The entire Functions engineering team monitors these questions, so you’re sure to get an expert answer. For product news, follow @AzureFunctions For walkthroughs and live sessions, check out Azure Functions on Youtube        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/11/15/Azure-Functions-Proxies-is-now-Generally-Available.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions on IoT Edge",
        "excerpt":"      Colby Tresness     11/15/2017 12:30:42 AM  Running Azure Functions on IoT Edge  Today, we’re very excited to have released the public preview of Azure IoT Edge at our yearly developer conference, Connect();. This adds to the Azure IoT Suite the ability to write code which executes directly on IoT devices, allowing devices to react more quickly to events and spend less time sending messages to the cloud. The simplicity of Azure Functions fits extremely well as a programming model for these scenarios, and from day one users of IoT Edge will be able to write a Function to implement business logic right on their IoT devices. IoT devices are a great addition to the already robust list of places you can run a Function. When Would IoT Edge be Useful?  To best answer this question, let’s consider a simple example. Imagine you’re a factory administrator who oversees thousands of machines. With Azure IoT Hub, you can track the status of all your devices, send messages to those devices, receive messages from those devices, and more. Let’s assume you have a system in place receiving telemetry data about the temperature of your machines. To prevent damage due to overheating, you’re running a Function which is listening on all device to cloud messages (through the underlying EventHub.) The result of this is that you get a notification any time a device gets too hot, so you can mitigate and avoid disaster.  Since you have thousands of machines sending temperature readings constantly, this is getting expensive and is taking up all your bandwidth. Here’s where IoT Edge comes in – by running your business logic directly on the devices, you only have to send messages to the cloud when an anomaly is detected. So, you augment your current system by adding the IoT Edge Runtime to your devices, writing a Function module deciding whether a message is necessary, and deploying this module to all your devices. You now have the same end system without the massive amount of message passing, and you can sit back and relax knowing your machines will tell you if they are overheating. How do I Run Functions on a Device?  Azure IoT Edge is made up of three main components: IoT Edge modules, the IoT Edge runtime, and the cloud based interface. Modules are the units of execution that are pushed to your devices and run your custom code.  The runtime is deployed to each device and manages these modules, which are implemented as Docker containers.   Figure 1: IoT Edge Experience Illustrated  When a user writes a Function they’d like to run on the Edge, we package it up as one of these modules and deploy to your devices for you. We’ve released a Visual Studio Code extension  to help you with this – no advanced knowledge of containers is needed, even though it’s a container under the hood. Follow the more detailed instruction set here in order to set up an edge enabled device, write a sample function, get it up and running on said device, and monitor the results.   Looking Forward  The ability to write code which executes on IoT devices is an exciting addition for Azure users. For public preview, only C# Functions are supported, but we’re looking to add the ability to write Functions in more languages as we move towards GA. Also note that for public preview Functions won’t run on devices with ARM distributions of Linux.  Be sure to visit the more detailed IoT Edge preview documentation, and try running a Function on the Edge! Also, please feel free to engage either me or the overall Functions team on Twitter with any questions: @ColbyTresness  @AzureFunctions  Reference Code  The below code is an example of a Function reacting to IoT Edge events – parsing a message to find a machine’s temperature, checking if its over a threshold, and appending an alert if it is.   Code Sample 1: The Run Method of a Function Reacting to IoT Edge Events      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/11/15/Azure-Functions-on-IoT-Edge.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "The Azure Functions on Linux Preview",
        "excerpt":"      Daria Grigoriu     11/15/2017 12:30:20 AM  The new Azure Functions on Linux preview enables local Azure Functions development on Linux and Mac platforms to seamlessly translate to cloud hosting on Linux across a broader choice of hosting options. The Linux hosting model for Azure Functions is based on Docker containers which brings greater flexibility in terms of packaging and leveraging app specific dependencies. This is another stepping stone in the journey to run Azure Functions anywhere and to enable reuse of your Function App code assets.  Functions on Linux can be hosted in a dedicated App Service tier in 2 different modes:  You bring the Function App code and we provide and manage the container, no specific Docker related knowledge required. You bring your own Docker container including the Azure Functions runtime 2.0, specific dependencies, and Function App code.  Please note that charges for the dedicated App Service Plan you select will apply to the preview as published on the App Service pricing page.  With the Azure Functions on Linux preview you should be able to run any Azure Functions scenarios supported by the Azure Functions runtime 2.0. Notes for known Azure Functions runtime 2.0 limitations are available at this link. Support for the Azure Functions on Linux preview is available with the Azure Portal and the Azure CLI. This blog post will focus on the Azure CLI for creating Azure Functions resources. The following steps are required regardless of the hosting mode selected:  Install the latest version of the Azure CLI. Run az login to access your Azure account. Create Azure resources:  # Create a Resource Group az group create -n rg-name -l \"South Central US\"  # Create a Linux App Service Plan (use S2 or S3 as the sku value for larger VMs) az appservice plan create -n plan-name -g rg-name --is-linux -l \"South Central US\" --sku S1 --number-of-workers 1  # Create a storage account az storage account create -n storage-name --location \"South Central US\" --resource-group rg-name --sku Standard_LRS Host Function App content via an App Service managed container  To host Function App content via an App Service managed container first create a Linux Function App: # Create a Linux Function App az functionapp create -n fun-app-name -g rg-name -p plan-name -s storage-name You can manage the Function App in the Azure Portal and deploy Function App content using your preferred workflow. Read more about this hosting mode in our App Service managed container for Azure Functions documentation. Host a custom Azure Functions container  To create a Function App pointing to a specific container image use the example below (referencing the latest Azure Functions on Linux starter image): # Create a Linux Function App pointing to a specific container image az functionapp create -n fun-app-name -g rg-name -p plan-name -i microsoft/azure-functions-runtime:2.0.0-jessie -s storage-name You can manage the Function App in the Azure Portal. The Function App content however is not editable in the Azure Portal when using a custom container.  To create your own container image, you must install a few prerequisites:  Docker .NET Core 2.0 The latest azure-functions-core-tools: npm i -g azure-functions-core-tools@core  Please note that app specific configuration can be included in the Dockerfile or managed as App Settings for the Function App. Once the prerequisites are installed you can follow these steps:  Create a Function App directory locally. Generate a Dockerfile and optionally a sample function:  func init . --docker --sample func start  Build your container image and optionally test your Function App running in a container locally:  docker build -t my-functions. docker run -p 8080:80 my-functions  Publish your container image to an online registry such as Docker Hub:  docker login docker tag my-functions my-repo/my-functions docker push my-repo/my-functions Read more about this hosting mode in our custom Azure Functions containers documentation.  You can also run your Function App in a container on other container-based hosting platforms such as Azure Container Instances: az container create --name &lt;your name=\"\" container=\"\"&gt; --image &lt;your alias=\"\" hub=\"\" docker=\"\"&gt;/&lt;your name=\"\" image=\"\"&gt; --resource-group &lt;your name=\"\" group=\"\" resource=\"\"&gt; --ip-address public Known issues for this preview are listed on the Azure Functions wiki. To ask questions or share issues with the engineering team for the Azure Functions on Linux preview please use the Azure Functions MSDN forum.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/11/15/The-Azure-Functions-on-Linux-Preview.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP updated to latest versions",
        "excerpt":"      Eric Stenson (Microsoft)     12/1/2017 12:55:27 PM  PHP updated to latest versions  As of December 2017, Azure App Service has updated the PHP stacks to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.    PHP Version Change log   5.6.32 http://www.php.net/ChangeLog-5.php#5.6.32   7.0.25 http://www.php.net/ChangeLog-7.php#7.0.25   7.1.11 http://www.php.net/ChangeLog-7.php#7.1.11        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/12/01/PHP-updated-to-latest-versions.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing Azure Functions Runtime preview 2",
        "excerpt":"      Andrew Westgarth     12/5/2017 10:22:56 AM  Customers have embraced Azure Functions because it allows them to focus on application innovation rather than infrastructure management. The simplicity of the Functions programming model that underpins the service, has been key to enable this. This model that allows developers to build event-driven solutions and easily bind their code to other services while using their favorite developer tools, has good utility even outside the cloud.  [caption id=\"attachment_6595\" align=\"aligncenter\" width=\"800\"] Azure Functions Runtime preview 2 portal showing an Azure Function running against the V2 runtime.[/caption]  Today we are excited to announce the second preview of Azure Functions Runtime, building on the first preview and feedback from customers, which brings the simplicity and power of Azure Functions to on-premises. Azure Functions Runtime Recap  The Azure Functions Runtime provides a method for customers to take advantage of the Functions Programming model on-premises within their own organization or datacenter.  Offering a consistent development experience with the public cloud service, customers can use the Functions portal or Visual Studio to develop and publish Function Applications on-premises.  This also enables customers to experience Functions-as-a-Service before committing to the cloud and also enabling customers to easily translate their code assets to the cloud when they move.  Azure Functions Runtime consists of two pieces, the Management Role and the Worker Role.  As the names suggest, these two are for managing and executing functions code respectively. You can scale out your Functions by installing the Worker Role on multiple machines and take advantage of spare computing power.  ­What’s New?  This release brings further improvements and features to our on-premises audience:  Support for Azure Functions runtime 2.0, known limitations of the v2.0 runtime are available at this link. This enables you to write functions in C# (.NET Standard) or JavaScript Hosting of v2 Functions on Windows Nano containers, providing a streamlined, lightweight experience.  [caption id=\"attachment_6585\" align=\"aligncenter\" width=\"800\"] Create new function app in Azure Functions Runtime preview 2[/caption] Updates to v1 Functions including language support for C#, F#, JavaScript and PowerShell, which are still executed within Windows Server Core containers.  [caption id=\"attachment_6605\" align=\"aligncenter\" width=\"800\"] Templates available to v1 functions in Azure Functions Runtime preview 2[/caption] Updated Portal experience Support for multi-tenancy, enable multiple users to use the same infrastructure and portal to work on their own function apps in isolation Customers can specify their own custom DNS name for the Azure Functions Runtime portal and can work behind a load balancer The ability to run alongside additional versions of Docker for Windows already deployed Ability to reset installation to factory defaults  Requirements  The Azure Functions Runtime Worker Role is deployed in a Windows Container. As such it requires that the host machine is running Windows Server 2016 or Windows 10 Creators Update.  If deployed in a virtual machine, it must have nested virtualization support. Looking Forward  We are continuing to shape the direction of our on-premises offering of Azure Functions, based on customer feedback during preview.  We are interested in hearing your feedback and use cases as we move towards a GA Release.  We’re excited to see the types of applications you are building and the types of workloads you envisage running in Azure Functions Runtime.  Please feel free to engage with me via the comments or Twitter regarding your needs and feature requests for Azure Functions Runtime in on-premises scenarios.  @apwestgarth  How do I get started?  Please download the Azure Functions Runtime preview 2 installer.  For details, please see the Azure Functions Runtime documentation.  We would love to hear your feedback, questions, comments about this runtime through our regular channels including Forums, StackOverFlow, or Uservoice.        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/12/05/Announcing-Azure-Functions-Runtime-preview-2.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "November 2017 App Service Update",
        "excerpt":"      Byron Tardif     12/12/2017 12:20:36 PM    New create function experience  We have a brand new function creation experience that includes among other improvements the ability to search templates by keywords as well as filtering templates by language and scenario.   Functions on Linux App Service Plans  You can now select Linux App Service plans to host your Function apps. You can read more about this scenario here: The Azure Functions on Linux Preview    Support for HTTPS Only  This was one of the most requested features in our Uservoice forum and it is now available in production.  This feature can be found under Custom Domain in the left menu and works for apps hosted on Windows as well as Linux App Service Plans.  When this feature is enabled all traffic reaching an HTTP hostname in your app will be redirected to it’s HTTPS equivalent. Make sure all custom hostnames have a valid SSL binding to avoid browser validation errors.  This feature also includes the ability to add bindings to existing hostnames directly from this blade.     Quick Start refresh  We have updated the App Service Quickstart for Windows and Linux based apps, scenario cards now link to existing scenario documentation on https://docs.microsoft.com/azure/app-service/ where they are frequently updated and provide a lot more content and more advanced scenarios.    If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/12/12/November-2017-App-Service-Update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP Minor Version Update for January 2018",
        "excerpt":"      Jennifer Lee (MSFT)     12/14/2017 10:10:23 AM  Latest version updates to PHP  In January 2018, Azure App Service will update the PHP stacks to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.    PHP Version Change log   7.0.26 http://www.php.net/ChangeLog-7.php#7.0.26   7.1.12 http://www.php.net/ChangeLog-7.php#7.1.12        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2017/12/14/PHP-Minor-Version-Update-for-January-2018.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "My Backups are failing, Let's open a support ticket",
        "excerpt":"      Ahmed Elnably     1/2/2018 1:25:31 PM  Actually wait!  A big percentage of the backup failures (More than 42%) can be fixed in minutes, and more importantly without even opening a support ticket.  Step 1: Figure out what is the failure.  From the backup blade, click on the failing backup and check the Log Details  Step 2: Check the following table.    Error Fix   Storage access failed. {0} Delete backup schedule and reconfigure it   The website + database size exceeds the {0} GB limit for backups. Your content size is {1} GB. Use a backup.filter file to exclude some files from the backup, or remove the database portion of the backup and use externally offered backups instead https://aka.ms/partial-backup   Error occurred while connecting to the database {0} on server {1}: Authentication to host '{1}' for user '&lt;username&gt;' using method 'mysql_native_password' failed with message: Unknown database '&lt;db name&gt;' Update database connection string   Cannot resolve {0}. {1} (CannotResolveStorageAccount) Delete backup schedule and reconfigure it   Login failed for user '{0}'. Update database connection string   Create Database copy of {0} ({1}) threw an exception. Could not create Database copy Use admin user in connection string   The server principal \"&lt;name&gt;\" is not able to access the database \"master\" under the current security context. Cannot open database \"master\" requested by the login. The login failed. Login failed for user '&lt;name&gt;'. Use admin user in connection string   A network-related or instance-specific error occurred while establishing a connection to SQL Server. The server was not found or was not accessible. Verify that the instance name is correct and that SQL Server is configured to allow remote connections. (provider: Named Pipes Provider, error: 40 - Could not open a connection to SQL Server) Check that the connection string is valid, whitelist site’s outbound IPs in database server settings   Cannot open server \"&lt;name&gt;\" requested by the login. The login failed. Check that the connection string is valid   Missing mandatory parameters for valid Shared Access Signature Delete backup schedule and reconfigure it   SSL connection is required. Please specify SSL options and retry. when trying to connect Please use the built in backup feature in Azure MySQL or Azure Postgressql.     Step 3: The failure is not in the table   Well ... Please open a support ticket.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/01/02/My-Backups-are-failing,-Let's-open-a-support-ticket.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP Minor Version Update for February 2018",
        "excerpt":"      Jennifer Lee (MSFT)     1/8/2018 10:07:20 AM  Latest version updates to PHP  In February 2018, Azure App Service will update the PHP stacks to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.    PHP Version Change log   5.6.33 http://php.net/ChangeLog-5.php#5.6.33   7.0.27 http://www.php.net/ChangeLog-7.php#7.0.27   7.1.13 http://www.php.net/ChangeLog-7.php#7.1.13          ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/01/08/PHP-Minor-Version-Update-for-February-2018.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Change domain contact information for App Service Domain",
        "excerpt":"      mksunitha     1/10/2018 10:31:39 AM  If the registrant of the domain contact information has changed  and needs to be updated , follow the guidance below to make the necessary changes to make sure there is continuity of your use of the domain or any certificates associated with that domain.  Follow these steps to update the contact information of your domain:  Login to Azure portal  . Go to your domain within the Azure portal. Click on Advance management to go to advance management portal.  Select your domain that needs to be updated and Click on Manage  Click on view personal information if it is hidden .  Click on  Edit  to modify the contact information for the registrant of the domain.  Click on Save  to save the changes .  When the email of the contact information is updated , you will receive an approval request to the new email address updated in the contact information for the domain . Please complete this process to use the new email address with the domain.        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/01/10/Change-domain-contact-information-for-App-Service-Domain.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Demystifying the magic behind App Service OS updates",
        "excerpt":"      Oded Dvoskin     1/18/2018 12:10:09 PM  Well, that’s a loaded title for a blog post! But here’s the thing, we’ve been asked many times about what actually goes on behind the scenes when App Service updates the resources hosting App Service apps.  First, we need to mention briefly what is App Service . App Service is a PaaS (Platform as a Service) offering that allows customers to focus on their code, rather than having to worry about managing the underlying Virtual Machines and other resources with the latest security updates, OS patches and so on.  Still, those resources don’t get magically updated, do they? That is the beauty in a managed platform — we do that for our customers! App Service applies monthly updates to the resources, making sure our customers’ code is always running on the most recent security patches and OS versions available. As an example, this was extremely useful for our customers when the latest Spectre and Meltdown vulnerabilities were announced. Customers did not have to take any action because the service was updated automatically.  To give some additional technical details and demystify the process, we’ll outline here what happens when the App Service updates takes place , but first we’ll go through some key concepts:  App (or site) – the structure that manages the code that is deployed for users. Instance – The Virtual Machine hosting the code. It can be in variations of memory allocation, CPU etc. Upgrade Domain – Collections of VMs in a given Scale Unit that are taken offline at the time of an update. Scale unit / Stamp – The collection of Virtual Machines in a given region. Region (or datacenter) – An area in the world where there is a collection of Virtual Machines managed by Microsoft. As of writing this blog, Azure is deployed in 42 regions worldwide. Paired Regions – Two Azure regions which within the same geography which Azure guarantees not to update simultaneously.  App Service update cycle:  First and foremost, it’s important to note that App Service assures and maintains its SLA at all times, even during updates. In addition, we try to avoid updates during local business hours, unless there is a pressing security issue or a high priority item to mitigate.  Before beginning worldwide updates, we deploy first to a private region which is not commonly accessible. Only after testing is validated there, we begin to roll out to datacenters across the globe.  Our typical time for completing updates worldwide is about 10 business days, which allows us to deploy during each region’s off hours and also avoid deploying to Paired Regions at the same time (for example, East US and West US). When you are planning your app’s infrastructure for high availability and looking to deploy in multiple regions, it’s always a good idea to deploy to the paired region of your target region, since if there is a platform issue in the update, it won’t affect the paired region. After mitigating any issue, we will only then continue to the paired region, after the first is complete.  As a managed service, we always leave a buffer in our capacity for new resources, for scaling operations on existing resources, in case instances become unhealthy and force us to move apps to other instances and of course for our OS update process, detailed here.    When the update reaches a specific region, we update available instances without apps on them, then move the apps to the updated instances, then update the offloaded instances.    This move results in a cold start, and there may be a performance hit associated with this. Application binaries are loaded to the new Virtual Machine, and libraries are loaded from the disk. Externally the user will see a one-time delay in responses to requests to the app, after which the site will run normally. The delay is dependent on many things, mainly on the complexity of the app, the framework it’s built on, and dependencies. You can reduce the impact of cold starts on your application by properly configuring the App Initialization model, as detailed in this blog.  Thanks for reading and if you’d like to try App Service yourself, create your first app using one of our quickstarts and see how easily you can deploy your app and change your code right away.  If you have questions about App Service, please reach out to us through the developer forums, on MSDN or Stack Overflow.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/01/18/Demystifying-the-magic-behind-App-Service-OS-updates.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Exciting New Features in App Service Diagnostics",
        "excerpt":"      Jennifer Lee (MSFT)     1/18/2018 10:10:47 AM  Have you checked out App Service diagnostics yet? In November 2017, we announced the general availability of App Service diagnostics, our new self-service diagnostic and troubleshooting experiencing to help you resolve issues with your web app.  Since then, based on your feedback, we’ve enabled several exciting features in the past few months. TCP Connections    We added a new tile shortcut! The “TCP Connections” tile shortcut allows you to investigate:  Outbound TCP Connections: Graphed over time per instance Connection Rejections: Detects issues with port rejections Open Socket Handles: Open socket count when outbound TCP connections crosses 95% of the machine-wide TCP connection limit.   App Service Diagnostics for Linux  For all our App Service on Linux users, you can now also use App Service diagnostics to run a health checkup and use the tile shortcuts to analyze issues in performance and availability, such as “Web App Down,” Web App Slow,” and “Container Initialization.”   Integration with Application Insights  For .NET applications, we have added integration with Application Insights to help you look for relevant exceptions correlating to downtime occurring on your web app. These features are:  Application Insights Enabled: Easily check if you have Application Insights enabled (and if you don’t, you can enable it right there). Inside the “Web App Down” tile, if there are exceptions available, you will be able to see the exceptions thrown from Application Insights, sorted by count so you know which ones are most important.   Open App Service Diagnostics  To access App Service diagnostics, navigate to your App Service web app in the Azure portal. In the left navigation, click on Diagnose and solve problems.    To learn more, check out these links:  Connect() Video: Want to see a demo of App Service diagnostics? Check out this video to learn more about \"What's New with App Service\" (where I demo App Service diagnostics starting at 1:50). Azure Friday Video: One of our App Service diagnostics engineers, Steve Ernst, joins Scott Hanselman to diagnose and troubleshoot a real case of a web app having issues. Azure.com Blog Announcement Documentation        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/01/18/Exciting-New-Features-in-App-Service-Diagnostics.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "az webapp new - where new is always better!",
        "excerpt":"      Ahmed Elnably     2/6/2018 2:31:20 PM  This blog post has old info, the new version is here.  The App Service team have been hard at work creating a new experimental create and deploy experience for Azure App Service.  We released a new Azure CLI extension that adds a new command called new (have you seen what we did there!?).  The new command (Which is currently in Preview) enables the user to create and deploy their Node.js or .NET Core app using a single command. For Node.js we check for the existence of a package.json file in the code root path to indicate it is a Node.js app. For .NET Core we check for the existence of a *.csproj file with netcoreapp as the TargetFramework  [caption id=\"attachment_7095\" align=\"alignnone\" width=\"586\"] Click on the gif to see the command in action[/caption]  In the case of Node.js app the command does the following:  Create a new resource group (in Central US, you can use the --location to change the region) Create a new Linux single VM small App Service plan in the Standard SKU (in Central US) Create a Linux webapp Deploy the content of the current working directory to the webapp using Zip Deployment  In the case of .NET Core app the command does the following:  Create a new resource group (in Central US, you can use the --location to change the region) Create a new free Windows App Service plan (in Central US) Create a Windows webapp Deploy the content of the current working directory to the webapp using Zip Deployment  To Install the Azure CLI tools refer to their documentation.  To Install the extension: az extension add --name webapp To update the extension with the latest fixes and new languages support (Current version is 0.1.0): az extension update --name webapp To know what the command will do without creating anything: az webapp new --name [app name] --location [optional Azure region name] --dryrun [caption id=\"attachment_7115\" align=\"alignnone\" width=\"626\"] Click to see --dryrun in action[/caption]  To use the new command: az webapp new --name [app name] --location [optional Azure region name] To update your app content - Just rerun the command you used to create the app (including the --location argument): az webapp new --name [app name] --location [optional Azure region name] To submit feedback or submit an issue please open an issue in the Azure CLI extensions Github Project page.  Road Map - also tracked here:  Add better support to update the app with new changes Add more languages to the supported list Add support to Azure Functions        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/02/06/az-webapp-new-where-new-is-always-better!.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Understanding Serverless Cold Start",
        "excerpt":"      Colby Tresness     2/7/2018 6:00:42 AM  “Cold start” is a large discussion point for serverless architectures and is a point of ambiguity for many users of Azure Functions. The goal of this post is to help you understand what cold start is, why it happens, and how you can architect your solutions around it. To provide this explanation, we’ll be going deep into some technical details of how Azure Functions works behind the scenes. Consumption Plan vs. Dedicated Plan  Azure Functions comes in two main flavors – consumption and dedicated. The difference between the two is important – choosing one over the other not only dictates the behavior of your application, but also how you’re billed. The consumption plan is our “serverless” model – your code reacts to events, effectively scales out to meet whatever load you’re seeing, scales down when code isn’t running, and you’re billed only for what you use. Plus, all of this happens without you thinking about what Azure is doing behind the scenes. The dedicated plan, on the other hand, involves renting control of a Virtual Machine. This control means you can do whatever you like on that machine – it’s always available and might make more sense financially if you have a function which needs to run 24/7. If you’re curious and want a more detailed explanation, check out our documentation. What is Cold Start?  Broadly speaking, cold start is a term used to describe the phenomenon that applications which haven’t been used a while take longer to start up. In the context of Azure Functions, latency is the total time a user must wait for their function – from when an event happens to start up a function until that function completes responding to the event. So, more precisely, a cold start is an increase in latency for functions which haven’t been called recently. When using Azure Functions in the dedicated plan, the functions host is always running, which means that cold start isn’t really an issue. So, our scope is narrowed to functions running the serverless consumption model. Let’s go deeper. What Happens When I Write a Function?  Suppose you’re writing your first function. You’ve provisioned a function app, created your function based on one of our templates, and are modifying it to fit your business needs. You save, and now wait for your specified trigger to initiate your function. Later, your function triggers. When this process begins, since you haven’t yet executed anything, all your code and config exist only as files in Azure Storage. Let’s pause and think through broadly what still needs to happen for your code to run:  Azure must allocate your application to a server with capacity The Functions runtime must then start up on that server Your code then needs to execute  Steps 1 and 2, if done unintelligently, can take a while - spinning up and configuring a server takes time. To make this experience better for users, instead of starting from scratch every time, we’ve implemented a way to keep a pool of servers warm and draw workers from that pool. What this means is that at any point in time there are idle workers that have been preconfigured with the Functions runtime up and running. Making these “pre-warmed sites” happen has given us measurable  improvements on our cold start times – things are now on the order of 3-4 times faster. Now, let’s go back and walk through a more detailed view of what happens when you trigger the execution of a function when resources haven’t yet been allocated. What Happens During a Cold Start    Azure allocates a preconfigured server from the pool of warm workers to your app. This server already has the Functions runtime running on it, but it is unspecialized. This worker becomes specialized by configuring the Functions runtime in ways that are specific to your app. A few things happen to do this specialization, including:  The Azure Functions infrastructure mounts your Azure Files content to the worker you’ve been assigned App settings specific to your function app are applied to the worker   The Functions runtime resets, and any required extensions are loaded onto the worker. To figure out which extensions to load, the runtime reads the function.json files of any function in the function app. For instance, this happens if you’re using Durable Functions, or if you have input or output bindings. The functions themselves are loaded into memory by language providers. This will take a varying amount of time based on the size of your application. Your code runs.  If you’ve executed your function recently, #1-4 have already happened – the resources are already allocated, and your site is “warm.” As you can imagine, in this scenario things are considerably faster. We deallocate resources after roughly 20 minutes of inactivity, after which your next call will be a cold start and this entire process will happen again.  This is illustrated above. Is the team making any more improvements?  Yes! This post is simply a point in time (February 2018) analysis of how things work, and many specifics are subject to change. As evidence, we recently released an update to the runtime and for our GA languages we’re seeing a further 50% improvement on cold start times. I won’t go super deep on it here, but this update fixed a regression in our native image generation. For more details, read up on NGEN or check out the release itself (we’re fully open source!) How Can I Improve My Code to Help Avoid Long Cold Starts?  Now that we have a baseline understanding of what’s happening behind the scenes to cause cold start, we can start to address how to architect your solutions to avoid it.  Language: First and foremost, use our generally available languages – C#, F#, and JavaScript. We have several experimental languages which aren’t fully supported and optimized – most of them actually spin up a new process on every execution, which impacts latency a great deal. Also, it’s important to note that any language running in our 2.0 runtime is in preview and also hasn’t been optimized fully. We expect these languages to perform better in the future, but for now, stick to the GA languages mentioned above. For more specifics, see our documentation. Write Lightweight Code  Dependencies: When you deploy your code, your dependencies are added as files to your application. As outlined in step 4 above, all code needed by your app eventually gets loaded into memory, which takes longer with a larger application. So, if you have a ton of dependencies, you’ll get a longer cold start due to a) increased time for I/O operations from Azure Files, and b) longer time needed to load a bigger app into memory. This is a thing we see all the time for folks writing functions in JavaScript – npm trees can get huge. Not only does this increase the size of your app, but also increases the number of files that Azure Files has to handle, which causes further slowdown. For this scenario in particular, we’ve released a tool to help: check out Funcpack to learn more!  Efficient Code: Sometimes the answer is simply writing more efficient code. There are a few approaches to note here – first, try to make as much processing as possible asynchronous. Functions won’t perform well if you have a heavyweight synchronous call blocking your code from completing. Along this vein, try to minimize the amount of work that has to happen before your code starts up and avoid code which consumes a lot of CPU. If you’re concerned about this yourself, we recommend trying out Application Insights – it’s a fantastic monitoring tool and can help isolate application slowdown from platform slowdown. Avoiding Cold Start Altogether  Dedicated Mode: As mentioned before, running Functions in an App Service Plan alleviates these issues since you control what happens on your VM. This is slightly more expensive, and isn’t serverless, but if your solution has a hard requirement for low latency on every individual call, consider using the Dedicated mode.    Feedback  Feedback is always welcome – if you want to tell us what you think or reach out to the product team directly for any other reason, engage with us on Twitter or GitHub!  @AzureFunctions @ColbyTresness Azure Functions     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/02/07/Understanding-Serverless-Cold-Start.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "January 2018 App Service update",
        "excerpt":"      Byron Tardif     2/8/2018 5:20:54 PM  Welcome to a new and exciting year of App Service updates, December 2017 was a quality milestone for the App Service team and over the break we delivered over 60 general quality of life and performance improvements for both the App Service and Functions experience in the Azure portal.  Now that we are in February it’s time to share some of the improvements and new features we delivered in January 2018 Application Settings UX refresh  The new application settings ux uses the same code base across App Service, Azure Functions and Web Apps for Containers. It provides a consistent look and feel, improves performance and allows us to deliver improvements and new features across all 3 products with less duplicated work.         My SQL in-app data import  My SQL in-app now lets you import as well as export the database content. This makes it easy to migrate existing databases in and out of MySQL in-app.   New FAQ UI  We have a new experience that provides in context help content filtered to the specific feature you are using. The content is driven by the App Service documentation and it lets you get straight to what you need without having to search for it.   Web App on Linux support for .NET Core 2.0  Web Apps on Linux now has built in support for .NET Core 2.0      If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice Previous updates:   November 2017 App Service Update October 2017 App Service Update September 2017 App Service Update August 2017 App Service update        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/02/08/January-2018-App-Service-update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Troubleshooting Tools for App Service Certificate",
        "excerpt":"      mksunitha     2/20/2018 11:26:25 AM  This blog post describes the various tools available to you to debug any issues with App Service Certificates  resources that you may be using with Web App or other Azure Services.  SSL is a critical part of your application and when configuring the certificate or renewing the certificate there can be a few issues you might run into . These tools listed below can help provide you information to self-debug the issue in most cases.    Verify Status of your Certificate : Check if the Status of your certificate is ready for use. Sometimes the certificate might have Domain verification step pending and this status tile can help provide information on what steps you need to take     There are many different states the certificate can be in :    Certificate Denied : Domain verification was not completed in  15 days causing the certificate to be in denied state. Certificate will not be billed. Purchase a new certificate with same domain to resolve this . Certificate cannot be restored. Certificate Expired : Certificate has expired . If auto renew was enabled and the certificate still expired , then credit card payment may have failed for the subscription. In this case , you need purchase a new certificate with the desired domain to resolve the issue.Certificate cannot be restored. Domain verification required : Domain verification is pending . Click on \"Certificate Configuration\" and complete STEP 2 for domain verification. If Domain verification option is not working , select Manual verification to complete this step.  If Domain verification is not completed in 15 days , certificate will be in denied state Key Vault out of sync: Key vault can be out of sync if it was deleted , moved to another subscription or if the subscription was in suspended/canceled  state.  Choose your app service certificate in the Azure portal , click on Certificate Configuration and complete STEP 1 to assign a new Key Vault resource to app service certificate.  Note if you are bringing you external certificate via Key Vault using this blog post , you must reconfigured to use the correct secret with the app service certificate. App service certificate looks for secret name and does not support using \"certificate object\" in key vault. This is a limitation and we are working in fixing it   Debug using Resource Explorer : You can look at the certificate order state in resource explorer https://resources.azure.com . Select your subscription -&gt; Providers -&gt; Microsoft.CertificateRegistration-&gt;Certificateorders .  This lists all the certificate orders within the subscription.  Search for a given  certificate and look at the  \"provisioingstate\" property . If Succeeded , it will be ready to use state. If not , resolve the issues based on the states mentioned earlier in this post.    Debug using Timeline : View the list of historical activities or operations that have occurred on App Service Certificate resource using the Timeline feature to help debug the issue  Sync a Certificate : The Web App service runs a background job that periodically (once a day ) that syncs all App Service certificate. Hence when you rotate or update a certificate, sometimes the application is still retrieving the old certificate and not the newly updated certificate.  This  is because the job has not run to sync the certificate resource.   To force a sync of the certificate , you can click on Rekey and Sync setting and then click on Sync button . Refer to FAQs   documentation  : Get access to appropriate documentation to App Service certificates to help resolve the issue with Configuration , Rekey and Sync , Renewal etc  .     If the above tools dont help you resolve the certificate related issues , then please contact Microsoft Azure Support.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/02/20/Troubleshooting-Tools-for-App-Service-Certificate.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Deep Dive into TCP Connections in App Service Diagnostics",
        "excerpt":"      Jennifer Lee (MSFT)     3/1/2018 8:51:29 AM  Note: This information below only applies to Windows web apps on App Service.  Recently, we released the TCP Connections tile shortcut in App Service diagnostics. In this blog, we will walk through the implications of having unhealthy TCP Connections and how you can analyze them using App Service diagnostics. Why should you care about TCP Connections?  Let's say that you have created two web apps on the App Service Plan, and both are breaking. An example of when TCP Connections can cause this behavior in your web apps could be that one app is leaking a lot of socket handles and ends up hitting the machine wide TCP Connection limit. App Service enforces limits on the number of outbound connections that can be outstanding at any given point in time. When web apps run into these connection limits, they will start intermittently failing because calls to those remote endpoints will fail, causing downtime. You’ll frequently see errors like the following: “An attempt was made to access a socket in a way forbidden by its access permissions aaa.bbb.ccc.ddd.”  The maximum connection limits are the following:  1,920 connections per B1/S1/P1 instance 3,968 connections per B2/S2/P2 instance 8,064 connections per B3/S3/P3 instance  If you want more information, read more in the “Network Port Capacity for Outbound Network Calls” section of the “Azure - Inside the Azure App Service Architecture” article. TCP Connections Walkthrough  To examine your TCP Connections more closely, click on the \"Diagnose and solve problems\" tab in the left hand menu. Then, select the \"TCP Connections\" tile shortcut.    Upon opening the TCP Connections, you can quickly see three levels of data: TCP Connections, Connections Rejections, Open Socket Handles. If it’s healthy, there will be a green checkmark. If it’s unhealthy, there will be an orange exclamation mark. TCP Connections   Here, you can monitor the total connections on your instances and the state of the connections, which include TIME_WAIT, ESTABLISHED etc.  If your web app has high outbound connections (&gt; 1500 outbound connections), you will see the IP addresses’ first three octets and the port number in the Summary. By examining the port number, you can determine what type of remote service is causing the high outbound connections.    Port Number Service   1433 SQL   80 or 433 Web Service     Connections Rejections   Check if there are any port rejections. If your web app failed to make an outbound TCP connection because the machine-wide TCP Connection limit was hit, we will highlight that in the Summary and associated graph.   Open Socket Handles  Here, you can determine which web app is causing a socket leak if you have multiple web apps in your App Service Plan.  If your web app has leaking connections, you will see the process name, process ID, site name, and number of open handles. We will highlight the process that is causing the maximum damage in the Summary.          ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/03/01/Deep-Dive-into-TCP-Connections-in-App-Service-Diagnostics.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Major Version Updates to Node and PHP on App Service on Linux",
        "excerpt":"      Jennifer Lee (MSFT)     3/5/2018 9:18:45 AM  We've recently released new versions to Node and PHP on App Service on Linux!  For Node, we have added:  9.4 8.9 8.8 8.2  For PHP, we have added:  7.2  If you already have an existing web app that you would like to update to the new versions, navigate to the \"Application Settings\" from the left-hand menu of your web app and select the new version in the \"Stack\" dropdown.    If you're creating a new web app, check them out in the \"Runtime Stack\" dropdown.       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/03/05/Major-Version-Updates-to-Node-and-PHP-on-App-Service-on-Linux.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure App Service on Azure Stack Update One Released",
        "excerpt":"      Andrew Westgarth     3/12/2018 3:52:20 PM      This morning we released the first update to Azure App Service on Azure Stack.  This release updates the resource provider and brings the following key capabilities:  Support for Highly Available deployments of Azure App Service on Azure Stack  The Azure Stack 1802 update enabled workloads to be deployed across fault domains. Therefore App Service infrastructure is able to be fault tolerant as it will be deployed across fault domains. By default all new deployments of Azure App Service will have this capability however for deployments completed prior to Azure Stack 1802 update being applied refer to the App Service Fault Domain documentation   Deploy in existing virtual network  As a result of customer feedback post release we have now added this capability enabling customers to deploy Azure App Service and communicate with their SQL and File Server resources over a private network.   Update the App Service Tenant, App Service Admin and Azure Functions portals. Updates to add .Net Core 2.0 support, additional versions of NodeJS, NPM, PHP, new versions of Git and Mercurial All other fixes and updates detailed in the App Service on Azure Stack Update One Release Notes  You can download the new installer and helper scripts:  Installer – https://aka.ms/appsvcupdate1installer Helper Scripts - https://aka.ms/appsvconmashelpers  Please read the updated documentation prior to getting started with deployment:  Before you get started with App Service on Azure Stack Deploy the App Service Resource Provider for new deployments Update the App Service Resource Provider for updating existing deployments         ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/03/12/Azure-App-Service-on-Azure-Stack-Update-One-Released.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Deprecating Service Management APIs support for Azure App Services",
        "excerpt":"      Naveed Aziz     3/12/2018 4:50:13 PM  At Build 2014, Azure announced RESTful API for resource management called Azure Resource Manager and a shiny new Azure portal. In the years since Azure App Service has  implemented support for Azure Resource Manager. If you manage your App Service resources through the portal or through automation against the REST API or any of these SDKs, clients or tools or deploy resources through deployment templates, you are already using Azure Resource Manager. If, however, you also have automation built against the legacy Azure Service Management APIs, this announcement affects you.  Azure App Service resource management will be supported only through Azure Resource Manager. Azure Service Management support will be retired on June 30, 2018. The Service Management APIs are archaic and not well suited for the modern cloud. Supporting Service Management APIs any longer will hold us back from delivering premium developer experience and control plane scale. Customers currently using the Service Management APIs will be better served by moving to Resource Manager. Azure Resource Manager has many benefits over Service Management like robust deployment model, role-based access and better API support for existing and new features. For more information,  see Difference between Azure Service Manager and Azure Resource Manager.  Determining if you are using Azure Service Management APIs  A good way to tell if your automation (SDK/tool/client) uses Service Management APIs is to see if that automation uses Web Spaces or Resource Groups to manage (deploy/create/update/start/stop/configure etc.) resources. To uniquely identify and manage resources, automation needs a logical grouping mechanism that is also the uniqueness scope for the resources. For Service Management APIs for Azure App Service that grouping is Web Spaces, while for Azure Resource Manager it is Resource Groups. If your automation (SDK/tool/client) uses Web Spaces to manage resources you are using Azure Service Management and we recommend that you switch to the Azure Resource Manager.  UPDATE::  App Service diagnostics now has a detector that can identify any soon to be deprecated APIs called within the last 24 hours on your web app or associated resources. Once the API in question is no longer called, the detector will let show 'green' for that API within 24 hours.  From the app service overview blade click on \"Diagnose and solve problems\".       Once the detectors have loaded click on \"Deprecating APIs\" under the section \"Management and Configuration\". This will open up a new tab \"Deprecating APIs\"    Once the detector execution completes, you will have names of all the API clients/tools used to call the deprecating APIs and the actual calls.   Authentication  Service Management supports authentication using Azure Active Directory or management certificates. For Resource Manager authentication is built around Azure Active Directory apps and interactive user access. To learn more, see Resource Manager API Authentication. If your automation must use certificates for management, you can achieve that by Authenticating to Azure Resource Manager using AAD and certificates.  Resource Deployment  Resource Manager has a robust deployment engine with declarative resource description. To understand how the resource deployment differences between the two, see  Resource Manager Deployment Model. Resource manager supports resource deployment via deployment templates. Additionally, starting from Microsoft Azure SDK for .NET 2.9, resource deployment via Visual Studio is also supported. For more information, see Deploying resources and code through Visual Studio. Directly calling the API  If you want to code against the Resource Manager REST API directly, refer to Azure App Service REST API documentation. ARMClient and Azure Resource Explorer are great tools to play with and discover the shape of the App Service Resource Manager API. For more information on ARMClient, see ARMClient: a command line tool for the Azure API.  SDKs and tools  Resource Manager offers SDKs and tools in a large set of languages, frameworks and platforms. These include but are not limited to .NET, Node, Java, Ruby, Python, Go, PowerShell and Azure CLI. Detailed documentation, tutorials and examples are available here.  App Service Resource Metrics  If your automation consumed the App Service resource metrics API, we recommend that you switch over to the Azure Resource Manager Monitoring APIs. While we still offer App Service specific metrics API, we plan on deprecating them soon. The Resource Manager Monitoring APIs are the common way of interacting with metrics across any resource on any service within Azure. For more information, see  metrics supported by Azure Monitor.  Please make sure to move all your automation and deployment tools to use new API’s before June 30th 2018 so that you do not experience any service interruptions and benefit from superior deployment and management capabilities of Azure Resource Manager.        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/03/12/Deprecating-Service-Management-APIs-support-for-Azure-App-Services.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Updating PHP to latest versions",
        "excerpt":"      Eric Stenson (Microsoft)     3/14/2018 12:52:07 PM  In the next release of Azure Web Apps, we will update the PHP stacks to the latest available versions.  For information on the changes in the new versions, please see the change logs on the PHP website.      PHP Version Change log   5.6.34 http://www.php.net/ChangeLog-5.php#5.6.34   7.0.28 http://www.php.net/ChangeLog-7.php#7.0.28   7.1.15 http://www.php.net/ChangeLog-7.php#7.1.15   7.2.3 http://www.php.net/ChangeLog-7.php#7.2.3         ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/03/14/Updating-PHP-to-latest-versions.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "BizTalk Hybrid Connections going end of life May 31, 2018",
        "excerpt":"      Christina Compy (MSFT)     3/20/2018 6:24:08 PM  Azure App Service has two features named Hybrid Connections. There is the original BizTalk Hybrid Connections and the newer Azure Relay based App Service Hybrid Connections. BizTalk Hybrid Connections is going end of life May 31, 2018.  To avoid problems, you should migrate from BizTalk Hybrid Connections to the new Azure Relay based Hybrid Connections. You can read more about them in Azure App Service Hybrid Connections To migrate your BizTalk Hybrid Connections to the new Hybrid Connections, you need to:  Make sure the apps you want to use Hybrid Connections with are running in a Basic, Standard, Premium, Premiumv2, or Isolated App Service plan. Create a new Hybrid Connection using the information in Add and Create Hybrid Connections in your app.  The name of the new Hybrid Connection does not have to match the old one but the endpoints should be the same between the new and the old Hybrid Connection. Add the new Hybrid Connection to the apps that are using the BizTalk Hybrid Connection. Upgrade all of your Hybrid Connection Managers to the newest version. The installer for the new Hybrid Connection Manager will upgrade your older instances. You can read more about the new Hybrid Connection Manager here and can download it from the Azure portal in the App Service Hybrid Connections portal. Add your new Hybrid Connections to all of the Hybrid Connection Managers you want to use. After the new Hybrid Connection shows a status of Connected in the portal, delete the older BizTalk Hybrid Connection.  The new Relay based Hybrid Connections exist as a service outside of Azure App Service. You can find more details starting with the Overview on Azure Relay.  Relay based Hybrid Connections does have a number of improvements over the BizTalk Hybrid Connections.  The newer feature uses TLS 1.2, communicates to Azure only over port 443, creates connections based on a DNS name, and has a much easier user experience.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/03/20/BizTalk-Hybrid-Connections-going-end-of-life-May-31,-2018.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Renaming our new command to up",
        "excerpt":"      Ahmed Elnably     3/22/2018 5:12:33 PM  We listened to feedback, we decided to change our previously released experimental \"new\" command to be now \"up\".  With version 0.2.0 of the extension, \"new\" is no longer available, and you will have to use \"up\" instead.    The command (Which is still in Preview) enables the user to create and deploy their Node.js, .NET Core, ASP.NET, Java, or Static HTML apps using a single command. For Node.js we check for the existence of a package.json file in the code root path to indicate it is a Node.js app. For ASP.NET and .NET Core we check for the existence of a *.csproj file with netcoreapp as the TargetFramework. For static HTML we check the existence of a *.html file.  The command check for languages in the following order:  Node.js .NET Core and ASP.NET Static HTML  In the case of Node.js and Java apps the command does the following:  Create a new resource group (in Central US, you can use the --location to change the region) Create a new Linux single VM small App Service plan in the Standard SKU (in Central US) Create a Linux webapp Deploy the content of the current working directory to the webapp using Zip Deployment  In the case of an ASP.NET, .NET Core, Static HTML app the command does the following:  Create a new resource group (in Central US, you can use the --location to change the region) Create a new free Windows App Service plan (in Central US) Create a Windows webapp Deploy the content of the current working directory to the webapp using Zip Deployment  To Install the Azure CLI tools refer to their documentation.  To Install the extension: az extension add --name webapp To update the extension with the latest fixes and new languages support (Current version is 0.2.0): az extension update --name webapp To know what the command will do without creating anything: az webapp up --name [app name] --location [optional Azure region name] --dryrun To use the new command: az webapp up --name [app name] --location [optional Azure region name] To update your app content - Just rerun the command you used to create the app (including the --location argument): az webapp up --name [app name] --location [optional Azure region name] To submit feedback or submit an issue please open an issue in the Azure CLI extensions Github Project page.  Road Map - also tracked here:  Add ASP.Net support Add Java support Add more languages to the supported list Add support to Azure Functions        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/03/22/Renaming-our-new-command-to-up.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Get Community driven Docker images for Web app for Containers",
        "excerpt":"      mksunitha     3/27/2018 1:53:59 PM  You can now find community driven docker images to try out on Web App for Containers on Github. These images follow best practices for Web app for containers , contain SSH for debugging purposes. How to deploy  These docker images can be found on Docker hub on hub.docker.com/r/appsvcorg.  Use the latest tag for the most recent version of the image when deploying it to Web app on Azure.  To deploy your application using these community images , follow the steps below  Login to Azure portal Create a new web app from Web app for Containers template  Under configure container , select  Image source as Docker Hub Repository access as public Enter docker image name in this format : appsvcorg/django-python:0.1 or  appsvcorg/django-python:latest       Click on Create to start the deployment View the Readme.md for the docker image you have selected on github if there are additional configurations to be made after the web app is created.  How to contribute  To make sure your docker image is included , please follow these guidelines. Any docker image that are out of compliance will be added to the blacklist and be removed from Docker hub repository https://hub.docker.com/r/appsvcorg .  Here is the end to end process flow for contributing to this docker hub repository .    When you contribute a new docker image , as the owner of that docker image your responsibilities include:  review issues reported on the docker image on Github fix and resolve bugs or compliance issues with the docker image keep the docker image up to date  Get started on how to contribute to the Github repository. How to remove a docker image from Docker hub  Docker images can be removed from Docker hub and Github repository  when either if the two cases below is applicable :  If the owner/primary maintainer of the docker image does not wish to maintain the docker image and remove it since they no longer support it. Please report it to appgal@microsoft.com to remove the docker image from Docker hub and Github repositories . If docker image is outdated , or is has bugs unresolved for more than 3 months the docker image will be removed .  How to report issues  If you want to report issues , please report an issue here. Provide all the necessary information as shown in this template to report an issue in order for us to help with resolving the issue.           ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/03/27/Get-Community-driven-Docker-images-for-Web-app-for-Containers.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing the Availability of Azure Functions in National Clouds",
        "excerpt":"      Asavari Tayal     3/28/2018 9:15:53 AM  To further our commitment of providing the latest in cloud innovation for each and every one of our customers, we're excited to announce the availability of Azure Functions in three separate national clouds - China, Germany and United States Government.  National or sovereign clouds are physically and logically network-isolated instances of Microsoft's cloud service, which are confined within the geographic boundaries of specific countries and operated by local personnel. These clouds offer a unique model for local regulations on service delivery, data residency, access and control.  Functions in the national clouds provides the same functionality and features as global Azure. The rich portal experience allows you to create, manage and monitor your functions. You can develop using C#, F# or JavaScript and integrate with a wide variety of services using triggers and bindings.   As always, you can pick from a range of tools such as the cross platform CLI, Visual Studio IDE and VS Code to develop, debug and test locally, before deploying your apps to Azure.  Known Limitations   Currently, Functions in the national clouds can only be hosted in an App Service Plan. Each plan requires you to define a specific region, number of VM instances in that region and size of the VMs that must be dedicated to your apps. If your scenario requires the consumption plan, please let us know by submitting a feature request on UserVoice.  Basic monitoring is available through the functions logs and the monitoring tab in the portal. A richer experience with more analytics options will be available once Azure Application Insights is available in the national cloud regions.    Next Steps  Here are some resources to help you get up and running with Functions:    Get started using the docs – Create your first function in the Azure Portal  For technical questions, please post on MSDN or StackOverflow. We actively monitor these forums and will be happy to help with your query.      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/03/28/Announcing-the-Availability-of-Azure-Functions-in-National-Clouds.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP Minor Version Update for May 2018",
        "excerpt":"      Jennifer Lee (MSFT)     4/7/2018 3:05:23 PM  Latest version updates to PHP  In May 2018, Azure App Service will update the PHP stacks to the latest available versions (including MSSQL Drivers for PHP 7.2). For information on the changes in the new versions, please see the change logs on the PHP website.    PHP Version Change Log   5.6.35 http://www.php.net/ChangeLog-5.php#5.6.35   7.0.29 http://www.php.net/ChangeLog-7.php#7.0.29   7.1.16 http://www.php.net/ChangeLog-7.php#7.1.16   7.2.4 http://www.php.net/ChangeLog-7.php#7.2.4        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/04/07/PHP-Minor-Version-Update-for-May-2018.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "March 2018 App Service update",
        "excerpt":"      Byron Tardif     4/10/2018 1:31:17 PM  New tiles on overview blade  Overview blade has been revamped to add quick links for Diagnose and Solve problems, Application Insights and App Service Advisor   Free and Shared apps now support HTTPS only configuration  Last year we enabled the ability to force HTTPS connection for your apps hosted on app service and we are now extending support to also cover apps hosted in free and shared App Service plans.    Quality of life improvements for App Service Certificates and App Service Domains  Over the last 2 months we have fixed over a dozen issues both in UX and back-end to improve reliability and reduce the incidence of most common user issues in these areas. Azure Function on National Clouds  Azure functions is now available for National Clouds          If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice Previous updates:   January 2018 App Service Update November 2017 App Service Update October 2017 App Service Update September 2017 App Service Update      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/04/10/March-2018-App-Service-update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service Environment is now available in US Government regions",
        "excerpt":"      Christina Compy (MSFT)     4/11/2018 1:37:03 PM  The App Service Environment, with Isolated pricing plans, is now available in the US Government regions.  The App Service Environment is a deployment of the Azure App Service and runs in your Azure Virtual Network.  With an App Service Environment you have more options for:  High scale Network isolation High memory utilization  The App Service Environment can be deployed with an internet accessible endpoint or with an endpoint on a private address in your Azure Virtual Network.  This makes the App Service Environment a great solution to host your line of business applications or those applications that you want to only expose through a web application firewall such as the Azure Application Gateway.  To learn more about the App Service Environment start with the Introduction to the App Service Environment   To create an internet accessible App Service Environment you can start with Creating an External App Service Environment   To create an App Service Environment with a private address you should use Create and use an internal load balancer with an App Service Environment  If you are interested in how to couple an App Service Environment with a web application firewall, we have a write up on Integrating your App Service Environment with an Application Gateway                 ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/04/11/App-Service-Environment-is-now-available-in-US-Government-regions.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Using EV SSL with Azure Web App",
        "excerpt":"      mksunitha     4/12/2018 12:33:21 PM  You can use EV SSL with Azure web apps. There are many CA that provide EV SSL for your web applications and the two options you have to use EV SSL with azure web app :  Option 1 : Bring your own certificate and upload to web app  Contact your CA to get instructions on how to export your EV SSL into PFX format . Then follow the instructions to upload this certificate into your web app . Once the certificate is uploaded , add an SSL binding to your web app . Option 2 : Buy a certificate via Key Vault and import to Web App  Azure Key Vault supports both DigiCert and GlobalSign CA providers to purchase ORG SSL and EV SSL.  You can purchase a EV SSL from either of these providers . Follow instructons on how to purchase and configure a EV SSL from these providers into Key Vault  Purchase and configure DigiCert  with Azure Key Vault  Purchase and configure GlobalSign with Azure Key Vault  Place the certificate (PFX format ) in Key Vault and then  follow the instructions here to import the Key Vault as an App Service Certificate . Troubleshooting Issues  In the Azure portal , go to your App Service Certificate using this Key Vault resource for your EV SSL certificate . Follow the steps below to troubleshoot issues :   Key Vault may have moved to another subscription or deleted or in a suspended state  : In the portal , when you open your App Service certificate you will see the status \"Key Vault out of Sync \"  . In this case , click on the status tile which will prompt you to reconfigure your Key Vault to App Service certificate to a valid Key Vault . Note the Key Vault must be in the same subscription as the App Service certificate Key Vault secret was updated but I still see the old secret in App Service certificate : Web App service runs a background job that periodically (once a day ) that syncs all App Service certificate. Hence when you rotate or update a certificate, sometimes the application is still retrieving the old certificate and not the newly updated certificate.  This  is because the job has not run to sync the certificate resource.   To force a sync of the certificate , you can click on Rekey and Sync setting and then click on Sync button .     Documentation Support : Checkout our FAQs for more details if you run into any issues managing your App Service Certificate       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/04/12/Using-EV-SSL-with-Azure-Web-App.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing HTTP2 support in Azure App Service",
        "excerpt":"      Oded Dvoskin     4/13/2018 10:00:02 AM  The Azure App Service team is happy to announce the global deployment of support for the HTTP/2 protocol for all apps hosted on App Service. HTTP/2 has been the top customer request we have received, and we are excited to light up support!    What is HTTP/2?  HTTP/2 is a rework of how HTTP semantics flow over TCP connections, and HTTP/2 support is present in Windows 10 and Windows Server 2016. HTTP/2 is a major upgrade after nearly two decades of HTTP/1.1 use and reduces the impact of latency and connection load on web servers.  The major advance of HTTP/1.1 was the use of persistent connections to service multiple requests in a row. In HTTP/2, a persistent connection can be used to service multiple simultaneous requests. In the process, HTTP/2 introduces several additional features that improve the efficiency of HTTP over the network. One connection for multiple requests  Every TCP connection requires a round trip to set up. If you're using encryption, the TLS handshake takes another 1-2 round trips. All this happens before the first byte of the first response can be sent. By reusing an existing connection instead of setting up a new one, this overhead can be shared by many requests. HTTP/2 sharply reduces the need for a request to wait while a new connection is established, or wait for an existing connection to become idle. Because a single connection is multiplexed between many requests, the request can usually be sent immediately without waiting for other requests to finish. Header compression with HPACK  HTTP has supported compression of data for ages. Headers, however, are sent as uncompressed text, with a lot of redundancy between requests. (Many of the longest headers are sent with exactly the same value on every request!) HTTP/2 introduces HPACK, a compression scheme for HTTP headers which reduces the redundancy between requests.  Compression also helps multiplexing, because requests are smaller. This enables clients to make many requests in their first packets on a connection, while TCP flow control windows are still small.  What are the key differences from HTTP/1.x?  HTTP/2 is binary Fully multiplexed, instead of ordered and blocking Ability to use one connection for parallelism Has one TCP/IP connection Uses header compression to reduce overhead    What action do App Service users need to take?  All you need is a just a simple configuration! HTTP/2 is disabled by default for all customers. However, if you would like to opt-in and apply HTTP/2 for your site, follow the steps below:  Through the Azure Portal, browse to your app and search for the \"Application settings\", where you will find the setting called \"HTTP Version\". Select 1.1 or 2.0 by your needs.    You may also browse to the Azure Resource Explorer using one of the following steps:  In the Azure Portal, select “Resource explorer” in your App Service app’s menu.    Then select ‘Go’    Alternatively, browse directly to Resource Explorer (https://resources.azure.com/).  The advantage of going through the Azure Portal route is that the browser will be automatically navigated to your requested app’s configuration, then you just have to navigate to config &gt; web, where you will find the needed value to update.  If browsing directly to Resource Explorer, drill down through the tree hierarchy to your site using the following path:  Subscription &gt; Resource Group &gt; your site name &gt; Providers &gt; Microsoft.Web &gt; sites &gt; your site name &gt; config &gt; web    On the top of the page make sure you’re in Read/Write mode:    Select Edit:    Find the parameter for HTTP/2:    Type in ‘true’ in place of ‘false’:    On the top, select ‘PUT’:    You’re done!  Support for HTTP/2 in App Service Environments and the Azure National Clouds is available as well!  HTTP/2 Browser Support Requires SSL  Most modern browsers only support using the HTTP/2 protocol over SSL, while non-SSL traffic continues to use HTTP/1.1.  App Service makes it easy to get up and running with SSL.  Learn how to configure a new SSL cert for your app, or learn how to bind an existing SSL cert to your app.  App Service also provides a default level of SSL functionality for all apps via a common wildcard SSL certificate bound to the *.azurewebsites.net domain. Regardless of which approach you choose, your apps will need to run over SSL to enjoy the benefits of HTTP/2 with modern browsers. What if I encounter an issue?  If you find an issue you suspect is stemming from the update to HTTP/2 you can alert us through the following methods:  Ask a question on the developer forums: MSDN or Stack Overflow Open a support ticket      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/04/13/Announcing-HTTP2-support-in-Azure-App-Service.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service and Functions hosted apps can now update TLS versions!",
        "excerpt":"      Oded Dvoskin     4/17/2018 10:47:40 AM  Following our communication earlier in the year, the App Service team is happy to announce that the ability to explicitly configure the TLS version for individual applications, is now available.    What is TLS?  Transport Layer Security (TLS) is a protocol that provides privacy and data integrity between two communicating applications. It's the most widely deployed security protocol used today, and is used for web browsers and other applications that require data to be securely exchanged over a network, such as file transfers, VPN connections, instant messaging and voice over IP.  Multiple versions of TLS are available, with each being released at a different time and mitigating different vulnerabilities. TLS 1.2 is the most current version available for apps running on Azure App Service. Why should I update my TLS version?  The PCI Security Standards Council has stated that June 30th, 2018, is the compliance deadline for disabling early TLS/SSL versions and implementing more secure protocols for your applications’ traffic. Customers requiring PCI compliance should move away from TLS 1.0, and onto TLS 1.1, though it is highly recommended to instead move directly to TLS 1.2. How can I test my connection and assess my risk?  Most traffic going to apps hosted on Azure App Service is originating from modern Web Browsers updated to recent versions.  SSL traffic originating from out-of-date browsers may not support newer TLS versions like TLS 1.2. In order to test your app’s compatibility with updated TLS versions, we suggest testing with one of the various 3rd party solutions to test traffic to your apps like SSLLabs. After updating the TLS setting for your app, you may use SSLLabs to test and see if lower versions of TLS are not accepted any more. What’s next for App Service hosted apps?  At the time of releasing this blog, all applications running on public multi-tenant App Service hosted platform, including Azure Functions, apps hosted on the Azure National Clouds and App Service Environments (ASE), can update settings to select the TLS version that is required.  From June 30th, 2018, all newly created App Service apps will automatically have TLS 1.2 selected as the default configuration. Though not recommended, we are allowing users to downgrade the TLS version if desired. How can I update the setting to select my required TLS version?  In the Azure Portal, go to your App Service app’s menu, select SSL Setting and select the toggle to the version you require. Auto-save of the selection is enabled. Please allow a few minutes for the setting to be reflected in the monitoring tools.    TLS configuration through CLI and PoweShell will be coming soon.  What if I have questions about this change?   Open a forum post on the App Service forum or on Stack Overflow. Open a support ticket. Refer to the document covering the feature and changes to the configurations.      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/04/17/App-Service-and-Functions-hosted-apps-can-now-update-TLS-versions!.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service Command Line Tools Resources",
        "excerpt":"      Ahmed Elnably     5/1/2018 11:14:38 AM  I usually find myself looking for the bookmarks I have for different command line docs and issues pages. Here is the one place for all the resources for our command line tools, this includes our new \"az webapp up\" experience, Azure CLI experience, and Azure PowerShell experience. az webapp up:  How to install: az extension add -n webapp Blog post: https://aka.ms/new-cli Reference Guide: https://docs.microsoft.com/en-us/cli/azure/ext/webapp Issues: https://aka.ms/webapp-extension-issues  App Service Azure CLI:  Reference Guides:  https://docs.microsoft.com/en-us/cli/azure/appservice https://docs.microsoft.com/en-us/cli/azure/webapp  Issues: https://github.com/Azure/azure-cli/issues Samples: https://docs.microsoft.com/en-us/azure/app-service/app-service-cli-samples  Azure Power Shell:  Reference Guide: https://docs.microsoft.com/en-us/powershell/module/azurerm.websites Issues: https://github.com/Azure/azure-powershell/issues Samples: https://docs.microsoft.com/en-us/azure/app-service/app-service-powershell-samples Functions Azure CLI:  Reference Guide: https://docs.microsoft.com/en-us/cli/azure/functionapp Issues: https://github.com/Azure/azure-cli/issues Samples: https://docs.microsoft.com/en-us/azure/azure-functions/functions-cli-samples      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/01/App-Service-Command-Line-Tools-Resources.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Breaking change for SNI-SSL hostnames on Azure App Service",
        "excerpt":"      Oded Dvoskin     5/2/2018 1:36:23 PM  SSL in Azure App Service  Azure app service is a multitenant infrastructure. When web apps are created on azure app service, we provide a default hostname which is sitename.azurewebsites.net. Clients can make requests over HTTP or HTTPs to these hostnames. When using HTTPs against the default hostname for the site, a certificate with subject name *.azurewebsites.net is returned to the client for SSL.  When customers configure an app service with a custom domain name, by default the system allows you to pick between an SNI-SSL binding type or IP-SSL binding type.  SNI-SSL bindings are free of cost. For an SNI binding to be in use, clients making requests to this host will need to include an SNI header in the TLS initial handshake message. From a specification standpoint, TLS 1.0 supports SNI header extension, and all modern browsers includes the SNI header by default.  In contrast, there can be older versions of browser clients or legacy library clients. For custom domains to work correctly for these clients, the site must be configured to have IPSSL bindings. What is SNI and IP-SSL really and why does it matter?  When the initial SSL handshake request arrives at a web server, the mandatory parameters like the version of SSL being negotiated, the cipher suites the client supports are included in the clear text CLIENT HELLO message. From the server standpoint, with this information, the server needs to select the appropriate certificate to use for this request. For a web server with a single site/hostname, the matter is easy, you can configure the server with just one binding/certificate on a single port and all is fine.  However, in a webserver which hosts multiple sites or hostnames, based on the version + cipher suites alone, the server cannot pick the correct certificate. Hence, this requires the bindings on the server to be configured based on a different IP for each of the hostname the server wishes to support. How does SNI help?  To solve the problem of not requiring unique IP address on the server side to support multiple hostnames with SSL, the concept of an SNI extension was introduced in RFC 3546 [https://tools.ietf.org/html/rfc3546], back in 2003.  Per this spec a client can include the destination host name in the clear text CLIENT HELLO message as an additional server name extension. Now, at the server, based on this information, the server can select the appropriate certificate to use for the handshake, thus solving the problem of not requiring unique IP addresses. Why does Azure App Service support both SNI-SSL and IP-SSL bindings?  While the RFC for SNI was introduced in 2003, and all major browsers added support shortly after that, there are still legacy HTTPs clients which doesn’t include the SNI header extension in the client hello. If an azure app service customer anticipates such a client to use their site hosted in azure app service, it is recommended to add an IP-SSL binding, so that this site now has a dedicated IP Address. This allows us to pick the correct certificate for that hostname. What are the breaking changes with TLS 1.2 compliance initiative?  We now enforce TLS 1.2 for clients which arrive without SNI header. Note that these are typically old browser clients which do not support SNI or programmatic clients which were written long ago and not updated to include the SNI header name.   For sites which did not have a custom domain name configured:  These hostnames are always SNI-SSL (or more like SNI-Required).  For these sites, the hostnames used is the default sitename.azurewebsites.net. Customers can configure the minimum required TLS version on this site to be 1.0 and above, and we will honor it.  However, if a request arrives without the SNI extension in the CLIENT HELLO message, we are unable to identify the exact site the request is eventually destined to, and hence we require this request to be at least of TLS 1.2 for compliance reasons.   Sites with custom domain configured:   SNI -SSL:  For these sites just like default host name, the configuration for the minimum required TLS version can be set and will be honored by the system. However, if a request arrives without the SNI extension in the CLIENT HELLO, we require this client to at least negotiate TLS 1.2, just like the case of default hostname.  IP-SSL: No breaking change, everything should continue to work as is.  For IP-SSL bindings, since there is a dedicated IP for the hostname, our system can correctly determine the destination site based on the incoming IP address, and hence there is no requirement of SNI header or minimum TLS version requirement on requests without the SNI header. The minimum configured TLS version for the web app will take effect. I'm currently using SNI-SSL bindings: What do I do if I'm impacted?  For browser clients, upgrade browser clients to modern browsers. For security best practices, it is highly recommended to use modern up to date browsers to protect the site and the user.  For programmatic scenarios, update application code to either use TLS 1.2, or explicitly include the hostname in the client hello handshake if using TLS 1.0  To update the TLS version in a .NET app using HttpWebRequest or HttpClient, update the SecurityProtocol in the ServicePointManager as shown below.    // To update the TLS version in a .NET C# app using HttpClient/HttpWebRequest,   ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls12;    Note that when using HttpWebRequest/HttpClient class to make SSL requests, SNI header is automatically added.     If both a) and b) are not an option, the last resort and the least preferred option, would be to use IP-SSL bindings.  If you are using the default hostname, then you will need to add a custom domain name with IP-SSL. If you are already using a custom domain name, you'll need to change the binding to IP-SSL.    /* Sample code */     using System;  using System.Net;     namespace SNIClient  {      class Program      {          static void Main(string[] args)          {              ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls12;                 HttpWebRequest request = (HttpWebRequest)HttpWebRequest.Create(\"https://mysite.azurewebsites.net/\");              try              {                  HttpWebResponse response = (HttpWebResponse)request.GetResponse();                  response.Close();              }              catch (WebException ex)              {                  Console.WriteLine(ex.Message);              }          }      }  }   What if I have questions?   Open a forum post on the App Service forum or on Stack Overflow. Open a support ticket.      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/02/Breaking-change-for-SNI-SSL-hostnames-on-Azure-App-Service.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions Recipes",
        "excerpt":"      Anthony Chu - MSFT     5/3/2018 7:37:31 AM  Recently, we released a collection of over 50 tips and tricks for Azure Functions that we're calling \"Functions Recipes\". Each recipe demonstrates a single, useful concept for working with Azure Functions.  They include patterns and practices, integrations with other services, and tips that you may have overlooked when reading the documentation. With every recipe, you get a short code sample, key takeaways, and links to detailed documentation to learn more.  Our goal is to create a comprehensive collection of recipes that you can quickly reference when you're working on your serverless projects with Azure Functions. If you want to see how triggers and bindings work, set up proxies, integrate with Cosmos DB, or even collect telemetry with Application insights, we want to be a resource that adds value to your workflow.   We're only getting started. We'll be expanding the collection with even more recipes (we just added 11 new ones on Durable Functions). We launched with recipes in C#, but we are starting to add other languages such as JavaScript, Java, F#, Python, and more.  We need your help!  If you have a recipe idea or updates to suggest, create an issue or submit a pull request at the Microsoft Docs Sandbox repository on GitHub. Contributing is as easy as clicking the \"edit\" button on any of the pages.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/03/Azure-Functions-Recipes.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing the Linux on App Service Environment Public Preview",
        "excerpt":"      Jennifer Lee (MSFT)     5/7/2018 8:26:10 AM  Today, we are excited to announce the public preview of Linux on App Service Environment (ASE). Finally, our Linux customers will be able to take advantage of deploying Linux web apps into an App Service Environment, which is perfect for deploying applications into a VNet for secure network access or apps running at a high scale. What can you do with Linux on ASE?  With Linux on ASE, you can deploy your Linux web applications into an Azure virtual network (VNet), by bringing your own custom container or just bring your code by using one of our built-in images. Additionally, both Windows and Linux/containerized web applications can be deployed into the same ASE, sharing the same VNet. You will be using the Isolated SKU with Dv2 VMs and additional scaling capabilities (up to 100 total App Service plan instances, between Windows and Linux, in one ASE), previously not offered in Linux.       There are two different kinds of ASEs that you can create: an external ASE with an internet accessible endpoint or an internal ASE with a private IP address in the VNet with an internal load balancer (ILB). Steps to get started are provided here. Currently, Linux on ASE is available in these 6 regions: West US, East US, West Europe, North Europe, Australia East, Southeast Asia  Public Preview Pricing  During the public preview, you will receive a 50% discount on the Isolated SKU prices on the pricing card that applies to your App Service Plan (ASP). There is no discount on the ASE itself (it will still cost ~$1000/month USD for the ASE, regardless the size of the ASE).    Things You Should Know   Please create a new ASE to try out this feature. Because deploying Linux apps in an ASE is a preview feature, deploying a Linux app in an ASE that you previously made before this preview may have some performance impacts.   You will be able to deploy both Windows and Linux web apps into the same ASE. Remember that even though Windows and Linux web apps can be in the same App Service Environment, Windows and Linux web apps have to be in separate App Service Plans.  Because this feature is in public preview, please do NOT deploy a Linux app or container into an ASE you want fully supported. Adding a Linux app to an ASE means that the ASE will be in preview mode.   Especially for those new to App Service Environment, how long will everything take to deploy?   Because an ASE gives you a fully isolated and dedicated environment for securely running App Service apps at high scale, there are many different parts that we provision for you upon creating a web app in an ASE. Instead of sharing front ends, you will have dedicated front ends that are responsible for HTTP/HTTPS termination and automatic load balancing of app requests within the ASE.   Therefore, when deploying a web app into an ASE or performing a scaling operation, the operation can take a couple of hours or more. This is not a promised SLA.  We recommend that you scheduling your scaling operations to account for the time it takes for any extended scaling processes.     How to Get Started  You can create a Linux web app into a new ASE by simply creating a new web app and selecting Linux as the OS (built-in image) or Docker (custom container) or creating a new Web App for Containers (custom container). When creating a new App Service Plan, remember to select one of the 6 supported regions and select one of the Isolated SKUs.    Because Linux on ASE is now in public preview, we would love to hear all of your feedback and questions about the product here. Start creating your first Linux/containerized web app into an ASE by following these instructions.        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/07/Announcing-the-Linux-on-App-Service-Environment-Public-Preview.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service AuthenticationAuthorization Coming to Linux Apps",
        "excerpt":"      Yi Liao MSFT     5/7/2018 8:25:00 AM  Following our communication earlier in the year, the App Service team is happy to announce that the App Service Authentication/Authorization feature is now available to Linux apps.  What’s App Service authentication/authorization feature?   Azure App Service provides built-in authentication and authorization support, so you can sign in users and access data by writing minimal or no code in your web app. The same authentication and authorization feature support for Windows apps is now available to App Service on Linux including Web App for Containers.  This overview article describes how App Service helps simplify authentication and authorization for your app.  Is the feature behavior different on Linux?   No. The authentication and authorization works the same way on Linux apps as Windows.  The configuration experience on Azure portal and CLI is exactly the same, if you’re familiar with how to configure a Windows app for this feature, you’re ready to go and can do the same for a Linux app.  I’m a Linux customer new to this feature, how do I configure it for my Linux app?   This how-to article shows you how to customize authentication and authorization in App Service, and to manage identity from your application.   To get started quickly, see one of the following tutorials:   How to configure your app to use Azure Active Directory login  How to configure your app to use Facebook login  How to configure your app to use Google login  How to configure your app to use Microsoft Account login  How to configure your app to use Twitter login       ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/07/App-Service-AuthenticationAuthorization-Coming-to-Linux-Apps.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service Diagnostics Comes to Functions, ASE, and More!",
        "excerpt":"      Jennifer Lee (MSFT)     5/7/2018 8:27:58 AM  Have you ever had issues with an unhealthy web app? Last year, we launched App Service Diagnostics, an intelligent and guided troubleshooting experience that points you and the right direction to diagnose and solve issues of your web app (without having to configuring anything special to enable this feature!). Since then, we’ve read all the feedback that you all have given, and have added new capabilities to make this feature even more robust and insightful, all without you have to configure anything special. New Tile Shortcuts for Management and Configuration  When you visit App Service Diagnostics (by clicking on Diagnose and solve problems in the left-hand menu), you will be greeted by Genie, who will point you in the right direction to start troubleshooting your issue. If you have some experience or know a little bit about the nature of the issue, you should select one of the tile shortcuts that match your problem category. We have now added parent problem categories, such as Availability and Performance, to help keep the tile shortcuts organized.  If you don’t know where to start, Genie will also allow you to run a health checkup, which will run several checks on our backend and intelligently highlight where you’re experiencing an issue.    Our newest tile shortcuts are in the Management and Configuration problem category. You can now validate your swap operations, use our \"Check Best Practices for Prod Apps\" tile shortcut to make sure that you're configuring everything optimally for production workloads, and even check if your autoscaling operation is running correctly. App Service Diagnostics is now live for…  Before, only web app users could get help from App Service Diagnostics. Today, we are excited to announce that you can now leverage App Service Diagnostics to diagnose and troubleshoot issues with not only your Windows web apps, but also your web apps on Linux, App Service Environment, and even Azure Functions.  For each service, we have tailored the troubleshooting problem categories to cater to the most common scenarios that customers have been looking to diagnose and troubleshoot. For example, for Functions, you can now identify scaling issues and analyze functions in error. For App Service Environment, we know that our customers have quite a few questions about networking, so we added a network security group verifier and also a tile shortcut to validate outbound connectivity from your ASE.  For Windows and Linux web apps, navigate to the App Service Portal. Click on Diagnose and solve problems on the left-hand menu.  For App Service Environments, navigate to the App Service Environment Portal. Click on Diagnose and solve problems on the left hand menu.   For Azure Functions, navigate to the Functions Portal. Click on the Platform Overview tab, and then click on Diagnose and solve problems under the Resource Management category.   New Diagnostic Tools  For our more advanced users who are familiar with troubleshooting web app issues, we released a new set of tile shortcuts under Diagnostic Tools (a new parent problem category). These Diagnostic Tools are stack specific and are here to help you dive deeper in investigating issues related to your application code, root causes for slowness, connection strings, and even issues with connecting to a remote server. As always, all of these tools have actionable documentation, which means not only do we tell you a little bit about what the tool does, but also allow you to perform that action right in App Service Diagnostics.   Click on Change Stack to view the Diagnostic Tools relevant to your stack of interest. Integration with Application Insights  Another insight that we’ve heard from our App Service Diagnostics users is about troubleshooting issues in their application code. To help with this beyond distinguishing between platform and application issues, we have integrated with Application Insights to provide code-level insights in context to availability downtimes. Application Insights is Azure’s application performance management and analytics tool that allows you to monitor your application.  Although you do need to configure Application Insights to enable it for your application, once you do, you will be able to see common exceptions that your app is throwing and dependencies that are causing issues under Web App Down and Web App Slow. These are all correlated to the downtimes that you’ve selected via the orange bar. Hopefully, you’ll be able to recognize your application code issues from the commonly occurring exceptions, but if not, we deep link into Application Insights for more context.    Next time you’re having issues with an unhealthy web app, App Service Environment, or Function, try out App Service Diagnostics to talk to Genie to get guidance on how to cure for your unhealthy web app. If you haven’t already, definitely leverage App Service Diagnostics to run a health checkup for piece-of-mind or drill-down to your specific issue that’s happening to your app.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/07/App-Service-Diagnostics-Comes-to-Functions,-ASE,-and-More!.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Introducing Restore from Snapshots (Preview)",
        "excerpt":"      Nick B. King     5/7/2018 10:54:00 AM  Azure App Service Snapshots now in public preview  Today we are announcing the public preview release of Azure App Service Snapshots. Snapshots are automatic periodic backups available for Premium SKU web apps. Snapshots are managed internally by Azure App Service and provide reliable, hassle-free backups of your web apps.  Snapshots contain both the contents of a web app and the web app configuration. At least 1 snapshot will be available every 6 hours for the past 30 days. Within the past 7 days, usually 1 snapshot will be available per hour. Accessing snapshots in the Azure Portal  Snapshots can be listed and restored in the Azure Portal from the Backups settings of the web app.   How to list snapshots  Azure CLI  az webapp config snapshot list -g &lt;resource group&gt; -n &lt;app name&gt; Azure Powershell  $snapshotRgName = &lt;resource group&gt; $snapshotAppName = &lt;app name&gt; $snapshotAppSlot = &lt;slot name&gt; Get-AzureRmWebAppSnapshot -ResourceGroupName $snapshotRgName -Name $snapshotAppName How to restore a snapshot  Snapshots can be restored to the original web app, a slot of the web app, or any other web app in the same App Service Plan. While the restore operation is in progress, the web app will be stopped. It is strongly recommended to restore snapshots to a new slot instead of overwriting an existing slot in order to prevent data loss if the restore operation is unsuccessful.  Snapshots contain both web app files and web app settings. You can choose to restore files only, or to restore the settings as well. All settings contained in regular backups are also contained in snapshots. However, some settings, like hostnames, certificates, and backup schedules, will not be restored with a snapshot. Azure CLI  Snapshot commands for Azure CLI are currently available as extensions. To install the extension, run az extension add -n webapp If the extension is already installed, update it with az extension update -n webapp Restore a snapshot from the production slot to a new slot named SnapshotSlot az webapp deployment slot create -g &lt;resource group&gt; -n &lt;name&gt; -s SnapshotSlot az webapp config snapshot list -g &lt;resource group&gt; -n &lt;app name&gt; az webapp config snapshot restore -g &lt;resource group&gt; -n &lt;name&gt; -t &lt;snapshot timestamp&gt; -s SnapshotSlot --restore-config --source-resource-group &lt;resource group&gt; --source-webapp-name &lt;name&gt; Azure Powershell  Snapshot cmdlets were added in Azure Powershell 6.0. Follow these instructions to update Azure Powershell if the snapshot cmdlets are not found.  https://docs.microsoft.com/en-us/powershell/azure/install-azurerm-ps?view=azurermps-6.0.0 Restore a snapshot from the production slot to a new slot named SnapshotSlot $snapshotRgName = &lt;resource group&gt; $snapshotAppName = &lt;app name&gt; $snapshotAppSlot = &lt;slot name&gt; $snapshots = Get-AzureRmWebAppSnapshot -ResourceGroupName $snapshotRgName -Name $snapshotAppName -Slot $snapshotAppSlot # Create a new slot for the restore operation - highly recommended to prevent data loss! $targetSlotName = \"SnapshotSlot\" New-AzureRmWebAppSlot -ResourceGroupName $snapshotRgName -Name $snapshotAppName -Slot $targetSlotName # Restore the first snapshot in the list to the new slot. Restore both the configuration and files. $snapshots[0] | Restore-AzureRmWebAppSnapshot -ResourceGroupName $snapshotRgName -Name $snapshotAppName -Slot $targetSlotName -RecoverConfiguration -Force Learn More  https://docs.microsoft.com/en-us/Azure/app-service/app-service-web-restore-snapshots     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/07/Introducing-Restore-from-Snapshots-(Preview).html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Multi-container Linux Web App",
        "excerpt":"      Yi Liao MSFT     5/7/2018 8:20:01 AM  The App Service team is happy to announce the public preview of Multi-container support in Web App for Containers. Multi-container Web App Concept  App Service Linux community has repeatedly asked for the capability to deploy multiple containers for a single App.  Customers want to have additional containers to complement the primary container and have these containers form an “operable” unit. The benefits for Multi-container are: 1. customer can separate capabilities such as proxies, cache and storage into additional containers and manage the source code and container images independently following the “separation of concerns” design pattern in containerization;  2. customer can operate those containers as an atomic unit and leverage App Service’s rich feature set for application life-cycle management, scaling and diagnosis, without the needs to stand up a container Orchestrator and to manage the hosting infrastructure by themselves.  Today we're happy to announce the public preview of Multi-container support in Web App for Containers! Primary Use Case  In App Service Linux community, the primary multi-container use case is that customer deploy a stateless web app with multiple containers (Web, Proxy, Cache or Git-mirror) to a single App Service plan.  For example: customer can have one container for web frontend and have another container for session cache using Redis, all deployed to the same App Service plan. All containers can communicate to each other through a Docker Bridge network using internal IP addresses. Supported Configurations   In Public Preview, we support Docker-Compose and Kubernetes configuration format as they’re the “standard” ways to describe multi-container applications. We don’t want to invent another format.  It’s also convenient for the customers because the formats are well documented and widely used by Docker community.  Customer can create or configure a Multi-container app from Azure Portal or through Azure CLI. Customer can describe a multi-container app using Docker Compose and Kubernetes configuration format in a yaml file. Customer can upload the multi-container config file through portal UI or point to the URL if the config file is hosted elsewhere (note: URL link support will come soon after announcement), portal screenshot as below.    For example, customer can use Docker-Compose format to describe a multi-container app: docker-compose.yml  version: '3' services: web: image: \"appsvcsample/flaskapp\" # this image repo's source code come from \"Get started with Docker Compose\" on docker.com ports: - \"80:80\" redis: image: \"redis:alpine\" CLI command to create a multi-container app: $ az webapp create --resource-group [resource group] --plan [service plan] --name [app name] --multicontainer-config-type \"compose\" --multicontainer-config-file [path to \"docker-compose.yml\"] CLI command to configure a multi-container app: $ az webapp config container set --resource-group [resource group] --name [app name] --multicontainer-config-type \"compose\" --multicontainer-config-file [path to \"docker-compose.yml\"] Customer can also use Kubernetes configuration format to describe a multi-container app: my-kube.yml  apiVersion: v1 kind: Pod metadata: name: python spec: containers: - name: web image: appsvcsample/flaskapp # this image repo's source code come from \"Get started with Docker Compose\" on docker.com ports: - containerPort: 80 - name: redis image: redis:alpine CLI command to create a multi-container app: $ az webapp create --resource-group [resource group] --plan [service plan] --name [app name] --multicontainer-config-type \"kube\" --multicontainer-config-file [path to \"my-kube.yml\"] CLI command to configure a multi-container app: $ az webapp config container set --resource-group [resource group] --name [app name] --multicontainer-config-type \"kube\" --multicontainer-config-file [path to \"my-kube.yml\"] Samples  We're working to add more Multi-container web app samples.  To get you started quickly, please feel free to copy the samples provided in this blog post, or download more from Github. Scaling Multi-container Web App  Customer can scale up and / or out a stateless multi-container app just as any web apps hosted on App Service, using the same scaling features provided by App Service.  If you would like to use a database in container for dev/testing purposes in a single-host app, please make sure to use the persisted shared storage to store your database files, so the database files can be persisted during app restarts. First, you should enable the App Service shared storage following the instructions at here. Then, you should mount the shared storage to a directory within the Docker container where you store the database files, a MySQL example in docker-compose.yml: services: mysql: image: mysql:5.7 volumes: - ${WEBAPP_STORAGE_HOME}/site:[/path/in/container/where/mysqlfiles/needs/to/be/mounted] If you would like to scale out a multi-container app to multiple hosts in an App Service plan and use the app for production purpose, we strongly recommend you use Azure Database services instead of putting the database in a container. For example, for a WordPress app you can move the database to an Azure Database for MySQL.  To do that, please follow the following steps:  Create a MySQL instance on Azure Database for MySQL servers. This can be easily done through Azure portal or CLI.  Make sure to configure MySQL server for SSL following the instructions at https://docs.microsoft.com/en-us/azure/mysql/howto-configure-ssl, and also make sure to enable client access to MySQL server by configuring MySQL firewall rules:  https://docs.microsoft.com/en-us/azure/mysql/concepts-firewall-rules. Modify your docker-compose.yml to use Azure MySQL instead of local MySQL server, for example, if you have a WordPress app connect to a MySQL database, you can pass the following environment variables in docker-compose.yml:  WORDPRESS_DB_HOST: [mysql server name].mysql.database.azure.com  WORDPRESS_DB_USER: [db user name]@[mysql server name]  WORDPRESS_DB_PASSWORD: [database password]  Test the configuration locally with docker-compose up before you push it to App Service.  Limitations in Public Preview  We wanted to put this feature out as soon as possible so customer can validate and provide more feedbacks during Preview. There are certain limitations in this Public Preview release.  We support Docker-Compose and Kubernetes format to describe a multi-container app, but we don’t support all their configuration objects during Public Preview. Our goal is to support any configuration objects that are meaningful to App Service during this release. The supported objects and limitations are as follows: Docker-Compose  Supported configuration in Public Preview:  services  A service definition contains configuration that is applied to each container started for that service, much like passing command-line parameters to docker container create.  image  Specify the image to start the container from. Can either be a repository/tag or a partial image ID.  ports  Expose ports by mapping ports in the HOST:CONTAINER pattern, recommend explicitly specifying your port mapping as string. App Service specific, we would only expose one service port to external, we would identify a single service port to expose to external based on the HOST port provided for each service, we're looking for port 80 or port 8080.  environment  Add environment variables. You can use an array as input. The dictionary format is not supported in current release, we will add support for dictionary format in next release. environment:  #supported RACK_ENV: development SHOW: 'true' SESSION_SECRET:  environment:  #not supported - RACK_ENV=development - SHOW=true - SESSION_SECRET volumes  Mount host paths or named volumes, specified as sub-options to a service. We support both persisted volume and non-persisted volume. To use the persisted volume, please enable the shared storage by set WEBSITES_ENABLE_APP_SERVICE_STORAGE=TRUE.  You can reference the shared storage using ${WEBAPP_STORAGE_HOME}.  For example, you can mount the shared storage to /tmp in the container: volumes: - ${WEBAPP_STORAGE_HOME}/site/wwwroot:/tmp command  Override the default command. Currently we support the collection format, for example: command: [\"bundle\", \"exec\", \"thin\", \"-p\", \"3000\"]. We will add support for a single string after public preview.  entrypoint  Override the default entrypoint.  restart  “no” is the default restart policy, and it does not restart a container under any circumstance. When “always” is specified, the container always restarts. More info at https://docs.docker.com/compose/compose-file/#restart.  Configuration not supported in Public Preview:  (besides the list below, any other Docker-Compose syntax not explicitly called out in the “Supported Configuration” section will not be supported in Public Preview)  build  Configuration options that are applied at build time. We don’t support “build” image locally as we need an explicit image to start the container with.  depends_on  Express dependency between services. we don’t currently support “depends_on” to specify the dependencies among containers, but we plan to support this shortly after Public Preview.  networks  Networks to join. We don’t support additional “networks” as we run all containers on one Bridge network.  secrets  Grant access to secrets on a per-service basis using the per-service secrets configuration. We don’t currently support it, but we plan to support this shortly after Public Preview. Kubernetes  Supported configuration in Public Preview:  spec  Spec schema is a description of a pod. It’s the parent level object for containers.  containers  A list of containers belonging to the pod.  name  The name of this pod. If it’s within a containers object, it’s the name for container.  image  Docker container image name.  command  The entrypoint array, override the default entrypoint provided by container image.  args  A command array containing arguments to the entrypoint. The docker image’s cmd is used if this is not provided.  ports  A list of ports to expose from the container.  Configuration not supported in Public Preview:  Any other Kubernetes syntax not explicitly called out in the “Supported Configuration” section will not be supported in Public Preview.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/07/Multi-container-Linux-Web-App.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "New SSH Experience and Remote Debugging for Linux Web Apps",
        "excerpt":"      Yi Liao MSFT     5/7/2018 8:27:27 AM  The App Service team is happy to announce the Public Preview of a new SSH experience and the remote debugging capability for Linux app developers. In this release, we're also enabling SFTP (Secure File Transfer Protocol) for Linux web app content management. What’s new?  We’re introducing a new TCP tunneling technology for Azure App Service, which enables SSH/SFTP access and remote debugging for Linux Web Apps.  We’re enabling Linux app developers to SSH into an app container using any SSH client at your choice. Previously we only enabled the SSH access through a Kudu web client. Based on Linux customer’s feedbacks, we’re adding support for any SSH clients to connect to app container.  We’re also enabling SFTP for managing web app content and downloading logs, in addition to the already supported FTP and FTPS protocols.  With the new remote debugging capability for Linux Web Apps, developers can now set break points in a code editor and live debug an web app running in App Service on Linux or Web App for Containers. We will publish additional blogs for know-how on remote debugging in the next several weeks. How do I configure my dev machine for SSH/SFTP and remote debugging?  We use TCP tunneling technology to create a network connection between your dev machine and App Service over an authenticated WebSocket connection. We included the TCP tunneling technology in Azure CLI.  First, make sure you have the latest Azure CLI installed. To enable the tunneling from your dev machine, you need to install Azure CLI \"webapp\" extension. If you install the extension for the first time, use this command: az extension add --name webapp. If you have an existing webapp extension, use this command to upgrade: az extension update --name webapp. Once the extension is installed, run the following CLI command to create a TCP tunnel to App Service: az webapp remote-connection create –g [resource group] -n [app name] -p [local port to open] The command line output on a Linux terminal will be something like this: Port [number] is open Tunnel is ready! Creating on port [number] Starting local server... Now, your dev machine is configured for any general purposed remote debugging and SSH/SFTP access for the web app as you specified in the remote-connection create command.  Please note: in the Public Preview, for a given app we only support a single TCP tunnel at any given time. We plan to remove this limitation in future releases after Public Preview.  How do I SSH into app container from a Linux terminal?  First, please make sure your web app is enabled for SSH. If you use App Service on Linux (blessed images), the SSH is enabled by default. If you use Web App for Containers (custom images), please follow the instructions here to enable SSH access in app container.  Tips for SSH to work correctly in your container:  Make sure you remember the pre-defined SSH password that is set in your Dockerfile. We recommend that you install SSH server and set the user/password in Dockerfile as follows:   # ------------------------ # SSH Server support # ------------------------ RUN apt-get update \\ &amp;&amp; apt-get install -y --no-install-recommends openssh-server \\ &amp;&amp; echo \"root:Docker!\" | chpasswd   Please remember to start the SSH service in your container startup script.  Second, make sure you create a TCP tunnel to the remote web app, if not, please run the CLI command provided in “configure my dev machine” section.  Once the TCP tunnel is established, you can simply run the following command in Linux terminal: $ ssh root@127.0.0.1 -p [local port created for TCP tunnel] Similarly, you can SSH to app container from a Mac or Windows machine.  Now, you can go party with SSH! How do I use SFTP to manage web app content?   Like SSH, please make sure your app container is enabled for SSH access, refer to the SSH section above for instructions. And run the same remote-connection create command to establish a TCP tunnel.  If you don’t have one, install a SFTP client such as WinSCP, connect the client to localhost at 127.0.0.1 and a port number that is created for TCP tunnel, use the SSH user name and password to login. Now you can manage the site content stored in /home/site/wwwroot using the SFTP client.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/07/New-SSH-Experience-and-Remote-Debugging-for-Linux-Web-Apps.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Revised Scaling Experience for Standard and Premium",
        "excerpt":"      Byron Tardif     5/7/2018 2:11:01 PM  The App Service team is delighted to announce a revised scaling experience between Basic, Standard, and Premium App Service plans that will make it easier for customers to scale up to more performant VMs at the same price point.  Central to this announcement is a 20% price reduction for Pv2 App Service plans.  This change makes the P1v2 App Service plan the same price as the current S2 App Service plan, making it possible for customers to scale directly from S2 to P1v2. Giving them a more performant Dv2 based instance with 2X memory and an SSD drive at the same price as the S2 offering.  With the 20% Premium V2 price reduction we also have a new scaling experience which highlights the ability to move directly from S2 to P1v2. Pricing tiers are now grouped by their target workload into Dev/Test, Production, and Isolated with recommended scale guidance provided.  Dev/Test includes the Free, Shared and Basic App Service plan options Production includes Standard, Premium and Premium v2 Isolated includes the scale options for App Service plans hosted in an App Service environment.    If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/07/Revised-Scaling-Experience-for-Standard-and-Premium.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Web Apps making changes to FTP deployments",
        "excerpt":"      Thad Kittelson     5/8/2018 10:19:42 AM  We are continuously taking steps to improve Azure Platform security. As part of this ongoing effort an upgrade of App Service is planned for all regions during the first part of May. Changes to deployment options  When this upgrade is complete Web Apps will provide the following configurations with the option to change your default setting.  Today your apps can be accessed through the legacy FTP protocol (using credentials over plain text) as well as the more secure FTPS protocol (not to be confused with SFTP). Once the upgrade is complete you will be able to configure your apps to continue to use FTP and FTPS, limit access only over FTPS or completely disable FTP access.       You can find these options in the Azure Portal under your app's menu: Application Settings &gt; FTP Access Whats next  In early July all new apps will default to FTPS only access. Users will continue to have the option to configure this as needed. Any previously created apps will retain their existing FTP/FTPS configuration with the option to change as needed. Best practice  As a best practice we recommend using FTPS for deployments. Doing so will ensure that your data transmissions are encrypted which helps address regulatory guidelines for security.  If you have any questions about this feature or App Service in general be sure to check our forums in MSDN and Stack Overflow. For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/08/Web-Apps-making-changes-to-FTP-deployments.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP Minor Version Update for June 2018",
        "excerpt":"      Jennifer Lee (MSFT)     5/11/2018 1:30:57 PM  Latest version updates to PHP  In June 2018, Azure App Service will update the PHP stacks to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.    PHP Version Change Log   5.6.36 http://www.php.net/ChangeLog-5.php#5.6.36   7.0.30 http://www.php.net/ChangeLog-7.php#7.0.30   7.1.17 http://www.php.net/ChangeLog-7.php#7.1.17   7.2.5 http://www.php.net/ChangeLog-7.php#7.2.5        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/11/PHP-Minor-Version-Update-for-June-2018.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "April 2018 App Service update",
        "excerpt":"      Byron Tardif     5/13/2018 10:16:06 AM  Kubernetes and Docker Compose come to App Service  Now you can bring your Kubernetes Pod Definitions or Docker Compose files to App Service and run multi container solutions in a fully managed PaaS solution with all the App Service features and ease of use you are already familiar with. Learn more about these scenarios in our announcement blog.  Linux and Docker on App Service Environments  You can now create Linux and Docker apps in your App Service Environment to take advantage of the advanced scaling and networking features. Learn more in the announcement blog. New App Service plan options for Linux and Docker on App Service  Now you can get started with Linux and Docker on App Service with a free B1 App Service plan for 30 days.   As well as access to the more powerful and cost effective PV2 Instances for production workloads.   App Service Authentication/Authorization for Linux Apps  You can now enable Authentication/Authorization on your Linux App Service Apps just as easy as you do for Windows hosted apps. Learn more in our announcement blog. Docker Logs in portal  You can now access your Docker logs directly form the portal under Container Settings.  Azure Functions on Linux and Docker  Earlier in the year we started the preview of Azure Functions on Linux, we are now extending this by including Docker as another hosting option.  New Functions Monitoring powered by Application Insights  Application Insights is the preferred monitoring solution for Azure Functions and we have made enabling it super easy.  TLS configuration  You can now define the minimum TLS version for your apps. You can find this setting under SSL Settings. This feature applies to Windows, Linux and Docker Web apps, Mobile apps and API apps as well as Azure Functions. Learn more in our announcement blog.  Fine grain FTP configuration  You can now configure FTP to enforce connections over FTPS or disable this publishing endpoint completely. This feature applies to Windows, Linux and Docker Web apps, Mobile apps and API apps as well as Azure Functions. Learn more in our announcement blog.      Snapshots: a new way to back up your App  Snapshots is a new premium feature for backing up the content of your app. You can find it under Backup in the left menu. Learn more in our announcement blog.  New pricing options and scale up experience  We have revised the pricing for App Service instances and re-vamped the experience to provide more information and make it easier to choose the right size for your app. Read more in our announcement blog.  App Settings now sorted alphabetically  This feature was one of the top 10 most requested features in our UserVoice forum and we are happy to deliver.      If you have any questions about any of this features or App Service in general be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice Previous updates:   March 2018 App Service update January 2018 App Service Update November 2017 App Service Update October 2017 App Service Update      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/13/April-2018-App-Service-update.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure App Service on Azure Stack Update Two Released",
        "excerpt":"      Andrew Westgarth     5/18/2018 10:00:43 AM  This morning we released the second update to Azure App Service on Azure Stack.  This release updates the resource provider and brings the following key capabilities:  Auto Swap of deployment slots feature is now enabled - Configuring Auto Swap Testing in Production feature enabled - Introduction to Testing in Production Azure Functions Proxies enabled - Work with Azure Functions Proxies App Service Admin extensions UX support added to enable:  Secret rotation Certificate rotation System credential rotation Connection string rotation   Updates to App Service Tenant, Admin, Functions portal and Kudu tools. Updates to .Net Core support, additional versions of NodeJS and NPM All other fixes and updates detailed in the App Service on Azure Stack Update Two Release Notes   You can download the new installer and helper scripts:  Installer – https://aka.ms/appsvcupdate2installer Helper Scripts – https://aka.ms/appsvconmashelpers  Please read the updated documentation prior to getting started with deployment:  Before you get started with App Service on Azure Stack Deploy the App Service Resource Provider for new deployments Update the App Service Resource Provider for updating existing deployments      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/05/18/Azure-App-Service-on-Azure-Stack-Update-Two-Released.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service Deployment Center (Preview)",
        "excerpt":"      Byron Tardif     6/4/2018 5:12:14 PM     We are happy to announce a new preview experience for setting up deployments to Azure App Service.  Deployment Center is a centralized overview for all of the deployment options available to you. It also provides a guided experience to set up your deployments.  With the new UX you can now search and filter through your repositories and branches making navigation through large code repositories easier.    We have also revamped the access to log files making them easier to find and consume.    Other improvements include:  Link back to source repository (as requested in our Uservoice) Displaying the branch information (as requested in our Uservoice) Information about the Commit ID and Author Surfacing the Check-in message  All of these improvements are geared to help developers understand what version of their code is currently deployed in their app.    Deployment credential management is now contextualized to your deployment provider/method of choice.  It is now easier to set and re-set credentials from the deployment center without having to visit another UI or abandon the flow.   Preview Limitations   This preview is currently available for Windows hosted apps and we plan to extend this to Linux and Functions in the coming months. You must be part of the Owner role in the subscription to use this feature, we plan to remove this limitation in future releases.  If you find any issues with the preview you can report a bug here  For any questions about any of this features or App Service be sure to check our forums in MSDN and Stack Overflow.  For any feature requests or ideas check out our User Voice     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/06/04/App-Service-Deployment-Center-(Preview).html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service Diagnostics – Profiling an ASP.NET Web App on Azure App Service",
        "excerpt":"      PuneetG     6/6/2018 12:47:44 AM  The Diagnostic Tools options under the Diagnose and Solve blade for Azure App Services has been live for a few months now and has many tools that help you troubleshoot apps based on their application stack. In this post, we are going to cover the Collect .NET Profiler Trace option in detail and how you can use it to troubleshoot a slow or a failing ASP.NET based Web App.    Profiler tool helps in collecting an on-demand trace that lets you identify the underlying .NET exceptions, time taken in the various request processing pipeline stages and even lets you drill down into exact methods within the application code that are taking time. It is extremely useful in situations where the problem is happening right now and you want to collect some data to identify the root cause of the issue. Profiling is designed for production scenarios and is based on ETW (Event tracing for Windows) . The analysis component of the profiler uses the TraceEvent library to generate a report that helps you drill down in to the problems in matter of a few minutes. It should be noted that no changes are made to your Web App code or your configuration during the collection or the analysis phase. In fact, the web app is not even restarted as a result of capturing this trace. The captured trace has ETW events emitted by the IIS and the ASP.NET providers along with stack traces captured at the CPU level. You can use this tool to efficiently troubleshoot delays which are relatively small (less than a second too) without impacting the run-time performance of the application. At this point, the profiler works only for ASP.NET web apps only and ASP.NET Core support might come soon. How to Collect the Trace  To collect the trace, go to Diagnose and Solve Problems and choose the Collect .NET Profiler Trace option under Diagnostic Tools option and click on Collect Profiler Trace. Unless you have isolated that only a specific instance is failing, it is best to just select all the instances on which your Web App is running.   Add thread report option - With this option enabled, a thread report of all the threads in the process is also collected at the end of the profiler trace. This is useful especially if you are troubleshooting totally hung processes, deadlocks or requests taking more than 60 seconds. This will pause your process for a few seconds until the thread dump is generated. This option is NOT recommended if you are experiencing high CPU on the instance because if the instance is under stress, it might take a long time to even start a new process to collect the thread dumps.  Clicking the Collect Profiler Trace will start profiling the Web App and the wizard will show progress of various steps involved.    Once the profiler trace is started, reproduce the issue by browsing the Web App. If you have a Web App running on multiple instances, make sure to browse a few more times to ensure that the requests to the web app get captured in the profiler trace. The default duration for which the profiler trace runs is 60 seconds and during this 60 seconds, all the requests that were made to the Web App get captured in the profiler trace. It is important to note that the profiler trace only has information about the requests that were captured in these 60 seconds (It is possible to increase this duration as mentioned below in this article)  After 60 seconds, the profiler automatically stops, and an analysis component gets triggered that starts analyzing the profiler trace that just got captured. After the analysis finishes, a link to view the profiler report for every instance serving the web app is generated and you click on the Open Report button to view the Analysis report.   Understanding the Analysis Report  The analysis report provides some basic information about the number of requests captured, successful and failed requests, CPU usage of the instance, CPU usage of the web app and request execution information that helps you identify how fast your Web App was responding when the trace was getting captured. This can be used to validate if the trace is useful and if the right set of requests got captured in the trace and if the cause of slowness is related to high CPU on the instance serving the web app or not. The trace file section also has a link to download the trace file.    For troubleshooting slow or slow or hung web applications, click on Slow Requests tab. This view shows you the top 100 slowest requests that got captured in the trace. It also breaks down the time spent in various modules of request execution in IIS and tries to categorize them in to Platform, Network and Application code to give you a quick indication on where the problem might be.    Application Code - represents the time spent in handlers or modules that get invoked either while executing application code (for e.g ManagedPipelineHandler) or those that are closely related to any explicit configuration done for the application (for e.g. RewriteModule). Any external or third party handlers, modules fall in this category. Anything which does not fall in the native IIS handlers or modules is classified as Application. Network - represents the time spent in reading the request entity body from the client or time spent in flushing the response buffer back to the client. Time spent in waiting on external outbound network calls made from the application (like Database, cache, external HTTP requests etc.) is not counted here and is grouped under Application Code. If requests are spending a lot of time in this category, then it means that there is either a network issue between the client and the web app, the network might be slow or the request and response body is big. Platform - represents the time a request spends in core native modules or handlers of IIS which are pre-installed in Azure App Service (for e.g. DefautlDocumentModule, StaticFileHandler etc.). A request spending too much time in these modules might indicate an overall platform issue so you can contact Microsoft Support to get more details.  The chart also plots the Top 5 handlers or modules in the IIS processing pipeline where the requests spent most of their time and this can give a quick indication as to where the problem might be. In the above example, we see that 83% of the time was spent in PageLoad and 15% of the time was spent waiting in the CLR thread pool queue waiting for the request to be picked up and assigned to a thread pool thread.  In the same section, if you scroll below, you find a list of Top 100 Slow requests with the time taken in request execution and the slowest module for these requests. Note that stack traces will be captured if the request execution delay is on the same thread or if the application code uses Tasks class (from System.Net.Threading) to perform asynchronous IO in the request. There are lot of ways in .NET Framework to achieve asynchronous execution behavior and not all of them can be tracked so it is possible that for those scenarios, there are no stack traces captured for the request. Even for those scenarios, at least the Module name should help in identifying where the delay might be happening and is good indication of where the problem lies.    So the above information tells us that the slowest request in this trace took around 30 seconds and 99.79% of the time was spent in the the Page_Load event of ASP.NET which tells us that something in the Page_Load caused the request to slow down hence narrowing the issue down to Application Code.  The Profiler tries its best to correlate the stack trace of thread to the slow requests and if it manages to find this information, a light bulb icon is displayed next to the Details view to illustrate that there are stack traces captured for this request. You can click on the Details button to get the stack trace captured. Stack Traces - Thread View  For a request, the Thread View is shown for requests where the profiler is able to determine that the request execution happened on the same thread and where the delay in request processing happened on the same very thread. It is however possible that the thread view is shown even for ASYNC requests if the .NET Task Scheduler decides to run them on the same thread. It is best advised to look at both the Thread View and Activity view for requests that executed on the same thread to get an idea of methods taking the longest time because at times one view may have more accurate information than the other and might help you go one more step closer to the code that is introducing the delay.    The stack trace helps us identify the delay is happening while trying to open a SqlConnection from a page named SlowSql.aspx and the function name is demomvp.SlowSql.Page_Load. There is also a toggle button for showing the full .NET Framework stack which shows time spent in all the functions that got executed on this thread and at times is helpful if you want to drill down further within the .NET Framework code to identify methods where time is being spent.  Profiler is able to show the stack traces accurately for requests that have completed in the trace. For requests that started in the trace and have not finished before the trace is stopped, the profiler tries its best to show the time taken but it may not be 100% accurate. Incomplete requests would have a warning icon next to the slow request report and it is suggested to look all the complete requests in the trace to get a better picture of request execution. Stack Traces - Activity View  If the request has switched multiple threads, you will notice an icon next to the list of requests in the slow request report indicating the request is an async request.    For asynchronous requests, the profiler report shows you the Activity View and the thread view is not shown. Activity view groups method execution by the activity information which is passed by CLR when using Tasks and the profiler groups similar tasks originating with the same Activity Id and stitches them together to show you this view. Here is an example of an asynchronous request's activity view.    In the above stack trace, we can see that the method demomvp.AsyncThreadDelaySleep.WaitForSomeTime invoked a new Delay Task and spent 8 seconds awaiting on it. As you can see, by the nature of asynchronous execution, understanding ASYNC tasks is slightly more trickier than synchronous threads but still the profiler report has grouped the right functions together by grouping .NET Activity. To know more about .NET Activities and how they are flown, check out this detailed post - https://blogs.msdn.microsoft.com/vancem/2015/09/14/exploring-eventsource-activity-correlation-and-causation-features/ Failed Requests  For requests, that failed with a HTTP error, the Failed Requests view highlights the HTTP Module or the handler that was responsible for setting the error status code. Clicking on Details will show more information about the failure and will highlight the underlying exception for the request. The profiler tries its best to correlate a request with an exception, however if a request has switched multiple threads (either due to multiple tasks or due to different threading primitives), then the profiler may not be able to correlate the exception with the request.   .NET Exceptions View  This view shows all .NET exceptions that happened in the process during the trace. The difference in this view vs. the Failed Requests view is that this can include all the exceptions that might have happened on background threads , IO threads or on threads that could not be associated to a request directly. CPU Stacks  If the process traced also consumed high CPU, then the profiler report would also show you the call-stack of the thread that consumed the maximum CPU and this should help in identifying the function that need to be optimized.       In the above example, we can see that there is a ProfilerClassTest.CalculateDiscounts method is taking 4 seconds on the CPU Increasing the duration for the Profiler Trace  It is possible to increase the default profiling duration by setting an application setting IIS_PROFILING_TIMEOUT_IN_SECONDS with a maximum value of 900 (i.e. 15 minutes). If you configure this application setting to a number more than 900, it defaults to the 60 second value. How to Analyze the trace further ?  If the profiler report is not able to identify the issue easily, you can use the PerfView tool or Visual Studio to analyze the trace . The trace file generated by the profiler is a *.diagsession file that is supported by these tools. The link to download the trace file is also present in the analysis report in the top section.  We hope this tool helps you identify issues in production easily and lets you optimize your code to better serve your Web Apps.  Happy Debugging !!!     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/06/06/App-Service-Diagnostics-Profiling-an-ASP.NET-Web-App-on-Azure-App-Service.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "TLS Configuration now fixed to block 1.0",
        "excerpt":"      Oded Dvoskin     6/13/2018 8:57:33 AM  We recently announced that all App Service and Functions apps could update TLS configuration. However, after deployment, an edge case scenario was identified involving SNI-SSL which led to SSL analyzing tools such as SSL Labs, showing that TLS 1.0 was still accepted, while higher versions were selected.  We have now completed the deployment which solves the issue for SSI-SSL and will also translate to the reporting tool indicating correctly that lower versions of TLS, mainly TLS 1.0, are indeed blocked.    To update your TLS configuration, follow one of the methods below:  In the Azure Portal, in the app's menu, browse to SSL Settings option and select which version of SSL you require.    Through CLI, details for the commands are in our documentation.  az webapp config set --name                      [--min-tls-version]    For any questions, please reach out over the App Service MSDN forum.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/06/13/TLS-Configuration-now-fixed-to-block-1.0.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing General Availability and Sovereign Cloud Support of Managed Service Identity for App Service and Azure Functions",
        "excerpt":"      Matthew Henderson - MSFT     6/26/2018 8:00:10 AM  Securing access between resources is an important part of modern cloud architectures, and we want to make that as simple as possible in Azure. Managed Service Identity (MSI) lets you securely connect to AAD-protected resources without needing to manage or rotate any secrets. If you need to work with a service that doesn't support AAD, MSI makes it easy to work with Azure Key Vault for secure secret management. This gives you secure access to resources without your application needing any bootstrapping secrets.  Today, we are pleased to announce that App Service and Azure Functions support of MSI is now generally available! We are also lighting up support in Azure China, Azure Germany, and Azure Government. Users in those sovereign clouds can get started with the APIs today, and updates to the portal, CLI, and PowerShell for those environments will become available over the next few weeks.  You can get started using MSI today using any app in App Service and Azure Functions by checking out our documentation. Be sure to also check out the new preview support in Visual Studio for using Key Vault with Connected Services. While Key Vault is the most common use case, MSI has also proven a powerful tool for automation tasks, allowing you to easily start working with Azure Resource Manager APIs. You can also connect directly to a variety of services including Azure SQL and Azure Service Bus.  Please note that App Service on Linux and Web App for Containers do not yet support MSI. We are working on this and look forward to giving Linux users the same great turnkey identity story soon.  UX behavior change  If you used the feature during preview, you may have noticed that turning MSI off in the portal, CLI, or PowerShell actually just set an app setting: WEBSITE_DISABLE_MSI. This app setting disables the local token service but does not remove the identity itself. Going forward, the \"off\" indication will change the identity type to \"None\" which will also remove the identity from AAD. The WEBSITE_DISABLE_MSI app setting will no longer be affected by the enablement/disablement behaviors. We encourage users to move away from this setting if possible, as your site will now show MSI as \"on\" even if this setting is present. CLI and PowerShell commands will be updated in the coming weeks to remove the preview tag and reflect this behavior change.  Try it out!  We're very excited to make our MSI support generally available. It's an extremely powerful tool that dramatically simplifies connecting your application to other resources. Give it a try, and please be sure to share your feedback. As always, you can reach us in the Forums (App Service, Functions) or on UserVoice (App Service, Functions).     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/06/26/Announcing-General-Availability-and-Sovereign-Cloud-Support-of-Managed-Service-Identity-for-App-Service-and-Azure-Functions.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Function Proxies now Available in Functions Version 2.x!",
        "excerpt":"      Alex Karcher     6/26/2018 9:00:13 AM  I'm very excited to announce the availability of Function Proxies in Functions Version 2.x! Function Proxies enable multiple HTTP Functions to be composited together, mock APIs and single page apps to be hosted in Functions, and HTTP requests to be modified in transit. All that functionality is now available alongside Java Functions, .NET Core Functions, and any other 2.x workloads! To learn about all the differences and improvements with 2.x going forward, check out our docs Run Proxies on MacOS and Linux!  2.x support enables cross platform local execution of Proxies across Mac, Linux, and Windows!  To learn more about Proxies check out the getting started docs! To run Proxies locally you'll need the 2.x runtime, with instructions here Make feature requests and file issues on our github page.           ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/06/26/Function-Proxies-now-Available-in-Functions-Version-2.x!.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "How to use Azure Container Registry for a Multi-container Web App",
        "excerpt":"      Yi Liao MSFT     6/27/2018 12:10:43 PM  Back in May at Microsoft Build, we announced the public preview of Multi-Container Web App, which supports the ability for you to deploy multiple Docker images to Web App for Containers.  All you have to do is bring your Docker Compose or Kubernetes Config file when creating a new web app.  (Here are instructions to get started with Multi-Container Web App).  Since we launched public preview, one of the most frequently asked questions that we've received is: \"How do I configure Azure Container Registry with Multi-Container?\"  Let me walk you through a quick tutorial that uses Azure Container Registry with Multi-Container. Configure Your Docker Compose/Kubernetes File  To create a Multi-Container web app, you first need a Docker Compose or Kubernetes Config yml file. This is basically a definition file that describes a Multi-Container web app. Because we will be using Azure Container Registry (ACR), notice that the Docker Compose file has the ACR image repos in the file. The image with \"ports: - 80:80\" is the main container that exposed to Internet.  Here is a sample Docker Compose file: version: '3'  services:  web:  image: [azure-container-registry-name].azurecr.io/flaskapp  ports:  – 80:80  redis:  image: [azure-container-registry-name].azurecr.io/redis:alpine If this Docker Compose file looks familiar, it is actually the same as the Docker Compose file in the Quickstart that you can use when creating a Multi-Container app (with DockerHub), with the exception of the ACR modifications.   Adding the App Settings  After you uploaded your Docker Compose file and clicked create, you will have to make sure App Service can access Azure Container Registry by adding the following App settings in the App Service portal:  DOCKER_REGISTRY_SERVER_USERNAME = [azure-container-registry-name]  DOCKER_REGISTRY_SERVER_URL = [azure-container-registry-name].azurecr.io  DOCKER_REGISTRY_SERVER_PASSWORD = [password] Note: please make sure to enable admin access in the Azure Container Registry Server settings. Limitations  All Docker images in the same Docker Compose or Kubernetes Config yml file need to come from the same Azure Container Registry server. This means that you may have to pull down popular images (such as nginx and Redis) from DockerHub, and tag it for ACR then push to your ACR registry server.  Further limitations on Docker Compose/Kube Config configuration options are documented here. Checking Your Logs  After the web app is restarted, you should see logs similar to the ones below in Container settings or in Kudu. (Kudu is where you can view all your Docker logs and is your source control management site. Kudu can be accessed via [your web app name].SCM.azurewebsites.net or under \"Advanced Tools\" in the left-hand menu). 2018-06-19 19:26:33.419 ERROR – multi-container unit was not started successfully 2018-06-19 19:26:33.422 INFO  – Container logs from yili-multicontainer-acr-01_web_0 = 2018-06-19 19:29:42.691 INFO  – Starting multi-container app, configuration = version: '3'  services: # this image repo’s source come from “Get started with Docker Compose” on docker.com web: image: [azure-container-registry-name].azurecr.io/flaskapp ports: – 80:80  redis: image: [azure-container-registry-name].azurecr.io/redis:alpine 2018-06-19 19:30:14.621 INFO  – Starting container for site 2018-06-19 19:30:14.622 INFO  – docker run -d -p 55955:80 –name yili-multicontainer-acr-01_web_0 -e WEBSITE_SITE_NAME=yili-multicontainer-acr-01 -e WEBSITE_AUTH_ENABLED=False -e WEBSITE_ROLE_INSTANCE_ID=0 -e WEBSITE_INSTANCE_ID=6cc2f742b7330fbd63a5e79967ed9ee7904bb9d93c7ca7843312788a4c2bc622 yiliacr05.azurecr.io/flaskapp 2018-06-19 19:30:14.622 INFO  – Logging is not enabled for this container. Please use https://aka.ms/linux-diagnostics to enable logging to see container logs here. 2018-06-19 19:30:22.542 INFO  – Starting container for site 2018-06-19 19:30:22.543 INFO  – docker run -d -p 0:6379 –name yili-multicontainer-acr-01_redis_0 -e WEBSITE_SITE_NAME=yili-multicontainer-acr-01 -e WEBSITE_AUTH_ENABLED=False -e WEBSITE_ROLE_INSTANCE_ID=0 -e WEBSITE_INSTANCE_ID=6cc2f742b7330fbd63a5e79967ed9ee7904bb9d93c7ca7843312788a4c2bc622 yiliacr05.azurecr.io/redis:alpine 2018-06-19 19:30:22.544 INFO  – Logging is not enabled for this container. Please use https://aka.ms/linux-diagnostics to enable logging to see container logs here. 2018-06-19 19:30:30.750 INFO  – Started multi-container app 2018-06-19 19:30:30.778 INFO  – Container yili-multicontainer-acr-01_web_0 for site yili-multicontainer-acr-01 initialized successfully.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/06/27/How-to-use-Azure-Container-Registry-for-a-Multi-container-Web-App.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP Minor Version + Xdebug Update for August 2018",
        "excerpt":"      Jennifer Lee (MSFT)     7/12/2018 10:10:50 AM  Latest version updates to PHP  In August 2018, Azure App Service will update the PHP stacks to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.    PHP Version Change log   7.1.19 http://www.php.net/ChangeLog-7.php#7.1.19   7.2.7 http://www.php.net/ChangeLog-7.php#7.2.7       Additionally, the Xdebug binaries will be updated.  This includes adding Xdebug support for PHP 7.1 and 7.2.    PHP Version Xdebug path   5.6 D:\\devtools\\xdebug\\2.5.5\\php_5.6\\php_xdebug-2.5.5-5.6-vc11-nts.dll   7.0 x86 D:\\devtools\\xdebug\\2.6.0\\php_7.0\\php_xdebug-2.6.0-7.0-vc14-nts.dll   7.0 x64 D:\\devtools\\xdebug\\2.6.0\\php_7.0\\php_xdebug-2.6.0-7.0-vc14-nts-x86_64.dll   7.1 x86 (new) D:\\devtools\\xdebug\\2.6.0\\php_7.1\\php_xdebug-2.6.0-7.1-vc14-nts.dll   7.1 x64 (new) D:\\devtools\\xdebug\\2.6.0\\php_7.1\\php_xdebug-2.6.0-7.1-vc14-nts-x86_64.dll   7.2 x86 (new) D:\\devtools\\xdebug\\2.6.0\\php_7.2\\php_xdebug-2.6.0-7.2-vc15-nts.dll   7.2 x64 (new) D:\\devtools\\xdebug\\2.6.0\\php_7.2\\php_xdebug-2.6.0-7.2-vc15-nts-x86_64.dll       Please note that the paths for the xdebug.dll will be changing to the paths in the chart above. This means that the old Xdebug paths will be removed. These old paths include:    Xdebug path being removed   D:\\devtools\\xdebug\\2.4.0\\php_5.4\\php_xdebug-2.4.0-5.4-vc9-nts.dll   D:\\devtools\\xdebug\\2.4.0\\php_5.5\\php_xdebug-2.4.0-5.5-vc11-nts.dll   D:\\devtools\\xdebug\\2.4.0\\php_5.6\\php_xdebug-2.4.0-5.6-vc11-nts.dll   D:\\devtools\\xdebug\\2.4.0\\php_7.0\\php_xdebug-2.4.0-7.0-vc14-nts-x86_64.dll   D:\\devtools\\xdebug\\2.4.0\\php_7.0\\php_xdebug-2.4.0-7.0-vc14-nts.dll    See the Xdebug blog post for more information on how to use Xdebug for PHP.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/07/12/PHP-Minor-Version-+-Xdebug-Update-for-August-2018.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing Linux on App Service Environment General Availability",
        "excerpt":"      Jennifer Lee (MSFT)     7/30/2018 10:00:16 AM  Interested in deploying your Linux or containerized web app in an Azure Virtual Network? Today, we are excited to announce the general availability of Linux on App Service Environment, which combines the features from App Service on Linux and App Service Environment. As we announced in our public preview, our Linux customers will be able to take advantage of deploying Linux and containerized apps in an App Service Environment, which is ideal for deploying applications into a VNet for secure network access or apps running at a high scale. What can I do with Linux on ASE?   With Linux on ASE, you can deploy your Linux web applications into an Azure virtual network (VNet), by bringing your own custom container or just bring your code by using one of our built-in images.  If you want bring your own custom Docker container, you can bring your image from:  DockerHub Azure Container Registry Your own private registry   If you want to use one of our built-in images, we support many popular stacks, such as:  Node PHP Java .NET Core And more to come    Additionally, both Windows, Linux, and containerized web applications can be deployed into the same ASE, sharing the same VNet. Remember that even though Windows and Linux web apps can be in the same App Service Environment, Windows and Linux web apps have to be in separate App Service Plans. With Linux on ASE, you will be using the Isolated SKU with Dv2 VMs and additional scaling capabilities (up to 100 total App Service plan instances, between Windows and Linux, in one ASE).   Depending on whether you want an internet accessible endpoint, there are two different kinds of ASEs that you can create:  An external ASE with an internet accessible endpoint or, An internal ASE with a private IP address in the VNet with an internal load balancer (ILB).  The consideration here is what kind of IP do you want to expose your apps hosted in your ASE. Steps to get started are provided here. More context about how to configure networking for your ASE can be found here.  Pricing Changes from Preview  Linux and containerized apps deployed in an App Service Environment will return to regular App Service on Linux and App Service Environment pricing, as the 50% discount on the Linux App Service Plan from public preview is removed for GA. New Regions Added  Since public preview, we have now expanded Linux on ASE to all App Service on Linux’s 20+ regions, which include:    Australia East Australia Southeast Brazil South Canada Central Canada East Central India Central US East Asia East US     East US 2 Japan East Japan West Korea Central Korea South North Central US North Europe South Central US South India     Southeast Asia UK South UK West West Central US West Europe West India West US West US 2      How to Get Started  You can create a Linux web app into a new ASE by simply creating a new web app and selecting Linux as the OS (built-in image), selecting Docker (custom container), or creating a new Web App for Containers (custom container). When creating a new App Service Plan, remember to select one of the Isolated SKUs.   If you need more detailed instructions, get started with creating your first Linux/containerized web app into an ASE by following these instructions.  We’d love to hear what you think! Please leave your feedback on Linux on ASE here. Frequently Asked Questions (FAQ)  Q: Especially for those new to App Service Environment, how long will everything take to deploy?  A: Because an ASE gives you a fully isolated and dedicated environment for securely running App Service apps at high scale, there are many different parts that we provision for you upon creating a web app in an ASE. Instead of sharing front ends, you will have dedicated front ends that are responsible for HTTP/HTTPS termination and automatic load balancing of app requests within the ASE.  Therefore, when deploying a web app into an ASE or performing a scaling operation, the operation can take a couple of hours or more. This is not a promised SLA. We recommend that you schedule your scaling operations to account for the time it takes for any extended scaling processes. Improving scaling and deployment time for apps in an ASE is definitely a top priority item for our team to improve on.  Q: What should I keep in mind if I want to lock down my ASE with NSG and routing rules?  A: Using an App Service Environment is a great use case for controlling network access and locking down access to your applications. This can be done using:  Network Security Groups (NSGs), where you can set inbound and outbound security rules Routes, where you can control the outbound traffic to not go directly to the internet (such as an ExpressRoute gateway or a virtual appliance)  This is done at the ASE level, and not the app level, which is important to keep in mind (because in the App Service portal, there is an option on the left-hand menu named “Networking” that is grayed out for Linux and container apps. This is unrelated to controlling your network access via NSGs and routes).  Additionally, for ASE management purposes, there are some domains and IPs of network resources that the ASE requires to function. For Windows-only ASEs, these are documented here and also are surfaced in the ASE Portal. In additional to these inbound and outbound access dependencies, Linux/containers has other dependencies, such as:  docker.io ubuntu.com docker.com treasuredata.com mono-project.com  Q: Can I deploy a Multi-Container app with Docker Compose/Kubernetes Config in an ASE?  A: You can deploy a Multi-Container app in an ASE, but the Multi-Container offering on App Service on Linux is still in preview. Learn more about how to deploy a Multi-Container app here. Q: Can I deploy a Function app in a container in an ASE?  A: You can deploy a Function app in a container in an ASE, but the Function on Linux feature is still in preview. Learn more about how to deploy a Functions on Linux app here.           ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/07/30/Announcing-Linux-on-App-Service-Environment-General-Availability.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP Minor Version Update for September 2018",
        "excerpt":"      Jennifer Lee (MSFT)     8/1/2018 10:40:29 AM  Latest version updates to PHP  In September 2018, Azure App Service will update the PHP stacks to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.    PHP Version Change Log   5.6.37 http://www.php.net/ChangeLog-5.php#5.6.37   7.0.31 http://www.php.net/ChangeLog-7.php#7.0.31   7.1.20 http://www.php.net/ChangeLog-7.php#7.1.20   7.2.8 http://www.php.net/ChangeLog-7.php#7.2.8        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/08/01/PHP-Minor-Version-Update-for-September-2018.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Learn how to orchestrate serverless functions by scraping APIs in 8 minutes",
        "excerpt":"      Maxime Rouiller     8/6/2018 9:00:33 AM  Our scenario  The project I'm working on requires me to retrieve information from multiple sources like the NuGet and GitHub API. Let's bring into focus how I'm downloading data from the GitHub API. If you follow me on Twitter, you've probably already heard me talk about it.  Ever ended up on a sample that should be covering the problem you're having, but it just doesn't work? Then, you check the last commit date only to realize that it's been 2 years since the last commit. The way the cloud is evolving, that sample is almost no good to you.  Well, some of the repositories on the Azure-Samples organization have those exact issues, and it's one of the many problems that I'm trying to solve.  There are tons of samples on the Azure-Samples organization on GitHub, and I want to be able to check them out to see which ones are \"too old.\" What does a user consider a valid sample? For me, a valid sample is an up to date sample.  We need a way to retrieve those over 900 samples and validate their last commit date.  However, we first need to be able to retrieve all that information.  File -&gt; New Project -&gt; Console Application  Our first instinct as programmers is to try to do it once through a console application. It's the minimum amount of complexity. If you can't make it work in a console, there's no hope of making it work anywhere else.  So, I went ahead and started by consulting the GitHub API documentation, created a GitHub token and started hunting for the information I need.  I ended up using the Octokit library to do all of my API access. The code to retrieve the last commit date is below.  var github = new GitHubClient(new ProductHeaderValue(\"AzureSampleChecker\")) { Credentials = new Credentials(\"\") };  var lastCommit = await github.Repository.Commit.GetAll(repositoryId, new ApiOptions { PageSize = 1, PageCount = 1 }); var commit = lastCommit.FirstOrDefault()?.Commit; var lastCommitDate = commit.Committer.Date;  //snipped: saving to the database First problem: Running locally  Everything was running fine, but the problem for me at that point was it was just a single console application running locally. I could have just taken the application as-is to containers, but I saw another way to solve this. I saw another way to scale it up. Azure Functions would help me scale it up.  By migrating the existing code into an Azure Function, the problem now was that it was still just a console application running inside an Azure Functions. This will just not cut it. We're just running the same workflow in sequence. We need to execute this workflow in parallel and be able to scale out.  Once you know all the repositories that you want to query, it becomes a distributed problem. How many repositories can I hit at once without having any state to correlate between them? The answer is all of them.  I needed to refactor to make this process more sturdy. I needed it to be durable.  Introducing Durable Functions  If you are new to serverless, there's an excellent book by Jeremy Likness that can bring you up to speed. Azure Functions is Microsoft's implementation of the serverless architecture. If you need a refresher, you can review the Azure Functions Overview on what is possible.  What is a Durable Function? With durable, it's all about orchestration. Just like in music, the orchestrator ensures that everyone is following the melody, but it's the responsibility of each musician to play their instrument.  Regarding Durable Functions, an orchestrator is in charge of starting and tracking a series of functions, but it's the responsibility of each activities to execute their part. Think of the orchestrator as a workflow written in code and activities as the steps of the workflow. An orchestrator and an activity are still Azure Functions.  Let's introduce two patterns that I'm using in my code.  Function Chaining  A pattern I want to cover quickly is function chaining. It's the most straightforward and most commonly used pattern.    [caption id=\"attachment_9105\" align=\"aligncenter\" width=\"825\"] Function Chaining[/caption]  Everytime that your orchestrator awaits a function before running another one, you're doing function chaining. Here's the above image visualized in a code example. [FunctionName(\"FunctionChaining\")] public static async Task RunFunctionChaining([OrchestrationTrigger]) DurableOrchestrationContext context) {     await context.CallActivityAsync(\"F1\", null);     await context.CallActivityAsync(\"F2\", null);     await context.CallActivityAsync(\"F3\", null);     await context.CallActivityAsync(\"F4\", null); } Fan-Out/Fan-In  One of the Durable Functions design patterns I used is Fan-Out/Fan-In.    [caption id=\"attachment_9095\" align=\"aligncenter\" width=\"577\"] Fan-Out/Fan-In Pattern[/caption] Fanning out means that your orchestrator function (F1) starts as many functions (F2) as necessary in parallel with some initial parameters like the repository I want. Once all those functions have finished executing, we need a way to return the requested data to our orchestrator (F3). Keep in mind that, all those functions may not be executing on the same server. It is not as simple as a multi-threaded application. It's a multi-threaded, multi-server, highly parallel execution workflow.  How would you do that in a local data center? A console application would retrieve the list of items on which you want to fan-out. Then, it would queue that list into a messaging system. Once queued up, you would have to have dequeue those messages asynchronously by other console applications that are on different servers. Each console applications would then be responsible for storing the result of their execution on shared storage. Once completed, you'd have to find a way to get the first console application to finish the workflow. Finishing the workflow would involve fanning in all the results back, and saving it to a database.  With Azure Functions, it's as easy as returning an object. All the necessary work of storing the results of individual functions and aggregating them together is done automatically for you.  This scenario is a hard problem. Durable Functions just saved me easily one week of work and more days of testing, debugging, and refining the process.  Now that the introduction is complete let's jump back to our scenario.  Orchestrators are special functions  Functions with the OrchestrationTrigger behaves widely differently than normal Azure Function. This trigger is what makes a normal Azure Function an Orchestrator Function. Just  Its behaviors are incredibly different than other Functions. It is called multiple times at different moment to orchestrate the execution of those functions. It is of the utmost importance that you do not calculate time and access external resources (e.g., SQL, Storage, API) in that context. The orchestrator is tasked to execute and track the status of those functions we started by executing itself repeatedly when something changes. You want the orchestrator function to be deterministic, meaning the same code executed at a different time need to give the same result. So no DateTime, no Math.Random or Guid.NewGuid() should be in an orchestrator.  It's also important to note that every call that you make using CallActivityAsync won't be executed more than once for the same orchestrator instance. Results are cached and handled by the Durable Functions.  CallActivityAsync is part of the concept that we call checkpoint and replay. In simpler terms, this allows resuming the execution of the orchestrator while remembering the state of the execution of previous activities we ran in a reliable way across servers.  Web Scraping scenario  Here's the code for my sample orchestrator.  [FunctionName(\"DownloadSamples_Orchestrator\")] public static async Task RunOrchestrator([OrchestrationTrigger] DurableOrchestrationContext context, TraceWriter log) {     var repositories = await context.CallActivityAsync&lt;List&gt;(\"DownloadSamples_GetAllPublicRepositories\", null);      var tasks = new Task[repositories.Count];     for (int i = 0; i &lt; repositories.Count; i++)     {         tasks[i] = context.CallActivityAsync(\"DownloadSamples_UpdateRepositoryData\", repositories[i]);     }     await Task.WhenAll(tasks);      var samplesToAdd = tasks.Select(x =&gt; x.Result).ToList();     await context.CallActivityAsync(\"DownloadSamples_SaveAllToDatabase\", samplesToAdd); } So let's decompose this together. First, I call a function to retrieve the list of over 900 Public Repositories available on Azure-Samples and await for the results before going any further. Then, we create an array of Tasks and go through our samples and start a function without an await for each of them. We're fanning out the execution of those functions to be run and scaled by the cloud automatically. We're not using await here. Otherwise, they would run sequentially instead of in parallel.  Then task then need to be awaited till completion. Finally, we aggregate the Samples object that has been returned by those functions into a list. Finally, we send it to a function to save them in a database. We've successfully fanned-in the results of 100s of functions. There is no need for a third-party system. No other configurations. No complex messaging architecture. Just code.  Just like that, we've made a complex parallel problem easy.  Advanced Scenario: Orchestrating Orchestrators with Sub Orchestrators  Isn't it amazing? Now, I have an Orchestrator that instantiates over 900 DownloadSamples_UpdateRepositoryData functions to download data from the GitHub API. What would happen if I have multiple orchestrators of data ingestion that I want to make?  How do I orchestrate the orchestrators? We need another orchestrator of course! Here's a simplified version of my code.  [FunctionName(\"MainDownloadOrchestrator_TimerStart\")] public static async Task TimerStart([TimerTrigger(\"0 0 7 * * *\")]TimerInfo myTimer,     [OrchestrationClient]DurableOrchestrationClient starter,     TraceWriter log) {     string instanceId = await starter.StartNewAsync(\"MainDownloadOrchestrator\", null);     log.Info($\"Started orchestration with ID = '{instanceId}'.\"); }  [FunctionName(\"MainDownloadOrchestrator\")] public static async Task RunOrchestrator(     [OrchestrationTrigger] DurableOrchestrationContext context) {     var runId = await context.CallActivityAsync(\"CommonActivityFunctions_CreateRun\", null);      var downloadPipelines = new List();     downloadPipelines.Add(context.CallSubOrchestratorAsync(\"DownloadSamples_Orchestrator\", runId));     downloadPipelines.Add(context.CallSubOrchestratorAsync(\"DownloadSomethingElse_Orchestration\", runId));     //todo: add more orchestrators     await Task.WhenAll(downloadPipelines);      return context.InstanceId; } What does it do? Create a single run that is going to be used to invoke every other data ingestion orchestrator.  All those orchestrators are all going to start at 7 am every day at the same time. They are all going to run as described before. Only this time, they also report back to another orchestrator.  Once you start implementing simple workflows, it becomes effortless to build complex scenarios out of simple ones. The same patterns we approached that were used to build a single orchestrator can be used to orchestrate multiple sub-orchestrators.  Why do I want this?  Imagine working on a team with many different processes that need to run in parallel. Maybe one team is working on the shipping process, the other on the payment process. With a single orchestrator to manage multiple sub orchestrators, it makes team collaboration easier.  In my case, what if someone else wants to add the parsing of another API? They can work on their orchestrator and plug it in my MainDownloadOrchestrator function, and that's it.  Scraping data from an API is just a single scenario. Whether you are building an order processing system, a conference organization tool or the next revolution in IoT data processing, we know that you need a way to organize complexity within your solution. We know that you want to reuse more significant part of your system than a single function.  Durable Functions is how you build complex systems with serverless.  What is missing  What you haven't seen implemented is how to handle rate limiting. GitHub API has a limit of 5000 (at the time of writing) API calls per hour which is more than enough for the use that I make of it.  However, if other teams were to query GitHub some more, I'd need to look into implementing it. I still don't have an elegant solution for this, but it's going to be something I'm looking to implement next.  Try it out  If you want to try it out, Azure Functions comes with a free quota even with a trial account. If you need an account, you can create one for free.  Contribute  Azure Functions is also open source. Look at these repositories if you want to contribute or just want to know what's going on with the project.   Azure Function Runtime Azure Function CLI for local development Azure Function Portal Azure Functions templates for the portal and Visual Studio  Resources to get you started   Introduction to Azure Functions Creating your first function in the Azure Portal Running Azure Functions on a Timer Trigger Installing the Durable Functions extensions What is Durable Azure Functions?      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/08/06/Learn-how-to-orchestrate-serverless-functions-by-scraping-APIs-in-8-minutes.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Windows Containers on Azure App Service Public Preview",
        "excerpt":"      Andrew Westgarth     8/8/2018 11:55:52 AM  This morning we announced the public preview of Windows Container support on Azure App Service Web App for Containers.  You can read the announcement blog, which covers the new capabilities and Dv3 powered SKUs, here - https://azure.microsoft.com/blog/announcing-the-public-preview-of-windows-container-support-in-azure-app-service/  This public preview will enable new opportunities for customers looking to modernize their existing applications.  For example here are the steps required to take an existing .Net Framework Web Forms application, containerise it, publish to Docker Hub and then deploy to App Service.  Pre-Requisites:  Visual Studio 2017 with .Net Core and Azure workloads installed Docker for Windows Docker Hub Account or an Azure Container Registry  Create a new or open an existing ASP.Net Web Forms application in Visual Studio 2017 Select the Web Forms project, go to the Project Menu and select \"Docker Support\".  If you do not see this option check that you have the .Net Core workload installed with the Visual Studio Installer  [caption id=\"attachment_9135\" align=\"aligncenter\" width=\"300\"] Add Docker Support to existing project[/caption] Visual Studio will have created a new docker-compose project and added a Dockerfile to the Web Forms Project.  Open the Dockerfile: FROM microsoft/aspnet:4.7.1-windowsservercore-1709 ARG source WORKDIR /inetpub/wwwroot COPY ${source:-obj/Docker/publish} .  Change the FROM argument in the Dockerfile to point to a Windows Server 2016 Core base image from the Long Term Servicing Channel.  Should you wish to publish a .Net Core application in a Windows Container, use a Windows Server 2016 Nano base image from the Long Term Servicing Channel.  We cache certain images as listed in the announcement blog post to enable faster container deployment, for example here specify microsoft/aspnet:4.7.2-windowsservercore-ltsc2016: FROM microsoft/aspnet:4.7.2-windowsservercore-ltsc2016 ARG source WORKDIR /inetpub/wwwroot COPY ${source:-obj/Docker/publish} .  Build the project. Select the Web Application and right click Publish. As we are publishing the application in a container we need to publish to a Container Registry.  Visual Studio 2017 enables the publishing of containers to an Azure Container Registry, a private registry or Docker Hub.  In this example we're going to publish to Docker Hub, so select Container Registry, then choose Docker Hub and click Publish:  When prompted enter your Docker Hub account username and password and click Save Once published take a note of the container image name and tag from the Output window.  Go to the Azure portal and sign in with your Azure subscription credentials Choose to Create a resource in the upper left-hand corner of the Azure portal. In the search box above the list of Azure Marketplace resources, search for and select Web App for Containers. Provide an app name, such as WindowsContainerHelloWorld, accept the defaults to create a new resource group, and click Windows (Preview) in the OS box. Create an App Service plan by clicking App Service plan/Location &gt; Create new. Give the new plan a name, accept the defaults, and click OK Click Configure container, type the username/image:tag that you noted in the output window earlier, for example, mydockerhub/myimage:latest in Image and optional tag, and click OK. Click Create and wait for Azure to create the required resources, you will be notified when the operation completes.  Click Go to resource in the notification box. In the application overview click Browse, you will see a page showing the container is starting up Refresh the page after a few minutes and you will see your ASP.Net Web Forms application running!  We want to hear from you!  Windows Container support for Azure App Service provides you with even more ways to build, migrate, deploy, and scale enterprise grade web and API applications running on the Windows platform. We are planning to add even more capabilities during the public preview and we are very interested in your feedback as we move towards general availability.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/08/08/Windows-Containers-on-Azure-App-Service-Public-Preview.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Twitter AMA with the App Service Team #AppServiceAMA!!",
        "excerpt":"      Oded Dvoskin     8/9/2018 10:09:35 AM  The Azure App service team will host a special Ask Me Anything (AMA) session on Twitter, Wednesday, August 22, 2018 from 9 AM to 11 AM PST. You can tweet to @AzureSupport with #AppServiceAMA with your questions about the service. What's an AMA session?  We'll have folks from across the Azure App Service engineering team available to answer any questions you have. You can ask us anything about our products, services, roadmap, new features or even about our team! Why are you doing an AMA?  We love reaching out and learning from our customers and community. We want to know how you use Azure in general and App Service specifically and how your experience has been. Your questions provide insights into how we can make the service even better. How do I ask questions on Twitter?  Just use the hashtag #AppServiceAMA in your tweet to @AzureSupport and we will record the rest. The doors open to the community to start posting questions to the #AppServiceAMA 24 hours prior to the AMA (Tues Aug 21st at 9am PST).  The questions will be recorded, and will be answered on the day of the AMA.  This is to allow customers in different time zones or who can’t attend the event to ask their questions and get answers directly from the Azure App Service team. You can catch us for a live conversation on Aug 22, 2018 from 9am to 11am PST. If there are follow-ups, we will continue the dialogue post AMA. Go ahead and tweet to us! Who will be there?  You, of course! We'll also have Program Managers and Developers from the App Service engineering team participating, pulling in specific people depending on the topics. Have any questions about the following topics? Bring them to the AMA.  App Service Environment App Service on Linux / Web App for Containers Multi-Containers in App Service App Service Diagnostics Best practice for high traffic resiliency Scaling App Service Plans / Autoscale Networking and Isolation Deploying App Service Deployment slots, when to use and how Much, much more!  Why should I ask questions here instead of StackOverflow or MSDN? Can I really ask anything?  An AMA is a great place to ask us anything. StackOverflow and MSDN have restrictions on which questions can be asked. With an AMA, you’ll get answers directly from the team and have a conversation with the people who build these products and services.  Here are some question ideas:  What is App Service? What are the benefits of PaaS in comparison with IaaS? How do I manage access control to my resources? How many apps can I host on each App Service Plan? How do I monitor the health of the traffic to my apps? How do I solve issues that may happen with my app and its resources? How can I isolate the traffic to my app? How do I autoscale my app and how does affect billing? How is life in Seattle? Does it really rain all the time?  Go ahead, ask us anything about our public products or the team. Please note, we cannot comment on unreleased features and future plans and issues which require deep level debugging.  We're looking forward to having a conversation with you!     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/08/09/Twitter-AMA-with-the-App-Service-Team-AppServiceAMA!!.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure App Service on Azure Stack Update 3 Released",
        "excerpt":"      Andrew Westgarth     8/15/2018 3:23:17 PM  This afternoon we released the third update to Azure App Service on Azure Stack.  This release updates the resource provider and brings the following key capabilities:  Support for use of SQL Server Always On for Azure App Service Resource Provider databases. Updates to App Service Tenant, Admin, Functions portals and Kudu tools. Updates to ASP.Net Core, NodeJS, Zulu OpenJDK, Tomcat, PHP, Wincache and Git   All other fixes and updates detailed in the App Service on Azure Stack Update Three Release Notes   You can download the new installer and helper scripts:  Installer – https://aka.ms/appsvcupdate3installer Helper Scripts – https://aka.ms/appsvconmashelpers  Please read the updated documentation prior to getting started with deployment:  Before you get started with App Service on Azure Stack Deploy the App Service Resource Provider for new deployments Update the App Service Resource Provider for updating existing deployments      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/08/15/Azure-App-Service-on-Azure-Stack-Update-3-Released.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Avoid downtime due to Docker Hub's scheduled maintenance window on August 25th",
        "excerpt":"      Yi Liao MSFT     8/20/2018 10:46:46 AM  Summary Docker has scheduled a maintenance window for Docker Hub on Saturday August 25th, which has potential impacts to App Service customers.  For Web App for Containers (using custom Docker image), customers will not be able to create new web apps using a Docker container image from Docker Hub during the maintenance window.  Customers can still create new apps using Docker images hosted on Azure Container Registry or a private Docker registry.  For App Service on Linux (using non-preview built-in stacks), customers will not be impacted as we have Docker container images cached on our Linux workers.   Recommendation To avoid unnecessary service interruptions, we recommend Web App for Containers customers not make any changes or restart your apps, or use an alternative Docker registry during the Docker Hub maintenance window.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/08/20/Avoid-downtime-due-to-Docker-Hub's-scheduled-maintenance-window-on-August-25th.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "DevTalk  App Service - SSL Settings Revamp",
        "excerpt":"      Chibi Chakaravarthi V     8/23/2018 2:00:40 PM  App Service SSL settings experience is one of the most used features in App Service. Based on customer feedback we are making the following changes to the UX to address and improve the overall experience of managing certificates in Azure App Service. Tabs  The new SSL settings experience divides the features into 3 tabs. Namely SSL Bindings, Private certificates (.pfx), and Public certificates (.cer). The Bindings tab allows the user to configure the protocol settings and add/edit/delete SSL bindings, the private certificates tab allows the user to upload and manage private certificates (.pfx) used in SSL bindings and the public certificates tab allows the user to upload and manage public certificates (.cer). We also call out what type of certificate type the customer needs to use for each feature.         Editing SSL Bindings  SSL Settings didn't have a way to update an existing SSL binding, the feature to edit was present but unfortunately hidden under the Add Binding flow. We enabled the ability to edit a few sprints ago, we polished the feature further and now the customer is free to edit any binding by clicking on the row. When you change the thumbprint for the IP Based SSL binding the IP will not be lost, but if you change out from IP Based SSL to SNI and back you will lose the IP. The ability to change the certificate without removing and adding back the binding was an issue in the past we are addressing with this release. For more details on adding SSL Bindings click here.    Private Certificate Details  Private certificates used in App Service required a facelift to show the information we already gather when the certificate is uploaded, imported from App Service Certificate or imported from KeyVault. The driving reason was when we saw hundreds of private certificates configured on their app and had a tough time browsing through the certificates, the revamp allows the customer to now to get details of the certificates uploaded and imported. We added a new status column to the grid showing three possible states. Healthy, Warning and Expired. Warning being a certificate about to expire in the next 60 days. We also explicitly mention that you will need to upload a .pfx file to add a private certificate.  [caption id=\"attachment_9355\" align=\"aligncenter\" width=\"1429\"] Showing a test certificate that is valid.[/caption]  We also show the KeyVault details and the sync status of the certificates pulled from KeyVault like certificates imported from App Service Certificate.      Uploading certificates  The Upload Certificate experience overall is more consistent in showing that private certificates only accept .pfx file and you need a valid pfx to add a private certificate to your App Service. Addressing another feedback, we stopped showing both upload path. Now upload certificates from the private certificates opens the UX where you can only upload the private certificates to avoid the confusion about uploading .cer or .pfx file. When the Upload certificate flow is opened from the public certificate tab we show only the public certificate option.    We updated the upload certificate UX (and the underlying way it is implemented) to show errors while trying to upload a certificate without leaving the upload blade.         Public Certificates  Public certificates can only be used by your app and they cannot be used for making SSL bindings. We are working out a way to move it to a place where it will make more sense. For now, SSL Setting is the place where Public certificates will reside. Private certificates require app settings to enable that feature (it's covered in this very old but reliable blog here) and now public certificates add another dimension to that feature by allowing you to upload (.cer) files and get the certificates in runtime.       Thanks for reading! I am writing this blog to showcase the changes we made to improve the overall certificate management experience for customers using App Service day in and day out. We are always open to feedback and looking forward to your comments.  Feel free to reach out to us for any feature request or issues.  App Service MSDN forum Feature Requests      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/08/23/DevTalk-App-Service-SSL-Settings-Revamp.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing the New Auto Healing Experience in App Service Diagnostics",
        "excerpt":"      Jennifer Lee (MSFT)     9/10/2018 9:31:11 AM  Note: Currently, this new experience is only for Windows web apps for now.  Hopefully, most of the time your apps are running healthily and happily. However, sometimes your app may run into issues, resulting in downtimes, slowness, or other unexpected behaviors. We’ve built App Service Diagnostics to help you diagnose and solve issues with your web app with recommended troubleshooting and next steps. You can learn more about App Service Diagnostics here.  However, these unexpected behaviors may be temporarily resolved with some simple mitigation steps, such as restarting the process or starting another executable, or require additional data collection, so that you can better troubleshoot the ongoing issue at a later time.  Today, we’re excited to announce our new Auto Healing experience in App Service Diagnostics. With our new Auto Healing tile shortcut, you can set up custom mitigation actions to run when certain conditions (that you define as unexpected or a sign of unhealthy behavior) are met.   Click Diagnostic Tools from the App Service Diagnostics homepage.   Then, click Auto Healing. How to Get Started   Step 1: Define conditions  Select the tile that best matches the condition that you want to set for your mitigation rule.  The conditions that are supported with the new Mitigate/Auto Heal experience in App Service Diagnostics are:  Request Duration: examines slow requests Memory Limit: examines process memory in private bytes Request Count: examines number of requests Status Codes: examines number of requests and their HTTP status code  After reading the description, select the blue button to configure the rule parameters. Parameters that have a red asterisk next to it are required fields.   Step 2: Configure actions  Select the tile that best matches the auto heal mitigation action that you want to perform under your mitigation rule conditions. When the graphic is blue, it means that action has been selected. (For custom actions, be sure to fill out the parameters required).  The custom mitigation actions that are supported are:  Recycle Process Log an Event Custom Action  Run Diagnostics: runs Run Any Executable: runs specified executable     Step 3: Override when action executes (optional)  Sometimes when an app has a long startup time, depending on the mitigation rule conditions that are set, it may kick off the mitigation action during app startup, which is not the intended use case. By modifying the startup time, you can specify how much time the mitigation rule should wait after the process startup before the mitigation rule kicks off.   Step 4: Review and save your settings  Here, you can review the rules that you just created and save them. If you have previously defined rules, they will show up under Current Settings (no rules will show up under Current Settings until they are saved).  Saving mitigation settings will restart the application domain for the web app and this can cause logged-in user information, sessions, and in-memory cache to be cleared. Hence, it is advised to make these changes during non-business hours.  Two things to keep in mind:  These mitigation actions should only be considered a temporary workaround until you find the real cause for the issue causing the unexpected behavior. For the latter, you can start with App Service Diagnostics to figure out what actually went wrong. The feature in this blog post is in addition to Proactive Auto Heal, which is automatically restarts your web app based on our percent memory and percent request rules. Learn more about Proactive Auto Heal here.  How to Delete a Mitigation Rule  For the mitigation rule that you want to delete, select the condition that the rule is set on. Then, click on the trash can next to the rule that you configured.    Get ahead of your issues and automatically mitigate these unexpected behaviors by trying out Mitigate and Auto Heal in App Service Diagnostics.           ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/09/10/Announcing-the-New-Auto-Healing-Experience-in-App-Service-Diagnostics.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "New Price Drops for App Service on Linux",
        "excerpt":"      Jennifer Lee (MSFT)     9/12/2018 10:53:36 AM  Have you tried bringing your code or bringing your container to App Service on Linux yet? App Service on Linux is a fully managed platform that allows you to quickly build, deploy, and globally scale your apps. You can bring your code to App Service on Linux and take advantage of the built-in images for popular supported language stacks, such as Node, Java, PHP, etc, or bring your Docker container to easily deploy to Web App for Containers. We have seen strong adoption since the General Availability of App Service on Linux and Web App for Containers in September 2017.   Basic and Premium Price Drop  To encourage further adoption, we’re happy to announce a 30% price drop for the Basic App Service Plan for Linux, and a 20% price drop for the Premium App Service Plan for Linux. The price change takes effect on October 1st, 2018. Learn about more details on the App Service Pricing page.  Please note the price change applies to any existing Linux Basic and Premium App Service Plans as well as new Basic and Premium App Service Plans created on or after the effective date.      Linux on ASE GA Price Offering  As some of you may know, we announced that Linux on App Service Environment (ASE) is now generally available. Because Linux on App Service Environment combines the features from App Service on Linux and App Service Environment, Linux customers will be able to take advantage of deploying Linux and containerized apps in an App Service Environment. This is ideal for deploying applications into an Azure Virtual Network for secure network access or apps running at a high scale.    🔒Lock down your app in an Azure Virtual Network (VNet)  🎨Run Windows, Linux, and containerized apps in the same ASE  📈Use the Isolated SKU with Dv2 VMs and scale up to 100 VMs  🌏GA and 20+ Azure regions available  Linux on ASE saw healthy adoption during preview, and we’d like to encourage further adoption now that we’re in General Availability. Taking that into consideration, we’re extending the preview price (for Linux on ASE, which is the Linux Isolated App Service Plan SKU) for a limited time through GA!  Please note that when this limited time GA price offering ends, the final Linux on ASE price will be approximately twice the price of our Premium SKU. (Once the price offering ends, the prices will be closer to Windows on ASE.)  While the date for the GA price change is TBD, a 30-day notice will be given and announced here on our App Service Team Blog as well.     Now is the time to bring your code or bring your Docker container to App Service on Linux!           ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/09/12/New-Price-Drops-for-App-Service-on-Linux.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Functions feeding your Serverless appetite at Microsoft Ignite 2018!",
        "excerpt":"      Oded Dvoskin     9/20/2018 11:38:55 AM  Microsoft Ignite is taking place between September 24-28 and we can't wait for it to finally arrive! We are looking forward to all the great interactions with our customers, learning about the various new scenarios being solved with Serverless and of course announcing all the exciting news we've been keeping under the wraps!  Can't make it to Ignite? No worries, we've got you covered! Log in to the Microsoft Ignite site to tune in to the keynotes live. We'll also publish recordings of all the sessions presented a few days later.  If you're at Ignite, please join us for these following sessions which will give you the very best of what Azure Functions has to offer at Ignite! Just log in to your session scheduler to save these sessions and attend them all.     Build real-time serverless apps with Azure Functions and SignalR Service  In this session, learn how the Azure Functions integration with Azure SignalR Service works, so you can work with it using all languages supported by Functions and integrate different Azure services for real-time tasks to build an entirely serverless web application.  Speaker: Anthony Chu. Code: THR2195. Time: Monday at 6:25pm.    Azure Functions for the enterprise  Serverless solutions are a common developer’s choice these days, due to clear productivity benefits. However, when using such solutions in the enterprise, many other important aspects come to mind, such as security, monitoring, scalability and DevOps. In this session we explore how serverless development with the Azure platform helps you get to market faster while still fulfilling all your administration policies. We dive deeply into the features Azure Functions provides to delight both developers and IT, as well as best practices for using them in your enterprise-grade serverless solutions.  Speakers: Jeff Hollan, Matthew Henderson. Code: BRK3348. Time: Tuesday at 9:00am.    Build intelligent serverless applications  From data ingestion, processing, model training, model updates to prediction - machine learning is hard! Join us to learn how serverless makes it all easier so you can stop worrying about managing the underlying infrastructure and focus on getting the most value out of your data, whether you're running in the cloud or on an IoT device.  Speakers: Asavari Tayal, Colby Tresness. Code: BRK3352. Time: Wednesday at 9:00am.    Build microservices applications with a serverless architecture  When you learn how to build your cloud-native applications using a PaaS architecture, infrastructure management or scaling based on demand isn't a problem anymore. In this session, we discuss how to go all serverless on microservices-based applications with a reference architecture, including data storage, endpoints management, and compute services.  Speaker: Gorka Madariaga Nuñez. Code: BRK2027. Time: Wednesday at 3:15pm.    Machine Learning using Python in Azure Functions  Learn how to build smarter serverless workloads with Azure Functions powering machine learning and data analysis models using Python.  Speaker: Asavari Tayal. Code: THR2201. Time: Wednesday at 5:05pm.    Azure Functions internals  Join our product engineering team on a technically deep lap around Azure Functions. Learn how Azure Functions enables you to quickly and easily deploy application services that scale massively in a cost-effective way, without having to worry about infrastructure and server management. This session goes beyond the basics to show you behind the scenes details on the latest advancements made by the product team. Azure Functions users learn new concepts in a demo-driven session covering topics like deployment, service management, and monitoring.  Speakers: Eduardo Laureano, Fabio Cavalcante. Code: BRK4020. Time: Thursday at 9:00am.    Serverless real use cases and best practices  Let's take a look at real cases from our customers worldwide, to learn how they solved their problems through our serverless platform, as well as best practices (and some caveats) from the architectures used developing these solutions. Speakers: Eduardo Laureano, Thiago Almeida, Nick Lizotte. Code: BRK2202. Time: Thursday at 12:45pm.    Automate your cloud infrastructure with Azure Functions, Azure Automation, and more  Companies are constantly increasing their cloud footprint, creating a wealth of resources that need to managed. IT professionals are looking for the most efficient ways to automate management operations on those resources. Learn in this session the multiple ways in which you can simplify your life by using Azure Functions, Azure Automation, Logic Apps and Event Grid. After this session, you will be armed with choices that fit your preferences and needs.  Speakers: Colby Tresness, Eamon O'Reilly. Code: BRK2208. Time: Friday at 10:45am.    Even more!  In addition to these fantastic sessions, we are also holding a live webcast on Thursday, September 27th at 2:15pm EST. Tune in to aka.ms/AzureFunctionsLive to hear a recap of all our announcements and get an opportunity to ask Jeff and Eduardo live questions!  Lastly, if you want to score a special prize, check out the questions here, write them down and come to our booth with the correct answers for a surprise. Of course, you can always stop by our booth regardless, meet the team, get your most burning questions answered and score some swag!     See you all soon at Microsoft Ignite in Orlando!     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/09/20/Azure-Functions-feeding-your-Serverless-appetite-at-Microsoft-Ignite-2018!.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Check out App Service sessions at Microsoft Ignite 2018!",
        "excerpt":"      Oded Dvoskin     9/20/2018 11:39:54 AM  We're getting excited leading up to Microsoft Ignite happening between September 24-28! As usual, there are many amazing sessions, announcements, demos, interactions and content planned.  Can't make it to Ignite? No worries, we've got you covered! Log in to the Microsoft Ignite site to tune in to the keynotes live. We'll also publish recordings of all the sessions presented a few days later.  As an attendee, it's always challenging to figure out which sessions to attend. Whether you are an advanced user of PaaS and App Service, or just getting started, we know you'll find the following sessions useful in planning your Ignite learning. Just log in to your session scheduler to save these sessions and attend them all.      Your web apps from code to deployed in a minute!  Web developers want to focus on code, not be held back by the pain of getting an app deployed to Azure App Service. In this session, learn how to use Azure CLI to deploy your code to App Service with a single command, regardless of your language. Speaker: Nick King. Code: THR1110. Time: Monday, 12:45pm.    Best practices for mission critical apps on Azure App Service  Azure App Service provides 99.95% SLA even for apps running on only a single instance. However, there are steps you should take as a developer to insulate your customers from perceived cold start latencies incurred when deploying a new version of an app. This session walks through using a combination of multi-phase deployment slots (swap with preview), local cache for disk resiliency, application initialization for warmup, and proper app service plan configuration to minimize cold start performance hits. Speaker: Stefan Schackow. Code: THR3105. Time: Monday, 1:20pm.    Oops, I deleted my web app! What now?  Sometimes, intentionally or accidentally, an Azure App Service web app get deleted. Up to now, the only way to restore that app was to open a support ticket. Introducing Azure App Service Web App Undelete, where you can restore your app without the need to have a support plan. In this session, learn how to use the different Azure management tools to restore your deleted app.  Speakers: Nick King, Oded Dvoskin. Code: THR2204. Time: Monday, 5:45pm.    What is new in Azure App Service networking  The Azure App Service has had multiple features to enable application isolation and virtual network access. Some of these capabilities required the use of an App Service Environment (ASE). New features have been developed to enable numerous use cases without the use of an ASE such as hosting line-of-business applications, accessing resources across ExpressRoute and also accessing resources that are secured with service endpoints. At the same time we are also making major improvements to the ASE and are enabling greater isolation than previously.  Speaker: Christina Compy. Code: BRK2386. Time: Tuesday, 2:00pm.    Fundamentals of Windows containers and Windows container-based web apps on Azure App Service  Join us to learn why containers are a paradigm shift to a modern DevOps workflow! Container isolation empowers developers and IT to collaborate effectively with clear boundaries of configuration and execution. In this session we show real-life examples, covering how to dockerize your web and API apps, how to run Windows-server based containers on Azure App Service, and how to perform container customizations for scenarios such as image generation, custom font installation, GAC assemblies, and calling native DLLs from your web apps. Learn how to get direct access into running containers to run PowerShell commands. If you want to achieve new levels of collaboration, you can’t miss this session!  Speaker: Andrew Westgarth. Code: BRK2045. Time: Tuesday, 2:15pm.    Keep your PaaS and serverless apps healthy and happy  Working on an web app on Azure App Service or Azure Functions? Join us to learn tips and tricks that will help you quickly and easily diagnose and resolve issues with your web app, Functions app, or App Service environment. In this session, learn how to effectively leverage App Service diagnostics for troubleshooting in both proactive and problem-first scenarios. We walk through real-world scenarios that guide you to a cure for common app issues.  Speaker: Jennifer Lee. Code: BRK3344. Time: Tuesday, 4:30pm.    Bring your container or code to easily deploy to App Service on Linux  Are you interested in our newest container and OSS offerings in Azure App Service on Linux? In this session, we walkthrough how easy it is to bring your containerized Linux app to Web App for Containers and take advantage of the PaaS environment for increased efficiency. We also show you how to modernize classic app architecture with multi-containers, new OSS announcements, and how to diagnose and keep your app running healthily. With simplicity at scale, learn about how you can operate at a global scale by utilizing the latest features to make your app production ready.  Speakers: Jennifer Lee, Jenny Lawrance. Code: BRK2390. Time: Friday, 12:30pm.     Last, but not least, be sure to drop by our booth for some good conversation, get your technical questions answered and stock up on cool swag!  See you in Orlando!     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/09/20/Check-out-App-Service-sessions-at-Microsoft-Ignite-2018!.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing Bring your own Storage to App Service",
        "excerpt":"      Ranjith Ramachandra     9/24/2018 12:34:40 PM  Bring your own Storage to App Service now in Public Preview  We’re excited to announce the “Bring Your Own Storage” feature to App Service on Linux and Web App for Containers. Available in public preview, “Bring Your Own Storage” supports mounting Azure Blobs and Azure Files into your Azure App Service. You can configure up to five Azure storage accounts for a given App Service.  “Bring your own storage” for example, enables the following scenarios:  Bring your own content and have it readily available for your web application hosted on App Service. This avoids the need to copy the content which could take a lot of time depending on the number and size of the files. Use the azure blob storage or azure files to write content or Log files which can be shared across different services you might have. For example, you can use any log management service like splunk with your app service writing logs to the azure files or blob storage and the log management service can consume the logs from the storage.  Configure azure storage account on App Service  With this public preview annoucement, Azure CLI will have support for “Bring your own storage”. The UX experience is coming soon.  Login to the CLI and ensure you have selected the right subscription:  $ az login $ az account list $ az account set –subscription “YourSubscriptionName”  To get help on the command to manage storage accounts on your app service, use the -h option:  az webapp config storage-account -h  Group az webapp config storage-account : Manage a web app's Azure storage account configurations.  Commands: add    : Add an Azure storage account configuration to a web app. delete : Delete a web app's Azure storage account configuration. list   : Get a web app's Azure storage account configurations. update : Update an existing Azure storage account configuration on a web app. Add a storage account to your app service  To add a new storage account, you will need an Azure Storage (blob or azure files). If you haven’t created one yet, please follow the steps mentioned here to create one.  Also, to learn more about how to create App Service, please follow the steps here.  To link a storage account with your App Service (assumes you have already created the app service and the storage account), use the following command:  $ az webapp config storage-account add -g RESOURCE_GROUP -n APP_NAME \\ --custom-id CustomId [Unique identifier for this storage mapping] \\ --storage-type [Azure storage type: AzureFiles or AzureBlob]   \\ --account-name [Azure storage account name]   \\ --share-name   [Azure storage share/file name]   \\ --access-key   [storage access key]   \\ --mount-path   [/path/to/mount within the container]  Sample:  $ az webapp config storage-account add -g AppSvcBYOSDemoSite -n AppSvcBYOSDemoSite --custom-id MediaVolume --storage-type AzureBlob --account-name appsvcbyosdemo --share-name mediablob --access-key &lt;youraccesskey&gt; --mount-path /var/media  Output:  { \"MediaVolume\": { \"accessKey\": \"youraccesskey\", \"accountName\": \"appsvcbyosdemo\", \"mountPath\": \"/var/media\", \"shareName\": \"mediablob\", \"state\": \"Ok\", \"type\": \"AzureBlob\" } }  At this point, your web application will have the storage mounted at /var/media and your web application has full access to this storage. If you want to use the mounted storage account in a Multi-container web app,  you need to specify the custom-id of your storage account in the volumes block of your container definition in the Docker-Compose or Kubernetes yaml file, for example:  version: '3' services: web: image: \"mydocker/image:latest\" ports: - \"80:80\" volumes: - &lt;custom-id&gt;:/var/media redis: image: \"redis:alpine\" List storage accounts associated with the App Service  To list the storage accounts associated with your app service, use the list command:  $ az webapp config storage-account list -g RESOURCE_GROUP -n NAME  Sample:  $ az webapp config storage-account list -g AppSvcBYOSDemoSite -n AppSvcBYOSDemoSite  Output:  [ { \"name\": \"MediaVolume\", \"slotSetting\": false, \"value\": { \"accessKey\": \"youraccesskey\", \"accountName\": \"appsvcbyosdemo\", \"mountPath\": \"/var/media\", \"shareName\": \"mediablob\", \"state\": \"Ok\", \"type\": \"AzureBlob\" } } ] Update storage account associated with the App Service  To update the storage accounts associated with your app service, use the update command:  $ az webapp config storage-account update -g RESOURCE_GROUP -n APP_NAME \\ --custom-id CustomId [Unique identifier for this storage mapping] \\ --storage-type [Azure storage type: AzureFiles or AzureBlob]   \\ --account-name [Azure storage account name]   \\ --share-name   [Azure storage share/file name]   \\ --access-key   [storage access key]   \\ --mount-path   [/path/to/mount within the container]  Sample:  $ az webapp config storage-account update -g AppSvcBYOSDemoSite -n AppSvcBYOSDemoSite --custom-id MediaVolume --storage-type AzureBlob --account-name appsvcbyosdemo --share-name mediablob --access-key &lt;youraccesskey&gt; --mount-path /var/media  Output:  { \"MediaVolume\": { \"accessKey\": \"youraccesskey\", \"accountName\": \"appsvcbyosdemo\", \"mountPath\": \"/var/media\", \"shareName\": \"mediablob\", \"state\": \"Ok\", \"type\": \"AzureBlob\" } } Remove storage account associated with the App Service  To remove the storage account from the Azure App Service, use the delete command.  $ az webapp config storage-account delete -g RESOURCE_GROUP -n APP_NAME --custom-id CustomId  Sample:  az webapp config storage-account delete -g AppSvcBYOSDemoSite -n AppSvcBYOSDemoSite --custom-id MediaVolume  Output:  {} Sample Web Application that uses external Azure Storage for static files  Here is a sample dotnetcore web application that shows how you easy it is to use an Azure Storage account to store your  content and reference it in your web application.  Useful Links  Hosting Web Applications on Azure App Service Creating Azure Storage Accounts and Azure Files Deploying web applications to Azure App Services           ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/09/24/Announcing-Bring-your-own-Storage-to-App-Service.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing Webapps Undelete (Preview)",
        "excerpt":"      Ahmed Elnably     9/24/2018 10:42:08 AM  Azure App Service Undelete now in public preview  Today we are announcing the public preview release of Azure App Service Undelete. Undelete is available for all App Service Plans, from Basic and up. Only sites deleted in the past 30 days can be restored.  A user can undelete a deleted web app, and restore the following:  The content of the deleted app. The configuration of the app (the commands allows to skip the restoration of the app configuration). The undelete commands will also to restore the *.azurewebsites.net host name if still available.  Currently the undelete commands support the restoration of apps deleted from the multi-tenant using Windows and Linux, other services like App Service Environments and Azure Functions will be supported in later releases.  To get started, install the PowerShell module or install Azure CLI.    Azure CLI  List deleted apps  You can list deleted apps using the following command, you can use the optional parameters to filter the apps with a specific name, belong to a specific resource group or App Service plan. Record the id of the deleted site as that will be used to restore the app. az webapp deleted list --name &lt;name of the deleted app&gt; Restore a deleted app  In CLI you need to have an existing app or an app slot to restore your app to az webapp deleted restore --deleted-id &lt;id of the deleted app&gt; --name &lt;name of the app to restore to&gt; --resource-group &lt;resource group of the app to restore to&gt;    Azure PowerShell  List deleted apps  You can list deleted apps using the following command, you can use the optional parameters to filter the apps with a specific name, belonging to a specific resource group. Get-AzureRmDeletedWebApp -name &lt;name of the deleted app&gt;  Restore a deleted app  In PowerShell, you can specify the name and resource group of the deleted app, and provide the information of the target app. You can specify an App Service plan name to restore to, and the command will try and restore the app with the same *.azurewebsites.net hostname as the deleted app. Restore-AzureRmDeletedWebApp -ResourceGroupName &lt;deleted app rg&gt; -Name &lt;deleted app name&gt; -TargetAppServicePlanName &lt;App Service plan name to create an app to restore to&gt;      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/09/24/Announcing-Webapps-Undelete-(Preview).html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing the New App Service Diagnostics Experience",
        "excerpt":"      Jennifer Lee (MSFT)     9/24/2018 2:00:51 AM  Today, we’re excited to announce our new user experience for App Service Diagnostics. App Service Diagnostics is our intelligent and interactive experience to help you diagnose and troubleshoot issues with your app. You can use Genie to guide you through the different ways to troubleshoot a variety of potential issues, since sometimes bad things happen to good apps. You can learn more about App Service Diagnostics in these other blog posts.  Since we’ve first started with helping you with availability and performance issues, the coverage of issues that App Service Diagnostics has grown. To accommodate for a variety of problem categories and to more closely integrate with other troubleshooting content, we have revamped the user experience for App Service Diagnostics.   How to Get Started  As always, without any additional configuration, you can access App Service Diagonstics by:  Go to the Azure Portal. Select your app (Windows, Linux, or Functions) or App Service Environment. Click on “Diagnose and solve problems.\"  You can still access the old experience by selecting the blue bar at the top. Problem Categories  In the new App Service Diagnostics homepage, the guided diagnostics experience is now separated into different problem categories to help you be more focused on the specific issue that you’re facing. Each problem category will have a description and keywords to help describe what types of problems would fall underneath that category.    If you’re new to diagnosing issues with your app or new to App Service, it’s a good idea to click around these tiles to investigate your issue.  The health checkup from our old experience will be under Availability and Performance.   Genie and Tiles for Each Problem Category  Once you have selected a problem category, you are introduced to Genie, who will guide you through the troubleshooting experience for that category. In this new iteration, Genie is specific to the problem category that you’ve selected.   The blue buttons that show up are tiles; you should select those that best match your issue. These tiles run analyses on our end and output insights that show up within Genie. You should click on these insights to get more data, the full report, and actual suggestions on what to do next.    Insights are arranged in terms of severity:  Red: critical Orange: warning Green: success Blue: informational  Once you click on the insight, there may be more insights and next steps to follow. Make sure you select each insight to expand to show more details. Also, there is a new time picker on the top right to help to navigate between different time periods of interest.    At any time, select Show Tile Menu to show all the tiles for that problem category. Search Documentation  Also new to Genie’s flow is our Search Documentation. If the tiles weren’t of help, you can enter in your issue in the inline search bar that appears after you select Search Documentation. This will do a web search of the issue you’ve written about to find relevant content that might help you with your “how do I…?” questions. It brings up the most relevant results if you include “App Service” or “web app” in your search terms.   Search App Service Diagnostics  Now, in the new App Service Diagnostics home page, we have a search bar in the top left-hand corner. This search bar allows you to search within App Service Diagnostics to find the relevant tiles or tools that fit the search term.  Therefore, the search bar is great when you are more experienced with App Service Diagnostics and know specifically what problem category, tile, or diagnostic tool you’re looking for. You can just type in the search term and quickly get to the tile that you’re interested in, which is great when showing your troubleshooting methods to other members on your team.   Diagnostic Tools  The Diagnostic Tools problem category is where our advanced tools are now. These include all the Support Tools that were on the right-hand side of the page as well our new Auto Healing feature. This is a great option for our advanced users who want to collect a profiler trace, memory dump, network trace, and more.   Best Practices  The Best Practices problem category is where our suggestions for running production apps in the cloud are. These suggestions are app-specific recommendations for optimizing your app configurations for production.    As before, App Service Diagnostics is a great first step in guiding you through the troubleshooting experience on App Service, App Service Environment, or Azure Functions. Please try out the new experience and let us know about your feedback!           ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/09/24/Announcing-the-New-App-Service-Diagnostics-Experience.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Twitter AMA with the Azure Functions team #FunctionsAMA!",
        "excerpt":"      Oded Dvoskin     10/1/2018 2:12:42 PM  The Azure Functions team will host a special Ask Me Anything (AMA) session on Twitter, Thursday, October 11, 2018 from 9 AM to 11 AM PST. You can tweet to @AzureFunctions or @AzureSupport with #FunctionsAMA with your questions about the service. What's an AMA session?  We'll have folks from across the Azure Functions engineering team available to answer any questions you have. You can ask us anything about our products, services, roadmap, new features or even about our team! Why are you doing an AMA?  We love reaching out and learning from our customers and community. We want to know how you use Azure in general and Functions specifically and how your experience has been. Your questions provide insights into how we can make the service even better. How do I ask questions on Twitter?  Just use the hashtag #FunctionsAMA in your tweet to @AzureFunctions or @AzureSupport and we will record the rest. The doors open to the community to start posting questions to the #FunctionsAMA 24 hours prior to the AMA (Wednesday Oct 10th at 9am PST).  The questions will be recorded, and will be answered on the day of the AMA.  This is to allow customers in different time zones or who can’t attend the event to ask their questions and get answers directly from the Azure Functions team. You can catch us for a live conversation on Oct 11th, 2018 from 9am to 11am PST. If there are follow-ups, we will continue the dialogue post AMA. Go ahead and tweet to us!  Who will be there?  You, of course! We'll also have Program Managers and Developers from the Functions engineering team participating, pulling in specific people depending on the topics. Have any questions about the following topics? Bring them to the AMA.  Getting started with Serverless. Deciding between hosting Functions in a consumption or dedicated plan. Functions runtime 2.0. Consumption plan on Linux (preview). Hosting Functions in containers. Bindings and Triggers connecting to other services. Scaling operations. Monitoring and debugging Functions. Where to develop Functions. Best practice. Much, much more!  Why should I ask questions here instead of StackOverflow or MSDN? Can I really ask anything?  An AMA is a great place to ask us anything. StackOverflow and MSDN have restrictions on which questions can be asked. With an AMA, you’ll get answers directly from the team and have a conversation with the people who build these products and services.  Here are some question ideas:  What is Serverless? What is Functions? What are the benefits of Serverless in comparison with IaaS? How do I manage access control to my resources? How many functions should I host in each Function app? How do I monitor the health of my functions? How do I diagnose issues that I suspect are happening with my functions' health? What is the Azure Functions Premium plan? When to choose between Durable Functions and Logic Apps? Between Functions and Logic Apps? Does Serverless really mean the lack or Servers? What is this madness??  Go ahead, ask us anything about our public products or the team. Please note, we cannot comment on unreleased features and future plans and issues which require deep level debugging.  We're looking forward to having a conversation with you!     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/10/01/Twitter-AMA-with-the-Azure-Functions-team-FunctionsAMA!.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP Minor Version Update for November 2018",
        "excerpt":"      Jennifer Lee (MSFT)     10/4/2018 10:30:21 AM  Latest version updates to PHP  In November 2018, Azure App Service will update the PHP stacks to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.    PHP Version Change Log   5.6.38 http://www.php.net/ChangeLog-5.php#5.6.38   7.0.32 http://www.php.net/ChangeLog-7.php#7.0.32   7.1.22 http://www.php.net/ChangeLog-7.php#7.1.22   7.2.10 http://www.php.net/ChangeLog-7.php#7.2.10        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/10/04/PHP-Minor-Version-Update-for-November-2018.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "New App Service VNet Integration feature",
        "excerpt":"      Christina Compy (MSFT)     10/17/2018 11:47:30 AM  We are happy to announce a new version of the VNet Integration capability that enables access to resources across Service Endpoints or ExpressRoute connections.  Like the pre-existing VNet Integration feature, this only enables your app to make calls into your VNet. It does not affect inbound traffic to your app.  This feature is in Preview in all public regions.  The new VNet Integration capability has the following characteristics.  No gateway is required to use the new VNet Integration feature You can access resources across ExpressRoute connections without any additional configuration beyond integrating with the ExpressRoute connected VNet. The app and the VNet must be in the same region The new feature requires an unused subnet in your Resource Manager VNet. Your App Service plan must be a Standard, Premium or PremiumV2 plan The new capability is only available from newer Azure App Service scale units. The VNet Integration UI in the portal will tell you if your app can use the new VNet Integration feature. Production workloads are not supported on the new feature while it is in Preview Your app must be in an Azure App Service deployment that is capable of scaling up to Premium v2. The new VNet Integration feature does not work for apps in an App Service Environment. The new VNet Integration feature currently works just with Windows apps.  One address is used for each App Service plan instance. Since subnet size cannot be changed after assignment, use a subnet that can more than cover your maximum scale size. A /27 with 32 addresses is the recommended size as that would accommodate an App Service plan that is scaled to 20 instances.  You can consume Service Endpoint secured resources using the new VNet Integration capability. To do so, enable service endpoints on the subnet used for VNet Integration.  To use the feature, go to the Networking UI in the portal. If your app is able to use the new feature then you will see a capability to use the new preview feature. Simply select the Resource Manager VNet that you want to integrate with and then either create a new subnet or pick an empty pre-existing subnet.  Initially there are some things that will not work initially against the subnet used for VNet Integration.  They include peering, network security groups, and route tables.  These capabilities will be gradually enabled during the preview period. Also not initially available is the ability for your web app to pick up the VNet DNS setting.  If you want your app to use your VNet DNS server then create an Application setting for your app where the name is WEBSITE_DNS_SERVER and the value is the IP address of the server.  If you have a secondary DNS server then create another Application setting where the name is WEBSITE_DNS_ALT_SERVER and the value is the IP address of the server.  You can read more about the feature in the documentation on Integrate an app with a VNet     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/10/17/New-App-Service-VNet-Integration-feature.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Git Version Update Planned for November and December 2018",
        "excerpt":"      Stefan Schackow (MSFT)     11/8/2018 12:33:19 PM  Starting on November 13th 2018, and running approximately through December 14th 2018, Azure App Service will be updating the version of Git deployed on the service to version 2.19.1.  This is expected to be a non-breaking update.   For information on the changes contained in the new version please see the Git release notes here:  https://raw.githubusercontent.com/git/git/master/Documentation/RelNotes/2.19.1.txt      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/11/08/Git-Version-Update-Planned-for-November-and-December-2018.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure App Service on Azure Stack Update 4 Released",
        "excerpt":"      Andrew Westgarth     11/13/2018 10:25:50 AM  This morning we released the fourth update to Azure App Service on Azure Stack.  This release updates the resource provider and brings the following key capabilities and fixes:  Resolution for CVE 2018-8600 Cross Site Scripting Vulnerability. Added support for App Service 2018-02-01 API version Updates to App Service Tenant, Admin, Functions portals and Kudu tools. Consistent with Azure Stack Portal SDK version. Updates to NodeJs, NPM, Zulu OpenJDK, Tomcat, PHP and Python All other fixes and updates are detailed in the App Service on Azure Stack Update Four Release Notes  You can download the new installer and helper scripts:  Installer – https://aka.ms/appsvcupdate4installer Helper Scripts – https://aka.ms/appsvconmashelpers  Please read the updated documentation prior to getting started with deployment:  Before you get started with App Service on Azure Stack Deploy the App Service Resource Provider for new deployments Update the App Service Resource Provider for updating existing deployments      ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/11/13/Azure-App-Service-on-Azure-Stack-Update-4-Released.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "WordPress on Linux Updated",
        "excerpt":"      Yi Liao MSFT     11/30/2018 2:30:16 PM  Updated image for WordPress on Linux  We have recently updated the WordPress on Linux offering on Azure Marketplace.  In this version we have replaced Apache/mod_php with Nginx/PHP-FPM, we've seen the improved performance in our internal testing.  Customers can use the WordPress on Linux image from the Azure Marketplace to create a new WordPress site and get the latest image automatically. Upgrade WordPress on Linux  If you have an existing WordPress site running on the previous version of the Marketplace template, you may upgrade to the new image following the steps below. Before you begin, we recommend you backup the database and WordPress site (details in Migrate section).  Upgrade steps:  In the Azure Portal, find your Web App and go to \"Container Settings\" Update the \"image:tag\" setting to 'appsvcorg/wordpress-alpine-php:0.61' Click Save and wait for the Web App to restart  Migrate your site to WordPress on Linux  For customers who plan to migrate their WordPress site to Azure App Service, while the Marketplace image comes with a fresh install of WordPress, customers can replace the code on the Web App and bring their own WordPress codebase (for example during migrations from on-premises or other hosting platforms).  Connect to the Web App using FTPS and replace the contents of the '/home/site/wwwroot' directory.  Alternatively, you can create a zip file for your codebase and deploy it to the Web App using App Service zipdeploy. Verify that 'wp-config.php' contains the correct database connection string, using the wp-config.php file from Azure Marketplace for reference. For WordPress database, you can use tools such as mysqldump or MySQL Workbench to backup the MySQL database from the original server and restore it to Azure Database for MySQL.  Customization  For cases in which additional customization is needed for plugins or themes, we recommend customers to modify the Docker image used in the Marketplace (source on GitHub), and run it on Web App for Containers. Once completed, migrate the site so that you don’t have to start from scratch.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2018/11/30/WordPress-on-Linux-Updated.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Python 2.7 Now Available for App Service on Linux",
        "excerpt":"      Python 2.7 has been added to the public preview of Python on Azure App Service (Linux).  With this recent addition developers can enjoy the productivity benefits and easy scaling features of Azure App Service using Python 2.7, 3.6 or 3.7.  More details on the public preview of Python support on Azure App Service (Linux) are available here: https://azure.microsoft.com/en-us/blog/native-python-support-on-azure-app-service-on-linux-new-public-preview/     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2019/01/04/Python-2.7-Now-Available-for-App-Service-on-Linux.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP Minor Version Update for January 2019",
        "excerpt":"      Yi Liao MSFT     1/11/2019 12:57:33 PM  In the next release of Azure Web Apps, we will update the PHP stacks on Windows to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.    PHP Version Change log   5.6.39 http://www.php.net/ChangeLog-5.php#5.6.39   7.0.33 http://www.php.net/ChangeLog-7.php#7.0.33   7.1.25 http://www.php.net/ChangeLog-7.php#7.1.25   7.2.13 http://www.php.net/ChangeLog-7.php#7.2.13        ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2019/01/11/PHP-Minor-Version-Update-for-January-2019.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service Environment Support for Availability Zones (Preview)",
        "excerpt":"      App Service Environment (ASE) support for Availability Zones (AZ) is now in preview.  Customers can deploy internal load balancer (ILB) ASEs into a specific AZ (Zone 1, 2 or 3) within an Azure region, and the runtime resources used by that ILB ASE will be deployed into the specified AZ.    An ILB ASE is deployed in a zonal manner which means the ILB ASE is pinned to a specific zone.  This means all of the following runtime ILB ASE resources will be located in the specified zone:  the internal load balancer IP address of the ASE,  the compute resources used by the ASE to run web applications, and the underlying file content storage for all of the web applications deployed on the ASE.    Currently ILB ASEs can be deployed into AZs in the Central US region.  The set of available regions for the ASE AZ preview will be expanded over the course of January and February to include all AZ enabled Azure regions.  Note that only ILB ASEs support availability zones - there are no plans at this time to enable AZ support for external facing ASEs (i.e. ASEs that have a public IP address for accepting website traffic).  Customers can deploy an ASE into an availability zone using ARM templates.  The ARM template snippet below shows the new properties and values in bold that tell the platform to deploy the ASE into an availability zone:       \"resources\": [       {          \"type\": \"Microsoft.Web/hostingEnvironments\",          \"kind\": \"ASEV2\",          \"name\": \"yourASENameHere\",          \"apiVersion\": \"2018-05-01-preview\",          \"location\": \"Central US\",          \"zones\": [             \"2\"          ],          \"properties\": {             \"name\": \"yourASENameHere\",             \"location\": \"Central US\",             \"ipSslAddressCount\": 0,             \"internalLoadBalancingMode\": \"3\",             \"dnsSuffix\": \"contoso-internal.com\",             \"virtualNetwork\": {                \"Id\": \"/subscriptions/your-subscription-id-here/resourceGroups/your-resource-group-here/providers/Microsoft.Network/virtualNetworks/your-vnet-name-here\",                \"Subnet\": \"yourSubnetNameHere\"             }          }       }     ]   There are only two minor changes needed in an ILB ASE ARM template to enable zonal deployment.  The apiVersion property must be set to 2018-05-01-preview in order for the zones property to be processed.  The zones property can be set as shown above with a value of 1, 2 or 3 depending on which zone you want to deploy the ASE into.  In order to attain zone resiliency for apps created on AZ deployed ILB ASEs, customers will need to deploy at least two ILB ASEs - one per zone.  Customers should then create and publish copies of their application onto each of the AZ deployed ASEs.  Customers will additionally need to deploy a load balancing solution upstream of the AZ deployed ASEs so that traffic bound for an application is distributed across all instances of the ASEs.  For example a zone-redundant Application Gateway could be deployed upstream, and then configured to route requests for a given application across all of the application instances created on the AZ deployed ASEs.  More details on zone-redundant Application Gateway are available here:  Autoscaling and Zone-redundant Application Gateway (Public Preview).  Once an ASE and its applications are running inside of a specific zone, the applications will continue to run and serve traffic on that ASE even if other zones in the same region suffer an outage.  However it is possible that non-runtime behavior including application service plan scaling as well as application creation/configuration/publishing may be impacted in the event of a region outage.  Future investments into availability zone support for App Service will eventually extend zone resiliency to these non-runtime behaviors.     ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2019/01/16/App-Service-Environment-Support-for-Availability-Zones-(Preview).html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "The Zend Z-Ray debugging feature will be discontinued in Azure App Service on June 7, 2019",
        "excerpt":"The Z-Ray PHP debugging feature will soon be discontinued in App Service. This shouldn’t affect the App Service service-level agreement (SLA) or the runtime behavior of your applications.   Beginning March 9, 2019, Z-Ray will no longer be available for purchase in the Azure portal. If you already have applications configured with Z-Ray, you may continue to use it until June 7, 2019. After that date, the Z-Ray feature will be removed from all applications and you’ll no longer be charged for it.   Have you configured Zend Z-Ray for your app?   Even though no action is required for customers that have configured Zend Z-Ray for the app, you can look for instances of Zend Z-Ray using the Azure Cloud Shell and one of the following sample scripts:   Azure Powershell   Get-AzResource -ResourceType Microsoft.Web/sites/premieraddons `    | Where-Object {$_.name -like '*/zray*'} `    | Select-Object Name,ResourceGroupName,ResourceType   Azure CLI   az resource  list --query \"[?contains(name, 'zray') &amp;&amp; type=='Microsoft.Web/sites/premieraddons'].{Name:name, RG:resourceGroup, Type:type}\" --output table   Manually Removing Zend Z-Ray debugging   Once you have identified Zend Z-Ray instances in your subscription you can manually delete them using the portal.      Browse to the Resource Group containing the Zend Z-Ray instance.   Enable the Show Hidden Types option.   Select the Zend Z-Ray instance using the checkbox associated with this item.   Click on Delete in the Resource Group command bar   Confirm the action.   Once the Zend Z-Ray resource has been manually deleted any monthly charges associated with it will also stop.      If you have questions, please contact Azure Support.  ","categories": [],
        "tags": [],
        "url": "https://azure.github.io/AppService/2019/02/05/Important-Update-for-Zend-Z-Ray-PHP-Debugging.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "The Data Connections will be removed from Web App menu",
        "excerpt":"Data connections provides a guided experience to easily add a connection string to a new or existing SQL Azure Database or Azure Storage Account.   To simplify the user experience, the data connections feature will be removed from the Web Apps menu on April 15, 2019. The feature has a limited audience, and you can easily create connection strings manually, as we describe below.   How can I add a connection string manually?   Use a new or existing data source   First determine whether you’ll create a data store or use an existing one.   If you’re going to create a data store, use one of the following quickstarts:      Quickstart: Create a storage account   Quickstart: Getting started with single databases in Azure SQL Database   If you are using an existing data source, then your next step is to create the connection string.   Create the connection string   Depending on what data store you use, the connection string will have a different format:   SQL Database Connection String format   Data Source=tcp:{your_SQLServer},{port};Initial Catalog={your_catalogue};User ID={your_username};Password={your_password}      {your_SQLServer} Name of the server, this can be found in the overview page for your database and is usually in the form of “server_name.database.windows.net”.   {port} usually 1433.   {your_catalogue} Name of the database.   {your_username} User name to access your database.   {your_password} Password to access your database.   Learn more about SQL Connection String format   Azure Storage Connection String format   DefaultEndpointsProtocol=https;AccountName={your_storageAccount};AccountKey={your_storageAccountKey}      {your_storageAccount} Name of your Azure Storage Account   {your_storageAccountKey} Keys used to access your Azure Storage Account   Where can I find my Azure Storage Account Access Keys     Add the connection string to your Web App   In App Service, you can manage connection strings for your application by using the Configuration option in the menu.   To add a connection string:           Click on the Application settings tab.            Click on [+] New connection string.            You will need to provide Name, Value and Type for your connection string.                       If your are adding a connection string to a SQL Azure database choose SQLAzure under type.                        If your are adding a connection to an Azure Storage account, chose Custom under type.                        NOTE If you are adding a connection string because you are planning on using the Easy API or Easy Table features, then the connection strings used by this features expect the following specific names:          Azure SQL database: MS_TableConnectionString     Azure Storage account: MS_AzureStorageAccountConnectionString     ","categories": [],
        "tags": ["Azure Portal"],
        "url": "https://azure.github.io/AppService/2019/02/26/Changes-to-data-connections-UX.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure App Service on Azure Stack Update 5 Released",
        "excerpt":"This morning we released the fifth update to Azure App Service on Azure Stack.  This release updates the resource provider and brings the following key capabilities and fixes:      Updates to App Service Tenant, Admin, Functions portals and Kudu tools. Consistent with Azure Stack Portal SDK version.   Updates to Kudu tools to resolve issues with styling and functionality for customers operating disconnected Azure Stack.   Updates to core service to improve reliability and error messaging enabling easier diagnosis of common issues.   All other fixes and updates are detailed in the App Service on Azure Stack Update Five Release Notes   You can download the new installer and helper scripts:      Installer   Helper Scripts   Please read the updated documentation prior to getting started with deployment:      Update 5 Release Notes   Before you get started with App Service on Azure Stack   Deploy the App Service Resource Provider for new deployments   Update the App Service Resource Provider for updating existing deployments  ","categories": [],
        "tags": ["Azure Stack"],
        "url": "https://azure.github.io/AppService/2019/02/28/Azure-App-Service-on-Azure-Stack-Update-5-Released.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Changes to Routing Rules UX",
        "excerpt":"We will soon be rolling out a series of UX and ARM API changes that will alter the behavior of routing rules for testing in production. After May 22nd, you will no longer be able to create routing rules in staging slots from the Portal, and on August 21st we will remove routing rules from all non-production slots. You will still be able to route traffic from your production slot to your staging slots to do testing in production. Please follow the instructions below to remove the routing rules from your staging slots.     The change   We originally allowed traffic routing from staging slots to enable advanced testing scenarios. However, we later learned that our customers were often routing traffic incorrectly and running into circular routing loops and other problems. Testing in production quickly gets complicated when routing rules are applied to non-production slots.   On August 21st we will remove all routing rules from staging slots. Rules on your production slot will not be changed.   How to remove rules on staging sites   Using the Portal   Until May 22nd, you can remove your staging slot rules through the Azure portal.      Go to your Web App in the portal. Under Deployment Slots you can select your staging slot(s).     In your staging slot, go to the Deployment Slots panel and set the traffic percentages to 0.   Click Save.   Using ARM   Until August 21st, you can remove your staging slot rules through the Resource Explorer. On August 21st we will remove all routing rules from staging slots.      Go to your staging slot in the Portal and click Resource Explorer  In the panel, click Go. This should open a new tab in your browser. The navigation menu will open to your staging slot.        Go to staging slot &gt; config &gt; web                   Click Edit              Scroll down to the routingRules attribute and set the child reroutePercentage’s to 0 for any other slots     Set the reroutePercentage to 100 for the slot current slot   Scroll back up and click “Put”.  ","categories": [],
        "tags": ["Azure Portal","deployment slots"],
        "url": "https://azure.github.io/AppService/update/2019/03/18/Changes-to-Testing-in-Production-UX.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "//DevTalk - App Service Certificate - New Sync and Export experiences",
        "excerpt":"App Service Certificates have been a very popular feature among App Service customers. However, our customers often get confused about the sync scenarios between App Service Certificates and Linked Private certificates. Specifically during the Manual Renew, Manual Rekey, and Auto Renew operations. This blog will showcase recent UX improvements to give you control over the sync scenarios. We will also talk about the internals of the automatic sync tasks running in the background to keep your certificates and SSL bindings synced up automatically.   App Service Certificate Overview experience   When you open the App Service Certificate UX you will see the list of Linked Private certificates that are referenced in your App Service Apps.      Note the sync button top, it will be disabled if all Linked Private certificates are in-sync. If any Linked Private certificates are not synced, the sync button will be enabled as shown above.   The Sync operation performs the following tasks:      Updates the Linked Private certificate with the current active App Service Certificate.   Updates all SSL Bindings in all apps used by the Linked Private certificate to use the new certificate.   You can sync all Linked Private certificates from the main sync experience in one click.      Manual Rekey and Renew experience   Previously, during rekey and renew scenarios we would show the certificates references. Now we show the status of the Linked Private certificate and the difference between the thumbprints between them to give a clear view of the certificate state. We also allow you to sync the certificate with the sync command directly.   This model allows you to perform a rekey or a renew and leave the UI and continue with your work in the portal. When you return to the App Service Certificate blade, you will see the out-of-sync certificates. At this point, you can either let the automatic sync task take care of it, or sync it manually using the button.   Manual Renew Scenario      Manual Rekey Scenario      Auto Renew and Sync internals   Our customers are sometimes confused by how the auto renew operation works and how it affects the Linked Private certificates. In an attempt to demystify the process, let me explain how our renew and syncs happen.   As we know by now, App Service Certificate uses GoDaddy APIs to issue your SSL certificates. Once a certificate is issued, we store the certificates in the KeyVault you configured during the KeyVault configuration step. We have a AutoRenew background task that runs every 8 hours in the App Service Certificate backend to look at all the certificates that are up for renewal and renew them if you have turned on Auto Renew. Once renewed the background task updates the KeyVault with the new certificate.   Meanwhile, in the App Service backend we have another task that runs every 48 hours to sync all certificates that have a KeyVault reference (you can import a certificate from KeyVault secret into a App Service Web App following this blog). The background tasks has to run through a lot of private certificates which have KeyVault references and check if they have changed and update the certificate if needed, during this sync we also need to update the SSL Bindings on all the apps that are using this private certificate to maintain a working configuration.   We have put in a lot of work to make these background task run at maximum efficiency and fall back properly on error cases. So when an Auto Renew happens, the new certificate will automatically be synced when 48-hour background task picks up the certificate to sync. We are aware that 48 hours is too long for some customers and we are working on improving the timings. Until then, you can do a manual sync with the experience provided above. You can rest assured that the certificate used in your app at any point of the scenario will be valid during the auto renew process as we give a buffer of 60 days when both the newly renewed certificate and the old are valid.   Looking forward to hearing more on whether the internal details shed some light on how the auto renew and sync works and if you need more details feel free to drop a comment with your ask.   Export Scenario   When you go to the export experience on App Service Certificate, you will see a new link to open the KeyVault Secret directly. In order to open the KeyVault secret you need to have GET permissions on the KeyVault Access Policy. Once you open the secret UI, you can navigate to the current version and download the certificate directly from the portal. The certificate will be in pfx format and may need further processing to add a password or prepare it for Linux/Mac usage. But for now, you do not need any PowerShell magic to get the pfx. Note that KeyVault secret UI does not add a password for the downloaded pfx. Once you downloaded the pfx, we advise you to install it on your Windows machine and export it with the password and delete the other occurrences to keep the pfx save (or as save as it can be now that it is out in the wild file system frontier). If you using mac or linux you will need to use openssl to secure it with a key.   Use it only when you want to take the pfx out of Azure and use it somewhere else. You can also use KeyVault APIs (which can run in any platform) to directly pull the secret when you need it in your code which is much more safer than keeping a file around.   Export experience - Click the “Open KeyVault Secret”      KeyVault Secret UI - Click the Current version      Download Pfx - Click “Download as a certificate” button      Epilogue   Looking forward to hearing more from you, we like to keep our //DevTalk series a quick informal blog series that bring you direct updates from us on improvements across App Service that we keep tinkering out in the service. We drive these changes based on customer feedback, support cases, user voice, internal DLs and posts like these. We look forward to feedback, asks and comments on the new improvements and old to help us develop the service you love to use 💖.  ","categories": [],
        "tags": ["certificates"],
        "url": "https://azure.github.io/AppService/appservicecertificate/2019/03/19/DevTalk-App-Service-Certificate-sync-improvements-and-design.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing the new change analysis experience in App Service Diagnostics",
        "excerpt":"In a fast-paced development environment, sometimes it is difficult to keep track of all the changes made to your app… let alone pinpoint a change that caused an unhealthy behavior. Change Analysis can help you narrow down on changes made to your app to facilitate the trouble-shooting experience.   Finding Change Analysis   Change Analysis is embedded in App Service Diagnostics’ tiles such as Application Changes and Application Crashes so you can use it concurrently with information from other tiles. For more information on how to navigate to App Service Diagnostics, please visit Azure App Service diagnostics overview.   How to enable Change Analysis   Upon opening a diagnostic report, you will see a message to enable Change Analysis. You can access the Change Analysis Settings by clicking on the Enable Now button.      Turn on Change Analysis and click Save to get property changes and code changes for your main web app. [Note: If you are using Change Analysis for the first time, enabling this setting will register Change Analysis Resource Provider on your subscription.] By enabling Change Analysis, your app’s Kudu will trigger a snapshot every 4 hours to capture the changes made between those time intervals.      To disable Change Analysis on your web app, click on Go to Change Analysis Settings in the upper right corner of Change Analysis in the diagnostic report. [Note: Change Analysis Resource Provider is still registered on the subscription of your web app.] To unregister Change Analysis Resource Provider from your subscription, navigate to your subscription, click Resource providers in the left navigation, select Microsoft.ChangeAnalysis, and click Unregister.   Navigating through the change timeline   Once Change Analysis is enabled, you will see a change timeline embedded in the diagnostic reports. The change timeline is populated by changes made in the past 24 hours, represented by square boxes on the timeline. You can click on each box to filter for corresponding change(s) in the change chart below. You can also use the search bar to filter for changes that have your search term.      You can also expand each row of change to view the difference between the old values and the new values.      Above the timeline is the last scanned time stamp that shows the last time the timeline was updated. If you wish to find out about changes made after the last scanned time, click Scan changes now. (This process may take few minutes)      After scanning is complete, you can update the timeline by clicking on View changes now.      Change Analysis in Practice   Now, let’s walk through a scenario where Change Analysis can be helpful. Suppose you have noticed some downtime in your app caused by a changed App Setting, but you do not know what has caused the issue. First, open a diagnostic report with Change Analysis like Application Crashes. Browse through the change timeline to see if there were any changes made before the app started crashing. If you do not find any changes on the timeline that could be related to the issue, click Scan changes now to update the timeline with the most recent changes. After the scanning completes, click View changes now to populate the timeline with the new changes. You notice there is one change that occurred right before the app started crashing. Expand the new change to view the differences. You may find that you accidentally deleted the connection string when you last made your code changes.   Used in tandem with other information, Change Analysis can serve as a powerful tool for diagnosing and solving problems with your web app.   Feel free to post any questions about Change Analysis on the MSDN Forum.  ","categories": [],
        "tags": ["diagnostics","troubleshooting","self-help"],
        "url": "https://azure.github.io/AppService/2019/05/07/Announcing-the-new-change-analysis-experience-in-App-Service-Diagnostics-Analysis.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "App Service Plan Density Check",
        "excerpt":"App Service Plans define the compute resource assigned to run your App Service. The pricing tier of your App Service Plan determines the compute power and features you get… the higher the tier, the more features and compute power are available. To find out which features are supported in each pricing tier, see App Service Plan details.   When you deploy multiple App Services in the same App Service Plan, they all share the underlying compute resources. If your App Service Plan has more than the recommended number of apps, the apps will compete for the same set of resources. This will cause high CPU and memory that could result in availability and performance issues.   How to verify the App Service Plan density   In order to verify if your apps are possibly competing for resources, run the App Service Plan Density check detector by following these steps:      From the Azure Portal, go to one of your Apps   Go to the “Diagnose and solve problems” blade   In the search bar, you can search for “Best Practices for Availability &amp; Performance” to run multiple checks on your app or search for “App Service Plan density check” to run this check only   You will see one of the following notifications.           Your plan is within the recommended value                   Your plan is nearing exhaustion              Recommended Solutions           Stop apps to decrease load       In the description, the detector will recommend stopping a number of apps to be within the recommended number of apps on the respective pricing tier. The number may actually be lower depending on how resource intensive the hosted applications are, however as a general guidance, you may refer to the table below.                                  Worker Size           Max sites                                           Small           8                             Medium           16                             Large           32                                  Note: An active slot is also classified as an active app as it too is competing for resources on the same App Service Plan.                 Scale up your App Service Plan       If your App Service Plan is on a Small/Medium tier, scaling up the plan will move the apps to a higher compute power with better CPU and memory. If you are not running on a Pv2 plan, Pv2 features Dv2-series VMs with faster processors, SSD storage, and double memory-to-core ratio compared to Standard.                   Split Apps in multiple App Service Plans       If you have other App Service Plans that have been created in the same Resource Group and Region, you can move your app to one of those plans and decrease the load.                   Alternatively, you can migrate your app to a new App Service Plan by following the instructions below             Create a new App Service Plan in the same resource group and location.       Select a pricing tier that fits the performance and feature needs for your application.       Navigate to the application in the Azure Portal whose app service plan you want to change.       Select the “Change App Service Plan” tab from the left sidebar menu.       Choose the newly created App Service Plan (created in Step 2).           Feel free to post any questions about App Service Plan Density Checks on the MSDN Forum.  ","categories": [],
        "tags": ["app service plan","troubleshooting","diagnostics","best practice"],
        "url": "https://azure.github.io/AppService/2019/05/21/App-Service-Plan-Density-Check.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure App Service on Azure Stack Update 6 Released",
        "excerpt":"This afternoon we released the sixth update to Azure App Service on Azure Stack.  This release updates the resource provider and brings the following key capabilities and fixes:      Updates to App Service Tenant, Admin, Functions portals and Kudu tools. Consistent with Azure Stack Portal SDK version.   Updates to Kudu tools to resolve issues with styling and functionality for customers operating disconnected Azure Stack.   Updates to core service to improve reliability and error messaging enabling easier diagnosis of common issues.   All other fixes and updates are detailed in the App Service on Azure Stack Update Six Release Notes   The App Service on Azure Stack Update 6 build number is 82.0.1.50   You can download the new installer and helper scripts:      Installer   Helper Scripts   Please read the updated documentation prior to getting started with deployment:      Update 5 Release Notes   Before you get started with App Service on Azure Stack   Deploy the App Service Resource Provider for new deployments   Update the App Service Resource Provider for updating existing deployments  ","categories": [],
        "tags": ["Azure Stack"],
        "url": "https://azure.github.io/AppService/2019/05/28/App-Service-on-Azure-Stack-Update-6-Released.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP Minor Version Update for August 2019",
        "excerpt":"Latest version updates to PHP   In August 2019, Azure App Service will update the PHP stacks to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.                  PHP Version       Change Log                       5.6.401       http://www.php.net/ChangeLog-5.php#5.6.40 + security fixes from https://github.com/microsoft/php-src/commits/PHP-5.6-security-backports                 7.0.331       http://www.php.net/ChangeLog-7.php#7.0.33 + security fixes from https://github.com/microsoft/php-src/commits/PHP-7.0-security-backports                 7.1.30       http://www.php.net/ChangeLog-7.php#7.1.30                 7.2.20       http://www.php.net/ChangeLog-7.php#7.2.20                 7.3.6       http://www.php.net/ChangeLog-7.php#7.3.6           Feel free to post any questions about PHP Minor Version Update for August 2019 on the MSDN Forum.    1 - Both PHP v5.6 and v7.0 are past End-Of-Life, and are no longer receiving security updates from the community.  However, to ensure our customers have the most secure PHP builds available, we have arranged to have relevant security fixes from supported versions of PHP backported to PHP v5.6 and v7.0.    Edit: Due to an issue with the Zend Opcache extension in PHP 7.2.19, we will move to 7.2.20 for this update.  ","categories": [],
        "tags": ["PHP"],
        "url": "https://azure.github.io/AppService/2019/06/18/PHP-Minor-Version-Update-for-August-2019.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP Minor Version Update for July 2019",
        "excerpt":"Latest version updates to PHP   In July 2019, Azure App Service will update the PHP stacks to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.                  PHP Version       Change Log                       7.1.28       http://www.php.net/ChangeLog-7.php#7.1.28                 7.2.17       http://www.php.net/ChangeLog-7.php#7.2.17                 7.3.4       http://www.php.net/ChangeLog-7.php#7.3.4           Feel free to post any questions about PHP Minor Version Update for July 2019 on the MSDN Forum.  ","categories": [],
        "tags": ["PHP"],
        "url": "https://azure.github.io/AppService/2019/07/17/PHP-Minor-Version-Update-for-July-2019.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Removing Easy Tables and Easy APIs from Azure App Service",
        "excerpt":"   Integrating mobile services in your application? Sign up with App Center    Visual Studio App Center is the next generation solution for mobile application developers. It offers  integrated end-to-end services central to mobile development. If you are integrating Microsoft cloud services in your mobile application, sign up with App Center today.   Removing Easy Tables and Easy APIs from Azure App Service  Azure App Service provides specific features for Node developers to easily get started with mobile backend services by leveraging Easy Tables and Easy APIs in the Azure portal. Easy Tables provides a portal experience for Node developers to create and manage their tables, their schema, and appropriate permissions. Easy APIs lets developers build and consume custom APIs in the backend.   Easy Tables and Easy APIs, along with the Mobile menu in the Azure portal will be removed on November 11, 2019 as these features have a limited audience and the existing functionality can be leveraged in alternate ways.   Developers that have mobile apps with a Node.js backend can leverage the existing functionality from Easy API and Easy Tables by following the guidance below.   Easy API   Existing API   Your existing APIs will continue to work as the backend is already deployed on App Services.   Create a new API or make changes to existing API   You can either make changes right in the Azure portal or modify the code locally in your development environment and then publish to Azure. Click on the App Service Editor (Preview) under Development Tools menu which provides an in-browser editing experience for your app code.      Click on Go and once the App Service Editor opens, you have full control over the source code. Assuming you have already installed express and azure-mobile-apps package with npm install command, click on the api folder under WWWROOT to create or edit custom API. Make your changes to the code file and the changes are saved automatically.      Easy Tables   You have full control on the Azure SQL Database used to store the application data. Your existing tables will continue to work without any required changes. For the existing portal features, below are the alternatives:   Add from CSV   Follow the documentation link in order to load data from CSV into Azure SQL Database.   Add Table   The “+ Add” button lets you add tables to the database. There are four options for creating new tables in the database.           Use SQL Server. This tutorial explains how to create tables in your database.            From the SQL database in Azure portal, you can run the following query to add a table named TodoItems from Query editor (preview)         CREATE TABLE TodoItems   (       id NVARCHAR(36) PRIMARY KEY,       createdAt DATETIMEOFFSET NOT NULL,       updatedAt DATETIMEOFFSET,       version TIMESTAMP NOT NULL,       deleted BIT NOT NULL,       complete BIT NOT NULL,       text NVARCHAR(256)   );                In App Service Editor or locally, click on wwwroot/tables directly to create new files, {tablename}.js and {tablename}.json where {tablename} refers to the name of the table you  created in Step 1. Sample code can be found at todoitem.js and todoitem.json.            Edit the files locally and deploy the changes to Azure App Service.       Change permission   In order to change access permissions on tables, you can either use the portal to change the code or modify it locally in your development environment. Click on the App Service Editor (Preview) under Development Tools menu which provides an in-browser editing experience for your app code.   Assuming you have already installed express and azure-mobile-apps package with npm install command, click on “Go” to open the App Service Editor. Once open, click on the tables folder under WWWROOT and open the json file for the table that you want the permissions to change. This will let you modify the access permissions for insert, update, delete, read and undelete operations for that table. You can also do this locally in the app code and deploy back to App Services.   Edit script   You can edit your table script by either using the App Service Editor or modifying the code locally and deploying it back to App Services.   Delete table   Since you own your SQL database, you can delete the table by executing a SQL query against the database.   Clear table   Since you own your SQL database, you can clear contents of the table by executing a SQL query against the database.   Streaming logs   You can use Log stream under the Monitoring menu to stream your application and Web Server logs.  ","categories": [],
        "tags": ["mobile apps"],
        "url": "https://azure.github.io/AppService/2019/07/25/Removing-Easy-Tables-and-Easy-APIs-from-Azure-App-Services.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure Key Vault References with Spring Apps",
        "excerpt":"Azure Key Vault provides a centralized service for managing secrets and certificates with full control over access policies and auditing capabilities. This article will show how to wire up a Spring Boot application on App Service to read a database username, password, and URL from Key Vault. Using Key Vault references requires no code changes, but we will need to do some configuration acrobatics.      See the previous article for instructions on setting up the Postgres server and deploying the starter app to App Service.    Set up a Managed Identity   A managed identity acts as a user in your Active Directory for automation purposes. It is inherently tied to your web app and will be deleted if the web app is deleted. For this scenario, the identity will be used to retrieve the secrets from Key Vault when the app starts. Run the following command to create a manged identity:   az webapp identity assign --name &lt;app_from_last_article&gt; --resource-group &lt;resource_group_of_app&gt;   In the console output, save the principalId for later.   Provision the Key Vault           Let’s spin up a Key Vault named java-app-key-vault. For information about the parameters specified below, run az keyvault create --help.        az keyvault create --name java-app-key-vault              \\                     --resource-group &lt;your_resource_group&gt; \\                     --location &lt;location&gt;                  \\                     --enabled-for-deployment true          \\                     --enabled-for-disk-encryption true     \\                     --enabled-for-template-deployment true \\                     --sku standard                Now we will grant the managed identity get and list access to the Key Vault.        az keyvault set-policy --name java-app-key-vault     \\                         --secret-permission get list  \\                         --object-id &lt;the principal ID from earlier&gt;                Finally, we will add the Postgres username, password, and URL to the Key Vault. If you followed the tutorial on data sources, you should still have the secrets saved as environment variables on your machine. (If you are using Powershell, use the $env:ENV_VAR syntax to inject the environment variables into the following command).        az keyvault secret set --name POSTGRES-USERNAME      \\                     --value $POSTGRES_USERNAME        \\                     --vault-name java-app-key-vault  az keyvault secret set --name POSTGRES-PASSWORD      \\                     --value $POSTGRES_PASSWORD        \\                     --vault-name java-app-key-vault  az keyvault secret set --name POSTGRES-URL           \\                     --value $POSTGRES_URL             \\                     --vault-name java-app-key-vault           Configuring our App   The following instructions assume you have completed the previous tutorial.   Key Vault References   When our Spring app is running on App Service, the secrets will be exposed as environment variables or “Application Settings”. We will now create these app settings using the Azure CLI.           First, we need the URI’s of our three secrets. Run the commands below and copy the id value in the console output.        az keyvault secret show --vault-name java-app-key-vault --name POSTGRES-URL  az keyvault secret show --vault-name java-app-key-vault --name POSTGRES-USERNAME  az keyvault secret show --vault-name java-app-key-vault --name POSTGRES-PASSWORD                Now we will create the app settings with the Key Vault references. For each setting, replace “YOUR_SECRET_URI” with the corresponding id’s from the previous step.        az webapp config appsettings set -n &lt;your_app_name&gt; -g &lt;resource_group&gt; --settings \\      SPRING_DATASOURCE_URL=@Microsoft.KeyVault(SecretUri=YOUR_SECRET_URI)\\      SPRING_DATASOURCE_USERNAME=@Microsoft.KeyVault(SecretUri=YOUR_SECRET_URI)\\      SPRING_DATASOURCE_PASSWORD=@Microsoft.KeyVault(SecretUri=YOUR_SECRET_URI)           A Key Vault reference is of the form @Microsoft.KeyVault(SecretUri=&lt;SecretURI&gt;), where &lt;SecretURI&gt; is data-plane URI of a secret in Key Vault, including a version. There is an alternate syntax documented here.   Environment Configuration   The Key Vault references will be replaced with the actual secrets when our App Service boots up. This means our Spring application needs to resolve the connection strings at runtime. (It currently resolves these strings at build time.) We also want to be able to use our H2 database for development, and optionally connect to the production DB from our local machine to run tests. To fill all these requirements, we will create two new configuration files: application-dev.properties, and application-prod.properties.           Create a file under src/main/resources named application-dev.properties. Copy/paste the following into the file:        # ===============================  # = DATA SOURCE  # ===============================  # Set here configurations for the database connection  spring.datasource.url=jdbc:h2:mem:testdb  spring.datasource.username=sa  spring.datasource.password=  spring.datasource.driver-class-name=org.h2.Driver   # ===============================  # = JPA / HIBERNATE  # ===============================   # Allows Hibernate to generate SQL optimized for a particular DBMS  spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.H2Dialect   # App Service  server.port=8080                Create a file under src/main/resources named application-dev.properties. Copy/paste the following into the file. Notice that we do not set the connection strings here. Instead, Spring will resolve them at runtime by looking for the uppercase and underscored versions of spring.datasource.url, spring.datasource.username, and spring.datasource.password.        # ===============================  # = DATA SOURCE  # ===============================   # The connection URL, username, and password will be sourced from environment variables  # on App Service   # Set here configurations for the database connection  spring.datasource.driver-class-name=org.postgresql.Driver   # ===============================  # = JPA / HIBERNATE  # ===============================   # Allows Hibernate to generate SQL optimized for a particular DBMS  spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect   # App Service  server.port=80                Now we can slim-down our original application.properties file. Replace the contents of application.properties with the following:        # Active profile is set by Maven  spring.profiles.active=@spring.profiles.active@   # ===============================  # = DATA SOURCE  # ===============================   # Keep the connection alive if idle for a long time (needed in production)  spring.datasource.testWhileIdle=true  spring.datasource.validationQuery=SELECT 1   # ===============================  # = JPA / HIBERNATE  # ===============================  # Show or not log for each sql query  spring.jpa.show-sql=true   # Hibernate ddl auto (create, create-drop, update): with \"create-drop\" the database  # schema will be automatically created afresh for every start of application  spring.jpa.hibernate.ddl-auto=create   # Naming strategy  spring.jpa.hibernate.naming.implicit-strategy=org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyHbmImpl  spring.jpa.hibernate.naming.physical-strategy=org.springframework.boot.orm.jpa.hibernate.SpringPhysicalNamingStrategy                Finally, we can also slim down our Maven profiles because we have moved th information to the new properties files. The profile section of your pom.xml should now be the following:        &lt;profiles&gt;    &lt;profile&gt;      &lt;!-- This profile will configure Spring to use an in-memory database for local development and testing. --&gt;        &lt;id&gt;dev&lt;/id&gt;        &lt;activation&gt;        &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;      &lt;/activation&gt;        &lt;properties&gt;        &lt;spring.profiles.active&gt;dev&lt;/spring.profiles.active&gt;      &lt;/properties&gt;    &lt;/profile&gt;      &lt;profile&gt;      &lt;!-- This profile will configure the application to use our Azure PostgreSQL server. --&gt;        &lt;id&gt;prod&lt;/id&gt;        &lt;properties&gt;          &lt;spring.profiles.active&gt;prod&lt;/spring.profiles.active&gt;      &lt;/properties&gt;    &lt;/profile&gt;  &lt;/profiles&gt;           See this article for more information on Spring configurations and precedence.   Deploy and Test   Check that the development profile works as expected by running the following commands and opening a browser to http://localhost:8080/.   mvn clean package -Pdev java -jar target/app.jar   Before deploying to App Service, build your application with the production profile and test against your PostgreSQL DB from your local machine. To do so, rename the three environment variables beginning with POSTGRES_ to SPRING_DATASOURCE_URL, SPRING_DATASOURCE_USERNAME, and SPRING_DATASOURCE_PASSWORD respectively. Run the following commands to build and start your app. Thanks to our new configuration, Spring will resolve the connection strings in the environment variables at runtime.   mvn clean package -Pprod java -jar target/app.jar   Finally, deploy the production app to App Service with mvn azure-webapp:deploy. Browse to the application and test that it works properly.   Next Steps   See the Java Developer Guide for more documentation and best practices for Java on App Service. Check back in the future for more articles. Thanks for reading!  ","categories": [],
        "tags": ["Java"],
        "url": "https://azure.github.io/AppService/2019/07/30/Key-Vault-References-with-Spring-Apps.html",
        "teaser":"https://azure.github.io/AppService/media/2019/07/locks-header.jpg"},{
        "title": "Get visibility into your app's dependencies with Navigator",
        "excerpt":"Application downtime can be dreadful, especially when the app is handling mission-critical load. There could be countless causes for your app’s downtime ranging from the app’s code to the misconfiguration of its dependencies. Fast troubleshooting is the key to minimizing the production impact. However, the complex nature of today’s applications makes narrowing down the cause a lengthy and difficult process. Sometimes it requires thorough investigation of changes made to each dependent resource.   We are excited to announce Navigator, a new feature offering for Windows apps in App Service Diagnostics, an intelligent and guided experience that helps you troubleshoot your web app with little to no configuration. Navigator is a new diagnostic feature that provides a centralized view of a web app and its dependencies as well as the changes made to those dependencies. The feature can automatically render dependencies in the same subscription as a dependency map and display the changes made to each resource, leveraging Change Analysis. With the new experience, you can easily identify the dependencies of your web app and explore the changes as part of your troubleshooting experience.   Paired with information from existing diagnostics information in App Service Diagnostics, Navigator can supplement your troubleshooting experience by providing a timeline of the changes made by your web app and its dependencies. Correlating this information with other information offered in App Service Diagnostics can help you further understand the changes and narrow down on potential causes for unhealthy behavior.   Finding Navigator   Navigator can be accessed through App Service Diagnostics’ homepage tile called Navigator so you can use it concurrently with information from other tiles. For more information on how to navigate to App Service Diagnostics, please visit Azure App Service diagnostics overview.      How to enable Change Analysis   Upon opening the tool, you will see a message to enable Change Analysis. You can access the Change Analysis Settings by clicking on the Enable Now button.      Turn on Change Analysis and click Save to get property changes and code changes for your main web app as well as property changes for your dependent resources. [Note: If you are using Change Analysis for the first time, enabling this setting will register Change Analysis Resource Provider on your subscription.] By enabling Change Analysis, your app’s Kudu will trigger a snapshot every 4 hours to capture the changes made between those time intervals.      To disable Change Analysis on your web app, click on Go to Change Analysis Settings in the upper right corner of Navigator view. [Note: Change Analysis Resource Provider is still registered on the subscription of your web app.] To unregister Change Analysis Resource Provider from your subscription, navigate to your subscription, click Resource providers in the left navigation, select Microsoft.ChangeAnalysis, and click Unregister.   Navigating through the change timeline   Once Change Analysis is enabled, you will see a dependency map of your web app and its dependencies in the same subscription. You can check the inner workings of your app using this view. Also, if you click on a resource supported by Change Analysis, you can view the recent changes made to the selected resource. See Change Analysis service to view the list of dependencies supported by Change Analysis service.      Once you click on each resource on the map, you will see a timeline with square boxes and a list of changes detected over the last 24 hours. These square boxes represent change(s) made during the 24 hours. You can click on each box to filter for corresponding change(s) in the list of changes below. You can also use the search bar to filter for changes that have your search term.      You can also expand each row of change to view the difference between the old values and the new values.      Above the timeline is the last scanned time stamp that shows the last time the timeline was updated. If you wish to find out about changes made after the last scanned time, click Scan changes now. (This process may take few minutes)      After scanning is complete, you can update the timeline by clicking on View changes now.      Navigator in Practice   Now, let’s explore a scenario where Navigator can come in handy. Suppose you have noticed a spike in the database connection errors in your app caused by a firewall rule, but you do not know what has caused the issue. First, click on Navigator in App Service Diagnostics. Take a look at the dependency map. Select a resource to explore the changes made to the resource. Browse through the timeline to see if there were any changes made before you observed unexpected behavior. If you do not find any changes on the timeline that could be related to the issue, click Scan changes now to update the timeline with the most recent changes. After the scanning completes, click View changes now to populate the timeline with the new changes. You notice there is one change that occurred right before the app started giving you database connection errors. Expand the new change to view the differences. You may find that you accidentally changed the firewall rules.   Used in tandem with other information from App Service Diagnostics, Navigator can serve as a powerful tool for diagnosing and solving problems with your web app.   Feel free to share your feedback or questions about Navigator by emailing diagnostics@microsoft.com  ","categories": [],
        "tags": ["diagnostics","troubleshooting","self-help"],
        "url": "https://azure.github.io/AppService/2019/08/06/Bring-visibility-to-your-app-and-its-dependencies-with-Navigator.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Restore App Service domains within 30 days",
        "excerpt":"If you deleted your App Service Domain resource within the past 30 days, you can easily restore it by purchasing it again with the same Domain Registration Subscription and resource group. Unlike trying to purchase the domain name from other subscriptions or resource groups, the validation will allow you to purchase the same domain name.   Clarifications           App Service Domains are domains that were purchased from Azure App Service. Domains added to App Service websites are custom domains. These are different resources.            If your App Service Domain was deleted because you deleted the domain registration subscription, we do not support restoring the domain in any circumstance.      ","categories": [],
        "tags": ["App Service Domains"],
        "url": "https://azure.github.io/AppService/2019/08/06/How-to-restore-soft-delete-App-Service-domains.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Announcing GitHub Actions for App Service",
        "excerpt":"Last week GitHub announced the preview of GitHub Actions with built-in CI/CD; watch the announcement here. These actions, defined in YAML files, allow you to trigger an automated workflow process on any GitHub event. Today the App Service team is happy to share our own action, allowing you to deploy to App Service following a push or pull request.   With the App Service Action, you can deploy your code to any of our managed language stacks. Simply specify your source code folder, zip file, JAR or WAR. If you prefer to deploy a Docker container instead, there’s an action for that!   Getting Started      GitHub Actions are currently in Beta. Request access here.    Configure the repository      Open the Azure Portal and navigate to your web app.   In the toolbar, select Get publish profile. This will trigger a download.     Open the downloaded file and copy the contents   Open GitHub and navigate to your repository   Select Settings &gt; Secrets. On the Secrets page, select Add a new secret and paste your publish profile XML.     Now you’re ready to create the workflow file.   Create the action   If you do not have any workflows defined, select the Actions tab and follow the prompts to create a new workflow. This will create a new directory an file in the root of your repository, /.github/workflows/workflow.yml.   In the editor for workflow.yml, define the build steps for your application. For example, a Node application is typically built using npm install followed by npm run build. Below is an example workflow file that installs the dependencies, builds the project, and runs tests on the latest Ubuntu version.   on: push  jobs:   build:     runs-on: ubuntu-latest     steps:     # This checks out the repository so your workflow operates from root of repository     - uses: actions/checkout@master      # Install dependencies, build, and test     - name: npm install, build, and test # Name is optional       run: |         npm install         npm run build --if-present         npm run test --if-present   See the examples at the end of this article for specific language examples.   Add the App Service Action   After your build action, add the App Service action with uses: azure/appservice-actions/webapp@master. This action has the following required arguments. These should be listed under a with: key:      app-name: Your application name   package: The path to the deployment file or folder (relative from the root)   publish-profile: The publish profile that you pasted into the GitHub Secrets earlier   # Deploy to App Service - uses: azure/appservice-actions/webapp@master - name: Deploy to app service  # Name is optional   with:     app-name: &lt;the app name&gt;  # Replace with your app name     package: &lt;path to deployment source&gt;  # Specify the folder or file to deploy     publish-profile: ${{ secrets.&lt;your-publish-profile-name&gt; }}  # Replace with the name of your publish profile   Deploy to a slot   The App Service Action deploys to the production slot by default. To deploy to a staging slot, redo the publish profile steps with the publish profile from your desired staging slot.   Other Azure Actions   In addition to this action, there are actions for other common Azure scenarios such as deploying to Azure Kubernetes Service, logging into Azure with a service principal, or signing into Docker. See the links below.   Examples   Containers   To deploy a container, you will need to create an Azure Service Principal via the Azure CLI, then paste the details of the principal as a GitHub Secret.      Install the Azure CLI        Run the following command, replacing {subscription} and {resource-group} with the subscription and resource group of your application        az ad sp create-for-rbac --name \"myServicePrincipal\" --role contributor \\    --scopes /subscriptions/{subscription}/resourceGroups/{resource-group} \\    --sdk-auth           Open GitHub and navigate to your repository   Select Settings &gt; Secrets. On the Secrets page, select Add a new secret and paste the JSON output from the earlier az ad sp command.     Finally, add your Docker username and password as GitHub Secrets   Here is a full example:   on: push  jobs:   deploy-container:     runs-on: ubuntu-latest     steps:     - uses: actions/checkout@master      # Unlike code deployment, you will authenticate using a Service Principal     - uses: azure/actions/login@master       with:         creds: ${{ secrets.AZURE_SP }}      # These creds are used to push your new image     - uses: azure/container-actions/docker-login@master       with:         username: ${{ secrets.DOCKER_USERNAME }}         password: ${{ secrets.DOCKER_PASSWORD }}         #loginServer: '&lt;login server&gt;' # default: index.docker.io      # Tag the image with the git commit hash     - run: |         docker build . -t contoso/demo:${{ github.sha }}         docker push contoso/demo:${{ github.sha }}      - uses: azure/appservice-actions/webapp-container@master       with:         app-name: '&lt;your app name&gt;'         images: 'contoso/demo:${{ github.sha }}'         #configuration-file: 'Optional path to a docker compose file'         #container-command: 'Optional startup command for the app (dotnet run, java -jar app.jar)'   Java   When deploying Java apps, make sure you specify the package name relative from the root directory. Most likely, your deployment artifact will be in the target/ directory.   on: push  jobs:   java-build-and-deploy:     runs-on: ubuntu-latest     steps:     # checkout the repo     - uses: actions/checkout@master      # install dependencies, build, and test     - name: Maven build phase       run: |         mvn clean package      - uses: azure/appservice-actions/webapp@master       with:         app-name: &lt;your-app-name&gt;         publish-profile: ${{ secrets.&lt;publish-profile&gt; }}         package: target/app.war   Javascript   on: push  jobs:   build-and-deploy:     runs-on: ubuntu-latest     steps:     - uses: actions/checkout@master      # install dependencies, build, and test     - name: npm install, build, and test       run: |         npm install         npm run build --if-present         npm run test --if-present     - uses: azure/appservice-actions/webapp@master      with:        app-name: &lt;your-app-name&gt;        publish-profile: ${{ secrets.&lt;publish-profile&gt; }}        package: '.'   Python   on: push  jobs:   build-and-deploy:     runs-on: ubuntu-latest     steps:     - uses: actions/checkout@master      - name: install dependencies, and zip the app to use ZipDeploy       run: |         pip install -r requirements.txt         zip -r myapp.zip      - uses: azure/appservice-actions/webapp@master       with:         app-name: &lt;your-app-name&gt;         publish-profile: ${{ secrets.&lt;publish-profile&gt; }}         package: './myapp.zip'   Helpful Resources      Actions for Containers   App Service Action source code   Checkout Action   Other Azure Actions  ","categories": [],
        "tags": ["deployment","devops","github"],
        "url": "https://azure.github.io/AppService/2019/08/10/Github-actions-for-webapps.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Azure App Service on Azure Stack Update 7 Released",
        "excerpt":"This afternoon we released the seventh update to Azure App Service on Azure Stack.  This release updates the resource provider and brings the following key capabilities and fixes:      Updates to App Service Tenant, Admin, Functions portals and Kudu tools. Consistent with Azure Stack Portal SDK version.   Updates to core service to improve reliability and error messaging enabling easier diagnosis of common issues.   Access Restrictions now enabled in User Portal As of this release Users can configure Access Restrictions for their Web/Api/Functions applications according to the documentation published - Azure App Service Access Restrictions, NOTE: Azure App Service on Azure Stack does not support Service Endpoints.   All other fixes and updates are detailed in the App Service on Azure Stack Update Seven Release Notes   The App Service on Azure Stack Update 7 build number is 82.0.2.10   You can download the new installer and helper scripts:      Installer   Helper Scripts   Please read the updated documentation prior to getting started with deployment:      Update 7 Release Notes   Before you get started with App Service on Azure Stack   Deploy the App Service Resource Provider for new deployments   Update the App Service Resource Provider for updating existing deployments  ","categories": [],
        "tags": ["Azure Stack"],
        "url": "https://azure.github.io/AppService/2019/08/29/App-Service-on-Azure-Stack-Update-7-Released.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "PHP Minor Version Update for September 2019",
        "excerpt":"Latest version updates to PHP   In September 2019, Azure App Service will update the PHP stacks to the latest available versions. For information on the changes in the new versions, please see the change logs on the PHP website.                  PHP Version       Change Log                       5.6.401       http://www.php.net/ChangeLog-5.php#5.6.40 + security fixes from https://github.com/microsoft/php-src/commits/PHP-5.6-security-backports                 7.0.331       http://www.php.net/ChangeLog-7.php#7.0.33 + security fixes from https://github.com/microsoft/php-src/commits/PHP-7.0-security-backports                 7.1.32       http://www.php.net/ChangeLog-7.php#7.1.32                 7.2.22       http://www.php.net/ChangeLog-7.php#7.2.22                 7.3.9       http://www.php.net/ChangeLog-7.php#7.3.9            1 - Both PHP v5.6 and v7.0 are past End-Of-Life, and are no longer receiving security updates from the community.  However, to ensure our customers have the most secure PHP builds available, we have arranged to have relevant security fixes from supported versions of PHP backported to PHP v5.6 and v7.0.  ","categories": [],
        "tags": ["PHP"],
        "url": "https://azure.github.io/AppService/2019/09/04/PHP-Minor-Version-Update-for-September-2019.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Use ARM templates to swap deployment slots",
        "excerpt":"A version of this article appeared on ruslany.net   Azure Resource Manager (ARM) templates are used to automate deployment and configuration of Azure resources. With the templates you can define the infrastructure to be deployed via a JSON file and then use that file to repeatedly deploy new resources or update existing ones. ARM templates are widely used to release new versions of the Azure web apps and function apps. During a release the new version of an app is deployed to a staging slot and then it is swapped into production. This blog post explains how to automate the App Service deployment slot swap operation with an ARM template.   Let’s assume you have a web app with production and staging deployment slots. When you release a new version of that web app you first would deploy it to the staging slot and then swap it into production slot. To define the swap operation via ARM template you’ll need to use two properties on the “Microsoft.Web/sites” and “Microsoft.Web/sites/slots” resources:      buildVersion – this is a string property which can be set to any arbitrary value that would represent the current version of the app deployed in the slot. For example: “v1“, “1.0.0.1“, “2019-09-20T11:53:25.2887393-07:00“.   targetBuildVersion – this is a string property that is used to specify what version of the app the current slot should have. If the targetBuildVersion is different from the buildVersion then this will trigger the swap operation by finding a slot that has the expected build version and then swapping the site from that slot into the current slot.   With that the process of deploying a new version of an app can be done as follows:      Deploy a new version of an app into a staging slot   Execute ARM template to update the buildVersion of the app in staging slot   Execute ARM template to set the targetBuildVersion on the production slot   Here is an example ARM template that demonstrates how to perform steps #2 and #3:   {     \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\",     \"contentVersion\": \"1.0.0.0\",     \"parameters\": {         \"sites_SwapAPIDemo_name\": {             \"defaultValue\": \"SwapAPIDemo\",             \"type\": \"String\"         },         \"sites_buildVersion\": {             \"defaultValue\": \"v1\",             \"type\": \"String\"         }     },     \"resources\": [         {             \"type\": \"Microsoft.Web/sites/slots\",             \"apiVersion\": \"2018-02-01\",             \"name\": \"[concat(parameters('sites_SwapAPIDemo_name'), '/staging')]\",             \"location\": \"East US\",             \"kind\": \"app\",             \"properties\": {                 \"buildVersion\": \"[parameters('sites_buildVersion')]\"             }         },         {             \"type\": \"Microsoft.Web/sites\",             \"apiVersion\": \"2018-02-01\",             \"name\": \"[parameters('sites_SwapAPIDemo_name')]\",             \"location\": \"East US\",             \"kind\": \"app\",             \"dependsOn\": [                 \"[resourceId('Microsoft.Web/sites/slots', parameters('sites_SwapAPIDemo_name'), 'staging')]\"             ],             \"properties\": {                 \"targetBuildVersion\": \"[parameters('sites_buildVersion')]\"             }         }     ] }   This ARM template is idempotent, meaning that it can be executed repeatedly and produce the same state of the slots. In other words if you re-run the same template with the same parameters after the swap has been performed and targetBuildVersion on production slot matches the buildVersion then it will not trigger another swap.   Helpful links      Documentation for swapping slots with ARM templates   App Service quickstarts   How to get started with slots  ","categories": [],
        "tags": ["deployment slots"],
        "url": "https://azure.github.io/AppService/2019/10/02/Swap-slots-with-arm-templates.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"},{
        "title": "Mitigate your CPU problems before they happen",
        "excerpt":"   Currently offered in App Service Diagnostics for Windows web apps.    Imagine there is a CPU spike in your cloud application at 2:00 in the morning, would you like to be woken up to mitigate and troubleshoot the issue or would you rather have the issue mitigated automatically and troubleshoot after a good night’s sleep? For those of us that enjoy a good night’s sleep, Proactive CPU monitoring is an easy, proactive way to take an action when your app or its child process is consuming too much CPU. You can configure CPU rules to temporarily mitigate a high CPU issue until the real cause for the unexpected issue is found.   Finding Proactive CPU Monitoring   To access Proactive CPU Monitoring, browse to your App Service web app in Azure portal and click Diagnose and solve problems in the left navigation panel. Then, click on the homepage tile named Diagnostic Tools. Once you are inside Diagnostic Tools, click Proactive CPU Monitoring.      Configuring Proactive CPU Monitoring   Proactive CPU monitoring operates based on 5 conditions and 4 modes of action by checking w3wp.exe process of the site or any child processes.   Conditions   There are five conditions you can configure to tailor to your needs.      CPU Threshold: the CPU threshold at which the rule will be triggered   Threshold Seconds: the duration of the CPU exceeding the CPU threshold. The rule will be triggered at the end of the duration.   Monitor Frequency: defines how often the condition will be evaluated   Maximum Actions: the maximum number of memory dumps that the rule collects, ensuring no dumps are collected beyond the set amount   Maximum Duration: the maximum duration of the rule until it becomes deactivated   Actions   Once the conditions are met, your selected action is triggered. Proactive CPU Monitoring offers 4 different modes listed below.           Collect: In this mode, a memory dump is collected whenever any process consumes CPU greater than the CPU Threshold for longer than the allowed Threshold Seconds. (Monitor Duration should always be lower than Threshold Seconds) Memory dump is collected via ProcDump.exe, and the number of dumps (or actions) are controlled by Maximum Actions. Once Maximum Duration is met, the rule becomes deactivated.       When the memory dump is collected, the process is frozen until the dump generation completes. The time the process is frozen depends directly on the memory consumed by the process. The size of the dump generated is also directly proportional to the memory consumed by the process.            Kill:  In this mode, the process is killed when the condition is met. The Maximum Actions is not honored and monitoring stops automatically after Maximum Duration. Kill is a forceful termination of the process and not a graceful exit. All requests that the current worker process is processing will be terminated, and end users may see 502 errors. If system terminates the child process, the error message may even be 500 or some form of application exception based on the stack.            Collect and Kill: In this mode, a memory dump is collected and the process consuming high CPU is killed when the site’s process (or child process) consumes CPU greater than CPU threshold for more than Threshold Seconds. No analysis is performed but after the session finishes, you have an option to analyze the memory dump after the session ends by clicking the Analyze button.            Collect, Kill, and Analyze: In this mode, a memory dump is collected and the process consuming high CPU is killed when a site’s process (or child process) consumes CPU greater than the CPU threshold for longer than the allowed Threshold Seconds. In addition, CPU dumps are analyzed by DumpAnalyzer tool, and an analysis report is generated. Analyzing a dump with this tool has some CPU impact on the instance and takes roughly 5-7 minutes at minimum to analyze one dump file. Analysis can take longer if the dump size is larger and depending upon what is captured in the dump.       To prevent CPU overhead, only one dump is analyzed by the instance at a time. For example, if there are 10 instances and say the monitoring collected 5 dumps, all instances in parallel can analyze memory dumps. If there is 1 instance and 5 dumps are collected, the dump analysis will happen one after the other.          What’s Next   Once you set the rule that best suits your app’s need, you can get ahead of your CPU issues, automatically mitigate CPU spikes, and save yourself from a dreadful 2:00am call.   Feel free to share your feedback or questions about Proactive CPU Monitoring by emailing diagnostics@microsoft.com or posting on UserVoice with “[Diag]” in the title.   For more information on other diagnostic tools, please visit Azure App Service diagnostics overview.  ","categories": [],
        "tags": ["diagnostics","troubleshooting","self-help"],
        "url": "https://azure.github.io/AppService/2019/10/07/Mitigate-your-CPU-problems-before-they-even-happen.html",
        "teaser":"https://azure.github.io/AppService/media/pages/new_app_service_logo_64.svg"}]
